# -*- coding: utf-8 -*-
# --- ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
#Windows Virtual Environment Activation: .\.venv\Scripts\activate.ps1
#Mac Virtual Environment Activation: source .venv/bin/activate
from threading import Lock  # <-- ADD THIS
import json
import os
import sys # sys.exit()ã®ãŸã‚ã«è¿½åŠ 
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait, Select
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import (
    NoSuchElementException, TimeoutException, ElementClickInterceptedException,
    WebDriverException, NoSuchWindowException, StaleElementReferenceException,
    InvalidSessionIdException
)
import time
import re
import traceback
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse
import random
import pickle
import datetime
# pprint ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ã‚¿ãƒ¼ãƒŸãƒŠãƒ«å‡ºåŠ›ã‚’æ•´å½¢ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
# from pprint import pprint
# â˜…â˜…â˜… ä¸¦åˆ—å‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯å‰Šé™¤ â˜…â˜…â˜…
#from concurrent.futures import ThreadPoolExecutor
#import concurrent.futures

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ãƒ»è¨­å®š ---
CHROME_DRIVER_PATH = None # ChromeDriverã®ãƒ‘ã‚¹ (Noneã®å ´åˆã¯è‡ªå‹•æ¤œå‡º)
OPENED_LINKS_LOCK = Lock()  # <-- ADD THIS
USER_EMAIL = 'kaitosumishi@keio.jp' # ãƒ­ã‚°ã‚¤ãƒ³ã«ä½¿ç”¨ã™ã‚‹ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹
USER_PASSWORD = '0528QBSkaito' # ãƒ­ã‚°ã‚¤ãƒ³ã«ä½¿ç”¨ã™ã‚‹ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰
OUTPUT_DIR_NAME = 'syllabus_output' # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå
OUTPUT_JSON_FILE = 'syllabus_data.json' # å‡ºåŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«å
#TARGET_FIELDS = ["ç‰¹è¨­ç§‘ç›®"] # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡ã®åˆ†é‡
TARGET_FIELDS = ["åŸºç›¤ç§‘ç›®", "å…ˆç«¯ç§‘ç›®", "ç‰¹è¨­ç§‘ç›®"] # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡ã®åˆ†é‡
#TARGET_YEARS = [2025, 2024] # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡ã®å¹´åº¦
TARGET_YEARS = [2025, 2024, 2023] # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡ã®å¹´åº¦
CONSECUTIVE_ERROR_THRESHOLD = 10  # é€£ç¶šã‚¨ãƒ©ãƒ¼ã®æœ€å¤§è¨±å®¹æ•° (å€¤ã‚’å¢—åŠ )
ERROR_RATE_THRESHOLD = 0.8  # ã‚¨ãƒ©ãƒ¼ç‡ã®è¨±å®¹é–¾å€¤ï¼ˆ80%ã«å¢—åŠ ï¼‰
MIN_SAMPLES_BEFORE_CHECK = 20  # ã‚¨ãƒ©ãƒ¼ç‡ãƒã‚§ãƒƒã‚¯å‰ã®æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•° (å¢—åŠ )
ENABLE_AUTO_HALT = True  # è‡ªå‹•åœæ­¢æ©Ÿèƒ½ã®æœ‰åŠ¹/ç„¡åŠ¹
# â˜…â˜…â˜… ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã‚’æœ‰åŠ¹åŒ–ã—ã¦é«˜é€ŸåŒ– â˜…â˜…â˜…
HEADLESS_MODE = False # Trueã«ã™ã‚‹ã¨ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ
PAGE_LOAD_TIMEOUT = 30 # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“åŠæ¸› (60â†’30ç§’)
ELEMENT_WAIT_TIMEOUT = 5 # è¦ç´ å¾…æ©Ÿæ™‚é–“åŠæ¸› (90â†’45ç§’)
# â˜…â˜…â˜… å¾…æ©Ÿæ™‚é–“ã‚’å¤§å¹…çŸ­ç¸® â˜…â˜…â˜…
SHORT_WAIT = 0.01 # çŸ­ã„å¾…æ©Ÿæ™‚é–“ã‚’çŸ­ç¸® (1.0â†’0.3ç§’)
MEDIUM_WAIT = 0.1 # ä¸­ç¨‹åº¦ã®å¾…æ©Ÿæ™‚é–“ã‚’çŸ­ç¸® (1.3â†’0.5ç§’)
LONG_WAIT = 0.1 # é•·ã„å¾…æ©Ÿæ™‚é–“ã‚’çŸ­ç¸® (1.5â†’0.7ç§’)
# â˜…â˜…â˜… è‹±èªãƒšãƒ¼ã‚¸ã§ã®JSãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°å¾…æ©Ÿæ™‚é–“çŸ­ç¸® â˜…â˜…â˜…
JS_RENDER_WAIT = 0.0 # ç§’ (å¤§å¹…çŸ­ç¸® 1.0â†’0.3ç§’)

# --- â˜… ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤–ã‚¯ãƒ©ã‚¹ â˜… ---
class MissingCriticalDataError(Exception):
    """å¿…é ˆãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯å®šç¾©æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã‹ã£ãŸå ´åˆã«ç™ºç”Ÿã•ã›ã‚‹ä¾‹å¤–"""
    pass

# --- XPathå®šç¾© ---

# === æ—¥æœ¬èªãƒšãƒ¼ã‚¸ç”¨ XPath ===
# â˜…â˜…â˜… 2025å¹´ä»¥é™ç”¨ (æ—¥æœ¬èª) â˜…â˜…â˜…
INFO_MAP_JA_2025 = {
    'name': ("ç§‘ç›®å", "//h2[@class='class-name']", "åç§°ä¸æ˜"),
    'semester': ("å­¦æœŸ", "//tr[th[normalize-space()='å¹´åº¦ãƒ»å­¦æœŸ']]/td", "å­¦æœŸä¸æ˜"),
    'professor': ("æ‹…å½“è€…å", "//tr[th[contains(text(),'æ‹…å½“è€…å')]]/td", ""),
    'credits': ("å˜ä½", "//tr[th[contains(text(),'å˜ä½')]]/td", "å˜ä½ä¸æ˜"),
    'field': ("åˆ†é‡", "//tr[th[contains(text(),'åˆ†é‡')]]/td", "åˆ†é‡ä¸æ˜"),
    'location': ("æ•™å®¤", "//tr[th[contains(text(),'æ•™å®¤') or contains(text(),'é–‹è¬›å ´æ‰€')]]/td", "æ•™å®¤ä¸æ˜"),
    'day_period': ("æ›œæ—¥æ™‚é™", "//tr[th[contains(text(),'æ›œæ—¥æ™‚é™')]]/td", "æ›œæ—¥æ™‚é™ä¸æ˜"), # æ›œæ—¥æ™‚é™ã®XPath
    'selection_method': ("é¸æŠœæ–¹æ³•", "//tr[th[contains(text(),'é¸æŠœæ–¹æ³•')]]/td", ""), # é¸æŠœæ–¹æ³•ã®XPath
    'class_format': ("æˆæ¥­å®Ÿæ–½å½¢æ…‹", "//tr[th[contains(text(),'æˆæ¥­å®Ÿæ–½å½¢æ…‹')]]/td", ""),
    'course_id_fallback': ("ç™»éŒ²ç•ªå·(è¡¨)", "//tr[th[normalize-space()='ç™»éŒ²ç•ªå·']]/td", None)
}

INFO_MAP_JA_2023_2024 = {
    'name': ("ç§‘ç›®å", "//h2/span[@class='title']", "åç§°ä¸æ˜"),
    'semester': ("å­¦æœŸ", "//div[contains(@class,'syllabus-info')]//dl/dt[normalize-space()='é–‹è¬›å¹´åº¦ãƒ»å­¦æœŸ']/following-sibling::dd[1]", "å­¦æœŸä¸æ˜"),
    'professor': ("æ‹…å½“è€…å", "//div[contains(@class,'syllabus-info')]//dl/dt[normalize-space()='æˆæ¥­æ•™å“¡å']/following-sibling::dd[1]", ""),
    'credits': ("å˜ä½", "//div[contains(@class,'subject')]//dl/dt[normalize-space()='å˜ä½']/following-sibling::dd[1]", "å˜ä½ä¸æ˜"),
    'field': ("åˆ†é‡", "//div[contains(@class,'subject')]//dl/dt[normalize-space()='åˆ†é‡']/following-sibling::dd[1]", "åˆ†é‡ä¸æ˜"),
    'location': ("æ•™å®¤", "//div[contains(@class,'syllabus-info')]//dl/dt[normalize-space()='é–‹è¬›å ´æ‰€']/following-sibling::dd[1]", "æ•™å®¤ä¸æ˜"),
    'day_period': ("æ›œæ—¥æ™‚é™", "//div[contains(@class,'syllabus-info')]//dl/dt[normalize-space()='æ›œæ—¥ãƒ»æ™‚é™']/following-sibling::dd[1]", "æ›œæ—¥æ™‚é™ä¸æ˜"),
    'selection_method': ("é¸æŠœæ–¹æ³•", "//div[contains(@class,'subject')]//dl/dt[normalize-space()='é¸æŠœæ–¹æ³•']/following-sibling::dd[1]", ""),
    'class_format': ("æˆæ¥­å®Ÿæ–½å½¢æ…‹", "//div[contains(@class,'syllabus-info')]//dl/dt[normalize-space()='å®Ÿæ–½å½¢æ…‹']/following-sibling::dd[1]", ""),
    'course_id_fallback': ("ç™»éŒ²ç•ªå·(è¡¨)", "//div[contains(@class,'subject')]//dl/dt[normalize-space()='ç™»éŒ²ç•ªå·']/following-sibling::dd[1]", None)
}

# === â˜…â˜…â˜… è‹±èªãƒšãƒ¼ã‚¸ç”¨ XPath (å†å®šç¾©) â˜…â˜…â˜… ===
# â˜…â˜…â˜… 2025å¹´ä»¥é™ç”¨ (è‹±èª) - ãƒ­ã‚°ã®HTMLã«åŸºã¥ã„ã¦ä¿®æ­£ â˜…â˜…â˜…
INFO_MAP_EN_2025 = {
    'name': ("Course Title", "//h2[@class='class-name']", "Name Unknown"),
    'semester': ("Year/Semester", "//tr[th[normalize-space()='Academic Year/Semester']]/td", "Semester Unknown"),
    'professor': ("Lecturer(s)", "//tr[th[normalize-space()='Lecturer(s)']]/td", ""), # HTMLã§ã¯Lecturer(s)ã ã£ãŸ
    'credits': ("Credits", "//tr[th[normalize-space()='Credit(s)']]/td", "Credits Unknown"),
    'field': ("Field", "//tr[th[normalize-space()='Field']]/td", "Field Unknown"),
    'location': ("Classroom", "//tr[th[normalize-space()='Classroom']]/td", "Classroom Unknown"),
    'day_period': ("Day/Period", "//tr[th[normalize-space()='Day/Period']]/td", "Day/Period Unknown"), # æ›œæ—¥æ™‚é™ã®XPath (è‹±)
    'selection_method': ("Selection Method", "//tr[th[normalize-space()='Selection Method']]/td", ""), # Changed from 'Lottery Method'
    'class_format': ("Class Format", "//tr[th[normalize-space()='Class Format']]/td", ""),
    'course_id_fallback': ("Registration Number", "//tr[th[normalize-space()='Registration Number']]/td", None)
}

INFO_MAP_EN_2023_2024 = {
    'name': ("Course Title", "//h2/span[@class='title']", "Name Unknown"),
    'semester': ("Year/Semester", "//div[contains(@class,'syllabus-info')]//dl/dt[normalize-space()='Year/Semester']/following-sibling::dd[1]", "Semester Unknown"),
    'professor': ("Lecturer(s)", "//div[contains(@class,'syllabus-info')]//dl/dt[normalize-space()='Lecturer Name']/following-sibling::dd[1]", ""),
    'credits': ("Credits", "//div[contains(@class,'subject')]//dl/dt[normalize-space()='Unit']/following-sibling::dd[1]", "Credits Unknown"),
    'field': ("Field", "//div[contains(@class,'subject')]//dl/dt[normalize-space()='Field']/following-sibling::dd[1]", "Field Unknown"),
    'location': ("Classroom", "//div[contains(@class,'syllabus-info')]//dl/dt[normalize-space()='Location']/following-sibling::dd[1]", "Classroom Unknown"),
    'day_period': ("Day/Period", "//div[contains(@class,'syllabus-info')]//dl/dt[normalize-space()='Day of Weekãƒ»Period']/following-sibling::dd[1]", "Day/Period Unknown"),
    'selection_method': ("Selection Method", "//div[contains(@class,'subject')]//dl/dt[normalize-space()='Selection Method']/following-sibling::dd[1]", ""),
    'class_format': ("Class Format", "//div[contains(@class,'syllabus-info')]//dl/dt[contains(text(),'Class Format')]/following-sibling::dd[1]", ""),
    'course_id_fallback': ("Registration Number", "//div[contains(@class,'subject')]//dl/dt[normalize-space()='Course Registration Number']/following-sibling::dd[1]", None)
}


# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---

def create_output_dirs(base_dir=OUTPUT_DIR_NAME):
    """å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã™ã‚‹"""
    logs_dir = os.path.join(base_dir, "logs")
    screenshots_dir = os.path.join(base_dir, "screenshots")
    for dir_path in [base_dir, logs_dir, screenshots_dir]:
        os.makedirs(dir_path, exist_ok=True)
    return base_dir, logs_dir, screenshots_dir

# é«˜é€ŸåŒ–ç‰ˆé–¢æ•°ç¾¤

def save_screenshot(driver, prefix="screenshot", dir_path="screenshots"):
    """ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜ã™ã‚‹ - é‡è¦ãªã‚¨ãƒ©ãƒ¼ã®ã¿"""
    # é‡è¦ãªã‚¨ãƒ©ãƒ¼ã®ã¿ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ
    if "critical" not in prefix and "error" not in prefix:
        return None  # Skip non-critical screenshots
    try:
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"{prefix}_{timestamp}.png"
        filepath = os.path.join(dir_path, filename)
        driver.save_screenshot(filepath)
        return filepath
    except:
        return None

def get_text_by_xpath(driver, xpath, default=""):
    """XPathã§è¦ç´ ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ (æœ€é©åŒ–ç‰ˆ)"""
    if not xpath:
        return default
    try:
        # Use JavaScript for faster text extraction
        js_script = """
            var element = document.evaluate(arguments[0], document, null, 
                        XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;
            return element ? element.textContent : "";
        """
        result = driver.execute_script(js_script, xpath)
        return normalize_text(result) if result else default
    except:
        # Fallback to traditional method
        try:
            element = driver.find_element(By.XPATH, xpath)
            return normalize_text(element.text) if element.text else default
        except:
            return default

def get_multiple_elements_text(driver, xpaths_dict):
    """Multiple XPaths to text values in a single JS call"""
    js_script = """
        function getTexts(xpaths) {
            var results = {};
            for (var key in xpaths) {
                try {
                    var element = document.evaluate(xpaths[key], document, null, 
                                XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;
                    results[key] = element ? element.textContent.trim() : "";
                } catch(e) {
                    results[key] = "";
                }
            }
            return results;
        }
        return getTexts(arguments[0]);
    """
    try:
        # Create dictionary of only xpath values
        xpath_values = {k: v[1] for k, v in xpaths_dict.items() if k != 'course_id_fallback'}
        results = driver.execute_script(js_script, xpath_values)
        
        # Apply normalization
        for key in results:
            results[key] = normalize_text(results[key])
            
        return results
    except:
        # Fallback to traditional method
        return {k: get_text_by_xpath(driver, v[1], v[2]) 
                for k, v in xpaths_dict.items() if k != 'course_id_fallback'}


def process_single_url(syllabus_url, year, screenshots_dir, opened_links_this_year_field, auth_cookies=None):
    """Thread-safe URL processing with shared authentication and proper tab management"""
    # Add timing tracking
    url_start_time = time.time()
    course_id = "unknown"
    
    try:
        # Use the global driver instance
        driver = globals()['driver']
        
        print(f"\n[{time.strftime('%H:%M:%S')}] ğŸ” Processing URL: {syllabus_url}")
        
        # Skip search pages and other non-syllabus URLs
        if "syllabus/search" in syllabus_url or (not any(x in syllabus_url for x in ["detail", "entno=", "courses/"])):
            print(f"[{time.strftime('%H:%M:%S')}] âš ï¸ Skipping non-syllabus URL: {syllabus_url}")
            return None
        
        # Save the main window handle (search results page)
        main_window = driver.current_window_handle
        
        # Open syllabus in a new tab instead of navigating in the same tab
        print(f"[{time.strftime('%H:%M:%S')}] ğŸ“„ Opening syllabus page in new tab")
        initial_handles = set(driver.window_handles)
        driver.execute_script(f"window.open('{syllabus_url}', '_blank');")
        WebDriverWait(driver, MEDIUM_WAIT * 2).until(lambda d: len(d.window_handles) > len(initial_handles))
        new_handles = set(driver.window_handles) - initial_handles
        
        if not new_handles:
            raise Exception("Failed to get handle for the new tab")
            
        # Switch to the new tab
        tab_handle = list(new_handles)[0]
        driver.switch_to.window(tab_handle)
        time.sleep(SHORT_WAIT)
        
        # Process the URL
        print(f"[{time.strftime('%H:%M:%S')}] ğŸ“Š Extracting syllabus details")
        details = get_syllabus_details(driver, year, screenshots_dir)
        
        # Get course ID and name for better logging
        if details:
            course_id = details.get('course_id', 'unknown')
            course_name = details.get('translations', {}).get('ja', {}).get('name', 'Unknown')
            professor = details.get('professor_ja', 'Unknown')
            field = details.get('field_ja', 'Unknown')
        
        # Close the tab and switch back to main window (search results)
        print(f"[{time.strftime('%H:%M:%S')}] ğŸ”™ Returning to search results page")
        driver.close()
        driver.switch_to.window(main_window)
        time.sleep(MEDIUM_WAIT)  # Give time to ensure we're back on the search page
        
        # Calculate and report elapsed time
        elapsed_time = time.time() - url_start_time
        
        if details:
            print(f"[{time.strftime('%H:%M:%S')}] âœ… SUCCESS ({elapsed_time:.2f}s): ID:{course_id} | {course_name} | Prof:{professor} | Field:{field}")
        else:
            print(f"[{time.strftime('%H:%M:%S')}] âŒ FAILED ({elapsed_time:.2f}s): {syllabus_url}")
            
        return details

    except Exception as e:
        # Calculate elapsed time even for errors
        elapsed_time = time.time() - url_start_time
        print(f"[{time.strftime('%H:%M:%S')}] âŒ ERROR ({elapsed_time:.2f}s): {str(e)} | URL: {syllabus_url}")
        
        # Try to return to the main window if we're in a different tab
        try:
            current_handle = driver.current_window_handle
            if 'main_window' in locals() and current_handle != main_window:
                driver.close()
                driver.switch_to.window(main_window)
                time.sleep(MEDIUM_WAIT)
        except Exception as e_recovery:
            print(f"[{time.strftime('%H:%M:%S')}] âš ï¸ Error during tab recovery: {str(e_recovery)}")
            
        return None
    

def select_option_by_text(driver, select_element, text):
    """ã‚»ãƒ¬ã‚¯ãƒˆè¦ç´ ã‹ã‚‰æŒ‡å®šã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’é¸æŠã™ã‚‹ (æœ€é©åŒ–ç‰ˆ)"""
    try:
        # JavaScriptã§ç›´æ¥é¸æŠ (é«˜é€ŸåŒ–)
        js_script = """
            // é«˜é€Ÿã‚»ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
            let found = false;
            let select = arguments[0];
            let targetText = arguments[1];
            
            // ã¾ãšå®Œå…¨ä¸€è‡´ã‚’è©¦ã™ï¼ˆæœ€é€Ÿï¼‰
            for(let i = 0; i < select.options.length; i++) {
                if(select.options[i].text.trim() === targetText) {
                    select.selectedIndex = i;
                    select.dispatchEvent(new Event('change', {bubbles:true}));
                    return true;
                }
            }
            
            // éƒ¨åˆ†ä¸€è‡´ã‚’è©¦ã™
            for(let i = 0; i < select.options.length; i++) {
                if(select.options[i].text.trim().includes(targetText)) {
                    select.selectedIndex = i;
                    select.dispatchEvent(new Event('change', {bubbles:true}));
                    return true;
                }
            }
            
            return false;
        """
        result = driver.execute_script(js_script, select_element, text)
        if result:
            return True
            
        # JavaScriptã§å¤±æ•—ã—ãŸå ´åˆã®ã¿Seleniumã‚’è©¦ã™
        # å…ƒã®ã‚³ãƒ¼ãƒ‰ã‚’æ®‹ã‚Šã¨ã—ã¦ä½¿ç”¨
        
        return False
    except Exception:
        return False

def normalize_text(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–ã™ã‚‹ (å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã‚’åŠè§’ã«ã€é€£ç¶šç©ºç™½ã‚’1ã¤ã«)"""
    if isinstance(text, str):
        text = text.replace('ã€€', ' ')
        text = re.sub(r'\s+', ' ', text)
        return text.strip()
    return ""

def normalize_field(field_text):
    """åˆ†é‡è¡¨è¨˜ã‚’æ­£è¦åŒ–ã™ã‚‹"""
    if not field_text:
        return field_text
        
    # å…ˆç«¯ç§‘ç›®ç’°å¢ƒæƒ…å ±ç³» â†’ å…ˆç«¯ç§‘ç›®-ç’°å¢ƒæƒ…å ±ç³»
    if 'å…ˆç«¯ç§‘ç›®' in field_text and '-' not in field_text:
        # Find where the prefix ends and add the hyphen
        for i in range(len('å…ˆç«¯ç§‘ç›®'), len(field_text)):
            if field_text[i] in 'ç’°å…ˆç·æ”¿æƒ…çµŒ':  # Common first characters of field names
                return field_text[:i] + '-' + field_text[i:]
    return field_text

def normalize_credits(credits_text, language='en'):
    """å˜ä½è¡¨è¨˜ã‚’æ­£è¦åŒ–ã™ã‚‹"""
    if not credits_text:
        return credits_text
        
    # Extract just the number using regex
    number_match = re.search(r'\d+', credits_text)
    if not number_match:
        return credits_text  # If no number found, return as-is
    
    number = number_match.group()
    
    # Format according to language
    if language == 'en':
        return f"{number} Credits"
    else:  # Japanese
        return f"{number}å˜ä½"

def parse_professor_names(ja_names_text, en_names_text=None):
    """æ•™æˆåã‚’ã‚»ãƒŸã‚³ãƒ­ãƒ³ã§åŒºåˆ‡ã£ã¦æ­£ã—ããƒ‘ãƒ¼ã‚¹ã—ã€æ—¥è‹±ã®åå‰ã‚’å¯¾å¿œä»˜ã‘ã‚‹"""
    ja_names = []
    en_names = []
    
    # Parse Japanese names
    if ja_names_text:
        if ';' in ja_names_text:
            ja_names = [name.strip() for name in ja_names_text.split(';') if name.strip()]
        else:
            ja_names = [name.strip() for name in ja_names_text.split(',') if name.strip()]
            # If there's only one entry but it has a space (like "ä¸€ãƒç€¬ å‹åš"), treat it as one name
            if len(ja_names) == 1 and ' ' in ja_names[0]:
                ja_names = [ja_names[0]]
    
    # Parse English names
    if en_names_text:
        if ';' in en_names_text:
            en_names = [name.strip() for name in en_names_text.split(';') if name.strip()]
        else:
            # For English names with format "LASTNAME, FIRSTNAME"
            # we need special handling to avoid splitting a single name
            if ',' in en_names_text and ';' not in en_names_text:
                # Try to detect if this is multiple professors or just one with lastname, firstname format
                comma_parts = en_names_text.split(',')
                if len(comma_parts) == 2 and not any(p.strip().isupper() for p in comma_parts):
                    # Likely a single name in "Lastname, Firstname" format
                    en_names = [en_names_text.strip()]
                else:
                    # Multiple names separated by commas
                    en_names = [name.strip() for name in comma_parts if name.strip()]
            else:
                en_names = [en_names_text.strip()]
    
    # Match names or use defaults
    num_ja_names = len(ja_names)
    num_en_names = len(en_names)
    
    # Create pairs of names
    professors = []
    for i in range(max(num_ja_names, num_en_names)):
        ja_name = ja_names[i] if i < num_ja_names else ""
        en_name = en_names[i] if i < num_en_names else ja_name
        
        professors.append({
            "ja": ja_name,
            "en": en_name
        })
    
    return professors
    return professors

def click_element(driver, element, wait_time=SHORT_WAIT):
    """è¦ç´ ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ (å…ƒã®é«˜é€Ÿç‰ˆ)"""
    try:
        element.click()
        return True
    except ElementClickInterceptedException:
        # è¦ç´ ãŒéš ã‚Œã¦ã„ã‚‹å ´åˆã¯JSã‚¯ãƒªãƒƒã‚¯
        try:
            driver.execute_script("arguments[0].click();", element)
            return True
        except:
            return False
    except:
        return False


def generate_english_url(current_url):
    """ç¾åœ¨ã®URLã« lang=en ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ /ç½®æ›ã—ã¦è‹±èªãƒšãƒ¼ã‚¸ã®URLã‚’ç”Ÿæˆã™ã‚‹"""
    try:
        parsed_url = urlparse(current_url)
        query_params = parse_qs(parsed_url.query)
        query_params['lang'] = ['en'] # langãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’enã«è¨­å®šï¼ˆå­˜åœ¨ã™ã‚Œã°ä¸Šæ›¸ãï¼‰
        new_query = urlencode(query_params, doseq=True) # ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—ã‚’å†æ§‹ç¯‰
        # æ–°ã—ã„ã‚¯ã‚¨ãƒªã§URLã‚’å†æ§‹ç¯‰
        english_url = urlunparse((
            parsed_url.scheme, parsed_url.netloc, parsed_url.path,
            parsed_url.params, new_query, parsed_url.fragment
        ))
        return english_url
    except Exception as e:
        print(f"     [è­¦å‘Š] è‹±èªURLã®ç”Ÿæˆã«å¤±æ•—: {e}ã€‚å…ƒã®URLã‚’è¿”ã—ã¾ã™: {current_url}")
        return current_url

# --- â˜…â˜…â˜… è¿½åŠ : å­¦æœŸæŠ½å‡ºãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° â˜…â˜…â˜… ---
def extract_season(semester_text):
    """å­¦æœŸæ–‡å­—åˆ—ã‹ã‚‰å­£ç¯€ ("spring", "fall", "full year", "summer", "winter", "unknown") ã‚’æŠ½å‡ºã™ã‚‹"""
    if not isinstance(semester_text, str):
        return "unknown"

    text_lower = semester_text.lower()

    # è‹±èªã®å­£ç¯€ã‚’å„ªå…ˆ
    if "spring" in text_lower: return "spring"
    if "fall" in text_lower or "autumn" in text_lower: return "fall"
    if "summer" in text_lower: return "summer" # Summerã‚‚è€ƒæ…®
    if "winter" in text_lower: return "winter" # Winterã‚‚è€ƒæ…®
    if "full year" in text_lower or "é€šå¹´" in semester_text: return "full year" # é€šå¹´ã‚‚è€ƒæ…®

    # æ—¥æœ¬èªã®å­£ç¯€
    if "æ˜¥" in semester_text: return "spring"
    if "ç§‹" in semester_text: return "fall"
    if "å¤" in semester_text: return "summer"
    if "å†¬" in semester_text: return "winter"

    # ã©ã¡ã‚‰ã§ã‚‚ãªã‘ã‚Œã°ä¸æ˜
    return "unknown"

def is_error_page(driver):
    """
    æ¤œå‡ºã—ãŸãƒšãƒ¼ã‚¸ãŒã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ã‹ã©ã†ã‹ã‚’ç¢ºèªã™ã‚‹
    """
    try:
        # ã‚¿ã‚¤ãƒˆãƒ«ãƒã‚§ãƒƒã‚¯
        page_title = driver.title
        if "Error" in page_title or "404" in page_title:
            print("           [æƒ…å ±] ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return True
            
        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ¤œå‡º
        error_messages = [
            "//h1[contains(text(), 'Error')]",
            "//p[contains(text(), 'ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')]",
            "//p[contains(text(), 'Page Not Found')]",
            "//div[contains(text(), 'ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')]",
            "//div[contains(text(), 'Page Not Found')]"
        ]
        
        for xpath in error_messages:
            try:
                elements = driver.find_elements(By.XPATH, xpath)
                if elements and any(element.is_displayed() for element in elements):
                    print(f"           [æƒ…å ±] ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ¤œå‡ºã—ã¾ã—ãŸ: {xpath}")
                    return True
            except Exception:
                continue
                
        # URLãƒã‚§ãƒƒã‚¯
        current_url = driver.current_url
        if "error" in current_url.lower() or "appMsg" in current_url:
            print(f"           [æƒ…å ±] ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ã®URLãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º: {current_url}")
            return True
            
        return False
    except Exception as e:
        print(f"           [è­¦å‘Š] ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ãƒã‚§ãƒƒã‚¯ä¸­ã«ä¾‹å¤–ãŒç™ºç”Ÿ: {e}")
        return False

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå†…ã§ç‰¹å®šã®URLã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹å ´åˆã«è¿½åŠ ã§ãã‚‹ãƒ‡ãƒãƒƒã‚°ã‚³ãƒ¼ãƒ‰

def test_error_page_detection(driver, test_url):
    """
    ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸æ¤œå‡ºæ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹é–¢æ•°
    """
    print(f"\n=== ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸æ¤œå‡ºãƒ†ã‚¹ãƒˆé–‹å§‹: {test_url} ===")
    try:
        # URLã«ç§»å‹•
        driver.get(test_url)
        WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.presence_of_element_located((By.TAG_NAME, "body")))
        # time.sleepå‰Šé™¤ - å³æ™‚å‡¦ç†ã«å¤‰æ›´
        
        # ãƒšãƒ¼ã‚¸æƒ…å ±å‡ºåŠ›
        print(f"ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«: {driver.title}")
        print(f"URL: {driver.current_url}")
        
        # ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸æ¤œå‡ºãƒ†ã‚¹ãƒˆ
        is_error = is_error_page(driver)
        print(f"ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸åˆ¤å®šçµæœ: {'ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ã§ã™' if is_error else 'ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ã§ã¯ã‚ã‚Šã¾ã›ã‚“'}")
        
        # ãƒšãƒ¼ã‚¸ã®HTMLæ§‹é€ ã‚’ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
        try:
            h1_elements = driver.find_elements(By.TAG_NAME, "h1")
            print(f"H1è¦ç´ æ•°: {len(h1_elements)}")
            for i, el in enumerate(h1_elements):
                print(f"  H1 #{i+1}: {el.text}")
            
            p_elements = driver.find_elements(By.TAG_NAME, "p")
            print(f"pè¦ç´ æ•°: {len(p_elements)}")
            for i, el in enumerate(p_elements[:5]):  # æœ€åˆã®5ã¤ã ã‘è¡¨ç¤º
                print(f"  p #{i+1}: {el.text}")
            
            # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«é–¢é€£ã™ã‚‹è¦ç´ ã‚’ç‰¹å®š
            print("\nã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é–¢é€£è¦ç´ :")
            error_selectors = [
                "//h1[contains(text(), 'Error')]",
                "//p[contains(text(), 'ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')]",
                "//p[contains(text(), 'Page Not Found')]",
                "//div[contains(text(), 'ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')]",
                "//div[contains(text(), 'Page Not Found')]"
            ]
            
            for selector in error_selectors:
                elements = driver.find_elements(By.XPATH, selector)
                if elements:
                    print(f"  {selector}: {len(elements)}å€‹ã®è¦ç´ ã‚’æ¤œå‡º")
                    for i, el in enumerate(elements):
                        print(f"    è¦ç´  #{i+1}: {el.text}, è¡¨ç¤ºçŠ¶æ…‹: {el.is_displayed()}")
                else:
                    print(f"  {selector}: è©²å½“è¦ç´ ãªã—")
            
        except Exception as e:
            print(f"HTMLæ§‹é€ å‡ºåŠ›ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        
    except Exception as e:
        print(f"ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        traceback.print_exc()
    
    print("=== ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸æ¤œå‡ºãƒ†ã‚¹ãƒˆçµ‚äº† ===\n")
    return

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¾‹
# test_error_page_detection(driver, "https://syllabus.sfc.keio.ac.jp/error")

def save_checkpoint(year, field_name, page_num, processed_urls):
    """é€²æ—çŠ¶æ³ã‚’ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹"""
    checkpoint = {
        'year': year,
        'field_name': field_name,
        'page_num': page_num,
        'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'processed_urls': list(processed_urls)  # setã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›
    }
    
    checkpoint_file = os.path.join(OUTPUT_DIR_NAME, 'checkpoint.pkl')
    with open(checkpoint_file, 'wb') as f:
        pickle.dump(checkpoint, f)
    print(f"\n[æƒ…å ±] ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜: å¹´åº¦={year}, åˆ†é‡={field_name}, ãƒšãƒ¼ã‚¸={page_num}, URLæ•°={len(processed_urls)}")

def load_checkpoint():
    """æœ€å¾Œã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’èª­ã¿è¾¼ã‚€ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰"""
    checkpoint_file = os.path.join(OUTPUT_DIR_NAME, 'checkpoint.pkl')
    if os.path.exists(checkpoint_file):
        try:
            with open(checkpoint_file, 'rb') as f:
                checkpoint = pickle.load(f)
            print(f"\n[æƒ…å ±] ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­è¾¼: å¹´åº¦={checkpoint['year']}, åˆ†é‡={checkpoint['field_name']}, "
                  f"ãƒšãƒ¼ã‚¸={checkpoint['page_num']}, ä¿å­˜æ—¥æ™‚={checkpoint['timestamp']}")
            return checkpoint
        except Exception as e:
            print(f"\n[è­¦å‘Š] ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆèª­è¾¼å¤±æ•—: {e}")
    return None

def get_syllabus_details(driver, current_year, screenshots_dir):
    """
    ã‚·ãƒ©ãƒã‚¹è©³ç´°ãƒšãƒ¼ã‚¸ã‹ã‚‰æŒ‡å®šã•ã‚ŒãŸæ—¥æœ¬èªã¨è‹±èªã®æƒ…å ±ã‚’å–å¾—ã€‚
    æ—¥æœ¬èªãƒšãƒ¼ã‚¸ã¨è‹±èªãƒšãƒ¼ã‚¸ã‚’å€‹åˆ¥ã«å‡¦ç†ã—ã€ãã‚Œãã‚Œã®è¨€èªã®æƒ…å ±ã‚’æ ¼ç´ã™ã‚‹ã€‚
    å¹´åº¦ã¨ã‚·ã‚¹ãƒ†ãƒ ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦é©åˆ‡ãªXPathãƒãƒƒãƒ—ã‚’ä½¿ç”¨ã™ã‚‹ã€‚
    """
    # Add timer for detailed logging
    detail_start_time = time.time()
    
    ja_data = {}  # æ—¥æœ¬èªãƒšãƒ¼ã‚¸ã‹ã‚‰å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿
    en_data = {}  # è‹±èªãƒšãƒ¼ã‚¸ã‹ã‚‰å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿
    course_id = None
    japanese_url = "N/A"
    english_url = "N/A"  # è‹±èªURLã‚‚åˆæœŸåŒ–

    # â˜…â˜…â˜… ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ  â˜…â˜…â˜…
    print(f"    [{time.strftime('%H:%M:%S')}] ğŸ” Checking for error page")
    if is_error_page(driver):
        print(f"    [{time.strftime('%H:%M:%S')}] âš ï¸ Error page detected, skipping")
        save_screenshot(driver, f"error_page_detected_{current_year}", screenshots_dir)
        return None

    # ã‚·ã‚¹ãƒ†ãƒ ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š
    current_url = driver.current_url
    is_old_system = "syllabus.sfc.keio.ac.jp" in current_url
    is_new_system = "gslbs.keio.jp" in current_url
    
    if is_old_system or (current_year <= 2024 and not is_new_system):
        print(f"    [{time.strftime('%H:%M:%S')}] ğŸ“‹ Processing old system syllabus (pre-2024)")
        # æ—§ã‚·ã‚¹ãƒ†ãƒ ç”¨ã®XPathå®šç¾©ï¼ˆSFC 2024å¹´å¯¾å¿œç‰ˆï¼‰
        ja_map_to_use = INFO_MAP_JA_2023_2024.copy()  # Use the 2023/2024 mapping
        en_map_to_use = INFO_MAP_EN_2023_2024.copy()  # Use the 2023/2024 mapping
    else:
        print(f"    [{time.strftime('%H:%M:%S')}] ğŸ“‹ Processing new system syllabus (2025+)")
        # æ–°ã‚·ã‚¹ãƒ†ãƒ ç”¨ã®XPathå®šç¾©ï¼ˆ2025å¹´ä»¥é™ç”¨ï¼‰
        ja_map_to_use = INFO_MAP_JA_2025.copy()
        en_map_to_use = INFO_MAP_EN_2025.copy()

# --- Course ID å–å¾— ---
        print(f"    [{time.strftime('%H:%M:%S')}] ğŸ”¢ Extracting course ID")
        try:
            # æ—§ã‚·ã‚¹ãƒ†ãƒ ã¨æ–°ã‚·ã‚¹ãƒ†ãƒ ã§ç•°ãªã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨
            if is_old_system or current_year <= 2024:
                # æ—§ã‚·ã‚¹ãƒ†ãƒ ç”¨ã®ã‚³ãƒ¼ã‚¹IDå–å¾—ãƒ‘ã‚¿ãƒ¼ãƒ³
                id_match = re.search(r'/courses/\d+_(\d+)', current_url) or \
                        re.search(r'\?id=(\d+)', current_url)
            else:
                # æ–°ã‚·ã‚¹ãƒ†ãƒ ç”¨ã®ã‚³ãƒ¼ã‚¹IDå–å¾—ãƒ‘ã‚¿ãƒ¼ãƒ³ - 2025 format
                id_match = re.search(r'[?&](?:id|entno)=(\d+)', current_url) or \
                        re.search(r'/courses/\d+_(\d+)', current_url) or \
                        re.search(r'/syllabus/(\d+)', current_url) or \
                        re.search(r'ttblyr=\d+&entno=(\d+)', current_url) 
                
            if id_match:
                course_id = id_match.group(1)
            else:
                course_id_xpath = ja_map_to_use.get('course_id_fallback', [None, None])[1]
                if course_id_xpath:
                    print(f"               URLã‹ã‚‰IDå–å¾—å¤±æ•—ã€‚XPathã§è©¦è¡Œ: {course_id_xpath}")
                    reg_num = get_text_by_xpath(driver, course_id_xpath)
                    if reg_num and reg_num.isdigit():
                        course_id = reg_num
                    else:
                        try:
                            hidden_elements = driver.find_elements(By.XPATH, "//input[@type='hidden' and (contains(@name, 'id') or contains(@name, 'entno'))]")
                            for hidden in hidden_elements:
                                value = hidden.get_attribute('value')
                                if value and value.isdigit():
                                    course_id = value
                                    print(f"               éš ã—è¦ç´ ã‹ã‚‰IDå–å¾—: {value}")
                                    break
                        except Exception: pass
        except Exception as e:
            print(f"    [{time.strftime('%H:%M:%S')}] âš ï¸ Error during Course ID extraction: {e}")

        if course_id:
            print(f"    [{time.strftime('%H:%M:%S')}] âœ… Course ID found: {course_id}")
        else:
            print(f"    [{time.strftime('%H:%M:%S')}] âš ï¸ Failed to find Course ID, trying alternative methods")

        if not course_id:
            print(f"    [{time.strftime('%H:%M:%S')}] âŒ Critical: Failed to find Course ID")
            raise MissingCriticalDataError(f"å¿…é ˆãƒ‡ãƒ¼ã‚¿(Course ID)ã®å–å¾—ã«å¤±æ•— (URL: {japanese_url})")
        print(f"               Course ID: {course_id}")

        # --- æ—¥æœ¬èªæƒ…å ±å–å¾—ãƒ«ãƒ¼ãƒ— ---
        print(f"    [{time.strftime('%H:%M:%S')}] ğŸ“ Extracting Japanese syllabus data")
        name_default_ja = f"åç§°ä¸æ˜-{course_id}"
        name_tuple_ja = ja_map_to_use['name']
        ja_map_to_use['name'] = (name_tuple_ja[0], name_tuple_ja[1], name_default_ja)

        INVALID_COURSE_NAME_PATTERNS = ["æ…¶æ‡‰ç¾©å¡¾å¤§å­¦ ã‚·ãƒ©ãƒã‚¹ãƒ»æ™‚é–“å‰²", "SFC Course Syllabus"]
        critical_data_missing_ja = False  # æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ç”¨ã®ãƒ•ãƒ©ã‚°
        missing_details_ja = []  # æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ç”¨ã®ãƒªã‚¹ãƒˆ

        print("           --- æ—¥æœ¬èªæƒ…å ±å–å¾—é–‹å§‹ ---")
        for key, (label, xpath, default_value, *_) in ja_map_to_use.items():
            if key == 'course_id_fallback': continue
            ja_data[key] = get_text_by_xpath(driver, xpath, default_value)

            # å¿…é ˆãƒã‚§ãƒƒã‚¯ (TTCK/Onlineå‡¦ç†å‰)
            optional_keys = ['professor', 'selection_method', 'class_format', 'location', 'day_period'] 
            if key not in optional_keys:
                if key == 'name':
                    if ja_data[key] == default_value or any(pattern in ja_data[key] for pattern in INVALID_COURSE_NAME_PATTERNS):
                        critical_data_missing_ja = True
                        missing_details_ja.append(f"{label}(ja): ä¸é©åˆ‡ã€Œ{ja_data[key]}ã€")
                elif ja_data[key] == default_value or not ja_data[key]:
                    if xpath:  # XPathãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿ã‚¨ãƒ©ãƒ¼å¯¾è±¡
                        critical_data_missing_ja = True
                        missing_details_ja.append(f"{label}(ja): æœªå–å¾—/ç©º")

        # --- Online/TTCKå‡¦ç† (æ—¥æœ¬èª) ---
        is_ttck_ja = "TTCK" in ja_data.get('name', '')
        is_online_ja = "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³" in ja_data.get('class_format', '') or "ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰" in ja_data.get('class_format', '')

        if is_ttck_ja:
            print("               æ—¥æœ¬èª: TTCKã‚³ãƒ¼ã‚¹æ¤œå‡ºã€‚æ•™å®¤ã¨æ›œæ—¥æ™‚é™ã‚’èª¿æ•´ã—ã¾ã™ã€‚")
            ja_data['location'] = "TTCK"
            if not ja_data.get('day_period') or ja_data.get('day_period') == "æ›œæ—¥æ™‚é™ä¸æ˜":
                ja_data['day_period'] = "ç‰¹å®šæœŸé–“é›†ä¸­"
        elif is_online_ja:
            print("               æ—¥æœ¬èª: ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æˆæ¥­æ¤œå‡ºã€‚æ•™å®¤ã¨æ›œæ—¥æ™‚é™ã‚’èª¿æ•´ã—ã¾ã™ã€‚")
            ja_data['location'] = "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³"
            if not ja_data.get('day_period') or ja_data.get('day_period') == "æ›œæ—¥æ™‚é™ä¸æ˜":
                ja_data['day_period'] = "ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æˆæ¥­"

        # --- å¿…é ˆãƒ‡ãƒ¼ã‚¿æœ€çµ‚ãƒã‚§ãƒƒã‚¯ (æ—¥æœ¬èª) ---
        if not is_ttck_ja:
            if not ja_data.get('location') or ja_data.get('location') == "æ•™å®¤ä¸æ˜":
                 if not is_online_ja:
                    critical_data_missing_ja = True
                    missing_details_ja.append("æ•™å®¤(ja): æœªå–å¾—/ç©º")
            if not ja_data.get('day_period') or ja_data.get('day_period') == "æ›œæ—¥æ™‚é™ä¸æ˜":
                critical_data_missing_ja = True
                missing_details_ja.append("æ›œæ—¥æ™‚é™(ja): æœªå–å¾—/ç©º")

        if critical_data_missing_ja:
            raise MissingCriticalDataError(f"å¿…é ˆæ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•— (URL: {japanese_url}): {'; '.join(missing_details_ja)}")

        print("           --- æ—¥æœ¬èªæƒ…å ±å–å¾—å®Œäº† ---")

        # After Japanese extraction
        ja_elapsed = time.time() - detail_start_time
        print(f"    [{time.strftime('%H:%M:%S')}] âœ… Japanese data extracted ({ja_elapsed:.2f}s)")
        
        # --- 2. è‹±èªãƒšãƒ¼ã‚¸ã®æƒ…å ±ã‚’å–å¾— ---
        # English page processing
        english_start_time = time.time()
        print(f"    [{time.strftime('%H:%M:%S')}] ğŸ‡¬ğŸ‡§ Processing English page")

        # æ—§ã‚·ã‚¹ãƒ†ãƒ ã¨æ–°ã‚·ã‚¹ãƒ†ãƒ ã§è‹±èªãƒšãƒ¼ã‚¸URLã®ç”Ÿæˆæ–¹æ³•ãŒç•°ãªã‚‹
        if is_old_system or current_year <= 2024:
            # æ—§ã‚·ã‚¹ãƒ†ãƒ ã®è‹±èªãƒšãƒ¼ã‚¸URLç”Ÿæˆ
            if "locale=ja" in current_url:
                english_url = current_url.replace("locale=ja", "locale=en")
            elif "locale=" not in current_url:
                english_url = current_url + ("&" if "?" in current_url else "?") + "locale=en"
            else:
                english_url = current_url
        else:
            # æ–°ã‚·ã‚¹ãƒ†ãƒ ã®è‹±èªãƒšãƒ¼ã‚¸URLç”Ÿæˆ (2025+)
            if "lang=jp" in current_url:
                english_url = current_url.replace("lang=jp", "lang=en")
            elif "lang=" not in current_url:
                english_url = current_url + ("&" if "?" in current_url else "?") + "lang=en"
            else:
                english_url = current_url

        print(f"           è‹±èªãƒšãƒ¼ã‚¸å‡¦ç†ä¸­: {english_url}")
        try:
            current_url = driver.current_url
            if '?' in current_url:
                english_url = f"{current_url}&lang=en"
            else:
                english_url = f"{current_url}?lang=en"
                
            # Execute JavaScript to reload with param
            driver.execute_script(f"window.location.href = '{english_url}';")
            
            # ã™ã¹ã¦ã®å¹´åº¦ã§çµ±ä¸€ã—ãŸå¾…æ©Ÿå‡¦ç†
            WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.presence_of_element_located((By.TAG_NAME, "body")))
            
            # â˜…â˜…â˜… è‹±èªãƒšãƒ¼ã‚¸ã§ã‚‚ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ã‚’ãƒã‚§ãƒƒã‚¯ â˜…â˜…â˜…
            if is_error_page(driver):
                print(f"           [æƒ…å ±] è‹±èªãƒšãƒ¼ã‚¸ã§ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚è‹±èªæƒ…å ±ã¯ä¸€éƒ¨æ¬ è½ã—ã¾ã™ã€‚")
                save_screenshot(driver, f"error_page_english_{current_year}_{course_id}", screenshots_dir)
                # è‹±èªãƒšãƒ¼ã‚¸ãŒã‚¨ãƒ©ãƒ¼ãªã‚‰ã€æ—¥æœ¬èªæƒ…å ±ã ã‘ã§ã‚‚è¿”ã™ï¼ˆå®Œå…¨ã‚¹ã‚­ãƒƒãƒ—ã—ãªã„ï¼‰
                print("           è‹±èªãƒšãƒ¼ã‚¸ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ—¥æœ¬èªæƒ…å ±ã®ã¿ã§é€²ã‚ã¾ã™ã€‚")
                # ã‚¨ãƒ©ãƒ¼æ™‚ã¯è‹±èªãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«æˆ»ã™
                en_data = {}
                name_default_en = f"Name Unknown-{course_id}"
                for key, (_, _, default_value_en, *_) in en_map_to_use.items():
                    en_data[key] = default_value_en if key != 'name' else name_default_en
            else:
                # è‹±èªãƒšãƒ¼ã‚¸ã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°å¾…æ©Ÿæ™‚é–“
                print(f"           è‹±èªãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿å®Œäº†ã€‚JavaScriptãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°å¾…æ©Ÿä¸­ ({JS_RENDER_WAIT}ç§’)...")
                #time.sleep(JS_RENDER_WAIT)
                print(f"           å¾…æ©Ÿå®Œäº†ã€‚è‹±èªæƒ…å ±å–å¾—è©¦è¡Œ...")

                print("           --- è‹±èªæƒ…å ±å–å¾—é–‹å§‹ ---")

                # --- è‹±èªæƒ…å ±å–å¾—ãƒ«ãƒ¼ãƒ— ---
                en_data = {}
                name_default_en = f"Name Unknown-{course_id}"
                # è‹±èªãƒãƒƒãƒ—ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã§åˆæœŸåŒ–
                for key, (_, _, default_value_en, *_) in en_map_to_use.items():
                    en_data[key] = default_value_en if key != 'name' else name_default_en

                for key, (label, xpath, default_value, *_) in en_map_to_use.items():
                    if key == 'course_id_fallback': continue
                    en_data[key] = get_text_by_xpath(driver, xpath, default_value)

                # --- Online/TTCKå‡¦ç† (è‹±èª) ---
                is_ttck_en = ("TTCK" in en_data.get('name', '')) or is_ttck_ja
                en_class_format_lower = en_data.get('class_format', '').lower()
                is_online_en = "online" in en_class_format_lower or "remote" in en_class_format_lower

                if is_ttck_en:
                    print("               è‹±èª: TTCKã‚³ãƒ¼ã‚¹æ¤œå‡ºã€‚æ•™å®¤ã¨æ›œæ—¥æ™‚é™ã‚’èª¿æ•´ã—ã¾ã™ã€‚")
                    en_data['location'] = "TTCK"
                    if not en_data.get('day_period') or en_data.get('day_period') == "Day/Period Unknown":
                        en_data['day_period'] = "Intensive Course"
                elif is_online_en:
                    print("               è‹±èª: ã‚ªãƒ³ãƒ©ã‚¤ãƒ³æˆæ¥­æ¤œå‡ºã€‚æ•™å®¤ã‚’èª¿æ•´ã—ã¾ã™ã€‚")
                    en_data['location'] = "Online"

                print("           --- è‹±èªæƒ…å ±å–å¾—å®Œäº† ---")

        except TimeoutException as e_timeout_en:
            print(f"     [è­¦å‘Š] è‹±èªãƒšãƒ¼ã‚¸({english_url})ã®èª­ã¿è¾¼ã¿ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€‚è‹±èªæƒ…å ±ã¯ä¸€éƒ¨æ¬ è½ã—ã¾ã™ã€‚ {e_timeout_en}")
            save_screenshot(driver, f"detail_en_load_timeout_{current_year}_{course_id or 'unknownID'}", screenshots_dir)
        except (InvalidSessionIdException, NoSuchWindowException) as e_session:
            print(f"     [ã‚¨ãƒ©ãƒ¼] è‹±èªãƒšãƒ¼ã‚¸å‡¦ç†ä¸­ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³/ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚¨ãƒ©ãƒ¼: {e_session}")
            raise
        except Exception as e_en:
            print(f"     [è­¦å‘Š] è‹±èªãƒšãƒ¼ã‚¸({english_url})ã®å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e_en}ã€‚è‹±èªæƒ…å ±ã¯ä¸€éƒ¨æ¬ è½ã—ã¾ã™ã€‚")
            save_screenshot(driver, f"detail_en_unknown_error_{current_year}_{course_id or 'unknownID'}", screenshots_dir)
            traceback.print_exc()
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯è‹±èªãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«æˆ»ã™
            en_data = {}
            name_default_en = f"Name Unknown-{course_id}"
            for key, (_, _, default_value_en, *_) in en_map_to_use.items():
                en_data[key] = default_value_en if key != 'name' else name_default_en

        # After English extraction
        en_elapsed = time.time() - english_start_time
        print(f"    [{time.strftime('%H:%M:%S')}] âœ… English data extracted ({en_elapsed:.2f}s)")
        
        # Final data construction
        print(f"    [{time.strftime('%H:%M:%S')}] ğŸ”„ Building final data object")
        
        # --- 3. æœ€çµ‚ãƒ‡ãƒ¼ã‚¿æ§‹ç¯‰ ---
        final_details = {
            'course_id': course_id,
            'year_scraped': current_year,
            'translations': {
                'ja': {},
                'en': {}
            }
        }

        all_keys_to_copy = [k for k in ja_map_to_use.keys() if k != 'course_id_fallback']

        # æ—¥æœ¬èªãƒ‡ãƒ¼ã‚¿ã‚’æ§‹æˆ
        for key in all_keys_to_copy:
            final_details['translations']['ja'][key] = ja_data.get(key, "")

        # è‹±èªãƒ‡ãƒ¼ã‚¿ã‚’æ§‹æˆ
        for key in all_keys_to_copy:
            final_details['translations']['en'][key] = en_data.get(key, "")

        # --- ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã®æƒ…å ±ã‚’è¨­å®š (è£œè¶³ç”¨) ---
        semester_en_raw = final_details['translations']['en'].get('semester', '')
        semester_ja_raw = final_details['translations']['ja'].get('semester', '')
        final_details['semester'] = extract_season(semester_en_raw) if extract_season(semester_en_raw) != "unknown" else extract_season(semester_ja_raw)
        final_details['professor_ja'] = final_details['translations']['ja'].get('professor', '')
        final_details['name_ja'] = final_details['translations']['ja'].get('name', '')
        final_details['field_ja'] = final_details['translations']['ja'].get('field', '')
        final_details['credits_ja'] = final_details['translations']['ja'].get('credits', '')

        # Log time for the entire process
        total_elapsed = time.time() - detail_start_time
        print(f"    [{time.strftime('%H:%M:%S')}] âœ… Complete syllabus details extracted ({total_elapsed:.2f}s)")
        
        return final_details

# --- â˜…â˜…â˜… aggregate_syllabus_data é–¢æ•° (å¤‰æ›´ãªã—) â˜…â˜…â˜… ---
def aggregate_syllabus_data(all_raw_data):
    """
    è¤‡æ•°å¹´åº¦ã«ã‚ãŸã‚‹ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’é›†ç´„ã—ã€æŒ‡å®šã•ã‚ŒãŸJSONå½¢å¼ã«æ•´å½¢ã™ã‚‹ã€‚
    â˜…â˜…â˜… é›†ç´„ã‚­ãƒ¼: æ‹…å½“è€…å(æ—¥), ç§‘ç›®å(æ—¥), å­¦æœŸ(å­£ç¯€ã®ã¿), åˆ†é‡(æ—¥), å˜ä½(æ—¥) â˜…â˜…â˜… (ç™»éŒ²ç•ªå·ã‚’é™¤å¤–)
    è¤‡æ•°å¹´åº¦ã‚ã‚‹å ´åˆã¯ã€æœ€æ–°å¹´åº¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŸºæœ¬ã¨ã—ã€year ã¨ available_years ã‚’æ›´æ–°ã™ã‚‹ã€‚
    """
    if not all_raw_data: return []
    grouped_by_key = {}
    skipped_count = 0
    print("\n--- ãƒ‡ãƒ¼ã‚¿é›†ç´„é–‹å§‹ ---")
    for item in all_raw_data:
        course_id = item.get('course_id')
        professor_ja_key = item.get('professor_ja', '')
        professors_tuple = tuple(sorted([p.strip() for p in re.split('[/,]', professor_ja_key) if p.strip()]))
        name_ja_key = item.get('name_ja', '')
        semester_agg_key = item.get('semester', 'unknown')
        field_ja_key = item.get('field_ja', '')
        credits_ja_key = item.get('credits_ja', '')

        agg_key = (
            professors_tuple, name_ja_key, semester_agg_key, field_ja_key, credits_ja_key
        )

        if not name_ja_key or not field_ja_key or not credits_ja_key or semester_agg_key == "unknown":
            error_msg = f"é›†ç´„ã‚­ãƒ¼ã«å¿…è¦ãªæƒ…å ±ãŒä¸è¶³ã¾ãŸã¯å­¦æœŸä¸æ˜ (Course ID: {course_id}, Year: {item.get('year_scraped')}, Semester: {semester_agg_key})"
            print(f"[è­¦å‘Š] {error_msg}")
            
            if not pause_on_error(f"Missing critical aggregation data: {error_msg}"):
                print("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ä¸­æ–­ã€‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                sys.exit(1)
            
            skipped_count += 1
            continue

        if agg_key not in grouped_by_key: grouped_by_key[agg_key] = []
        grouped_by_key[agg_key].append(item)

    if skipped_count > 0: print(f"ã‚­ãƒ¼æƒ…å ±ä¸è¶³ã¾ãŸã¯å­¦æœŸä¸æ˜ã«ã‚ˆã‚Š {skipped_count} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ãŒé›†ç´„ã‹ã‚‰ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚")
    print(f"{len(grouped_by_key)} ä»¶ã«é›†ç´„ã•ã‚Œã¾ã—ãŸã€‚")

    final_list = []
    item_count = 0
    for agg_key, year_data_list in grouped_by_key.items():
        item_count += 1
        if item_count % 100 == 0:
             print(f"   é›†ç´„å‡¦ç†ä¸­... {item_count}/{len(grouped_by_key)}")

        year_data_list.sort(key=lambda x: x['year_scraped'], reverse=True)
        latest_data = year_data_list[0]
        years_scraped_int = sorted(list(set(d['year_scraped'] for d in year_data_list)), reverse=True)
        available_years_str = [str(y) for y in years_scraped_int]

        trans_ja = latest_data.get('translations', {}).get('ja', {})
        trans_en = latest_data.get('translations', {}).get('en', {})
        semester_final = agg_key[2]

        professors_list = []
        prof_ja_raw = trans_ja.get('professor', '')
        prof_en_raw = trans_en.get('professor', '')

        # Use the new parsing function
        prof_ja_names = parse_professor_names(prof_ja_raw)
        prof_en_names = parse_professor_names(prof_en_raw)

        num_professors = len(prof_ja_names)
        if len(prof_en_names) < num_professors:
            prof_en_names.extend([""] * (num_professors - len(prof_en_names)))
        elif len(prof_en_names) > num_professors:
            prof_en_names = prof_en_names[:num_professors]

        # FIX: Set default empty values for department
        dept_ja = ""
        dept_en = ""

        for i in range(num_professors):
            prof_obj = {
                "name": {
                    "ja": prof_ja_names[i],
                    "en": prof_en_names[i] if i < len(prof_en_names) and prof_en_names[i] else prof_ja_names[i]
                },
                "department": { "ja": dept_ja, "en": dept_en }
            }
            professors_list.append(prof_obj)

        # Normalize field and credits
        field_ja = normalize_field(trans_ja.get('field', ''))
        field_en = normalize_field(trans_en.get('field', ''))
        credits_ja = normalize_credits(trans_ja.get('credits', ''), 'ja')
        credits_en = normalize_credits(trans_en.get('credits', ''), 'en')

        aggregated_item = {
            "course_id": latest_data['course_id'],
            "year": "&".join(available_years_str),
            "semester": semester_final,
            "translations": {
                "ja": {
                    "name": trans_ja.get('name', ''), 
                    "field": field_ja,
                    "credits": credits_ja, 
                    "semester": trans_ja.get('semester', ''),
                    "Classroom": trans_ja.get('location', ''), 
                    "day_period": trans_ja.get('day_period', ''),
                    "selection_method": trans_ja.get('selection_method', '')
                },
                "en": {
                    "name": trans_en.get('name', ''), 
                    "field": field_en,
                    "credits": credits_en, 
                    "semester": trans_en.get('semester', ''),
                    "Classroom": trans_en.get('location', ''), 
                    "day_period": trans_en.get('day_period', ''),
                    "selection_method": trans_en.get('selection_method', '')
                }
            },
            "professors": professors_list,
            "available_years": available_years_str
        }
        final_list.append(aggregated_item)
    print("--- ãƒ‡ãƒ¼ã‚¿é›†ç´„å®Œäº† ---")
    return final_list
# --- login é–¢æ•° (å¤‰æ›´ãªã—) ---
def login(driver, email, password, screenshots_dir):
    """æŒ‡å®šã•ã‚ŒãŸæƒ…å ±ã§ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ã‚’è¡Œã†"""
    login_url = 'https://gslbs.keio.jp/syllabus/search'
    max_login_attempts = 2
    for attempt in range(max_login_attempts):
        print(f"\nãƒ­ã‚°ã‚¤ãƒ³è©¦è¡Œ {attempt + 1}/{max_login_attempts}...")
        try:
            driver.get(login_url)
            WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.presence_of_element_located((By.XPATH, "//input[@type='email' or @name='identifier']")))
            time.sleep(SHORT_WAIT)
            username_field = WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.visibility_of_element_located((By.XPATH, "//input[@type='email' or @name='identifier']")))
            username_field.clear(); username_field.send_keys(email); time.sleep(0.5)

            next_button_selectors = ["//button[contains(., 'Next')]", "//button[contains(., 'æ¬¡ã¸')]", "//button[@type='submit']", "//input[@type='submit' and (contains(@value, 'Next') or contains(@value, 'æ¬¡ã¸'))]", "//div[@role='button' and (contains(., 'Next') or contains(., 'æ¬¡ã¸'))]" ]
            next_button = None
            for selector in next_button_selectors:
                try:
                    next_button = WebDriverWait(driver, SHORT_WAIT).until(EC.element_to_be_clickable((By.XPATH, selector)))
                    if click_element(driver, next_button): break
                    else: next_button = None
                except TimeoutException: continue
                except StaleElementReferenceException: time.sleep(1); continue
                except (InvalidSessionIdException, NoSuchWindowException) as e_session: raise e_session

            if not next_button:
                try:
                    print("     ã€Œæ¬¡ã¸ã€ãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€Enterã‚­ãƒ¼ã‚’é€ä¿¡ã—ã¾ã™ã€‚")
                    username_field.send_keys(Keys.RETURN)
                    time.sleep(MEDIUM_WAIT)
                except Exception as e_enter: print(f"     Enterã‚­ãƒ¼é€ä¿¡ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e_enter}"); save_screenshot(driver, f"login_next_button_error_{attempt+1}", screenshots_dir); raise Exception("ã€Œæ¬¡ã¸ã€ãƒœã‚¿ãƒ³å‡¦ç†å¤±æ•—")

            WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.visibility_of_element_located((By.XPATH, "//input[@type='password']")))
            time.sleep(SHORT_WAIT)
            password_field = WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.visibility_of_element_located((By.XPATH, "//input[@type='password']")))
            password_field.clear(); password_field.send_keys(password); time.sleep(0.5)

            signin_button_selectors = ["//button[contains(., 'Sign in')]", "//button[contains(., 'ã‚µã‚¤ãƒ³ã‚¤ãƒ³')]", "//button[contains(., 'Verify')]", "//button[@type='submit']", "//input[@type='submit' and (contains(@value, 'Sign in') or contains(@value, 'ã‚µã‚¤ãƒ³ã‚¤ãƒ³') or contains(@value, 'Verify'))]", "//div[@role='button' and (contains(., 'Sign in') or contains(., 'ã‚µã‚¤ãƒ³ã‚¤ãƒ³') or contains(., 'Verify'))]" ]
            signin_button = None
            for selector in signin_button_selectors:
                try:
                    signin_button = WebDriverWait(driver, SHORT_WAIT).until(EC.element_to_be_clickable((By.XPATH, selector)))
                    if click_element(driver, signin_button): break
                    else: signin_button = None
                except TimeoutException: continue
                except StaleElementReferenceException: time.sleep(1); continue
                except (InvalidSessionIdException, NoSuchWindowException) as e_session: raise e_session

            if not signin_button:
                try:
                    print("     ã€Œã‚µã‚¤ãƒ³ã‚¤ãƒ³ã€ãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€Enterã‚­ãƒ¼ã‚’é€ä¿¡ã—ã¾ã™ã€‚")
                    password_field.send_keys(Keys.RETURN)
                    time.sleep(LONG_WAIT)
                except Exception as e_enter: print(f"     Enterã‚­ãƒ¼é€ä¿¡ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e_enter}"); save_screenshot(driver, f"login_signin_button_error_{attempt+1}", screenshots_dir); raise Exception("ã€Œã‚µã‚¤ãƒ³ã‚¤ãƒ³ã€ãƒœã‚¿ãƒ³å‡¦ç†å¤±æ•—")

            print("     ãƒ­ã‚°ã‚¤ãƒ³å¾Œã®ãƒšãƒ¼ã‚¸é·ç§»å¾…æ©Ÿä¸­...")
            WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT + LONG_WAIT).until(EC.any_of(
                EC.url_contains("gslbs.keio.jp/syllabus/search"),
                EC.presence_of_element_located((By.XPATH, "//button[contains(text(), 'æ¤œç´¢')] | //button[@data-action_id='SYLLABUS_SEARCH_KEYWORD_EXECUTE']"))
            ))

            current_url = driver.current_url
            if "gslbs.keio.jp/syllabus/search" in current_url:
                print("ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸã€æ¤œç´¢ãƒšãƒ¼ã‚¸ã«åˆ°é”ã—ã¾ã—ãŸã€‚")
                try:
                    WebDriverWait(driver, MEDIUM_WAIT).until(EC.element_to_be_clickable((By.XPATH, "//button[@data-action_id='SYLLABUS_SEARCH_KEYWORD_EXECUTE'] | //button[contains(text(),'æ¤œç´¢')]")))
                except TimeoutException:
                    print("[è­¦å‘Š] æ¤œç´¢ç”»é¢ã®ä¸»è¦è¦ç´ ç¢ºèªã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€‚")
                return True
            else:
                print(f"[è­¦å‘Š] ãƒ­ã‚°ã‚¤ãƒ³å¾Œã®URLãŒæœŸå¾…ã—ãŸæ¤œç´¢ãƒšãƒ¼ã‚¸ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ URL: {current_url}")
                save_screenshot(driver, f"login_unexpected_page_{attempt+1}", screenshots_dir)
                if "auth" in current_url or "verify" in current_url or "duo" in current_url or "device" in current_url:
                    print("[æƒ…å ±] 2æ®µéšèªè¨¼ã¾ãŸã¯ãƒ‡ãƒã‚¤ã‚¹ç¢ºèªãƒšãƒ¼ã‚¸ã«é·ç§»ã—ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                    raise Exception("2æ®µéšèªè¨¼/ãƒ‡ãƒã‚¤ã‚¹ç¢ºèªæ¤œå‡º")
                print("     äºˆæœŸã›ã¬ãƒšãƒ¼ã‚¸ã«é·ç§»ã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—ã¨åˆ¤æ–­ã—ã¾ã™ã€‚")

        except (InvalidSessionIdException, NoSuchWindowException) as e_session:
            print(f"[ã‚¨ãƒ©ãƒ¼] ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ä¸­ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³/ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}): {e_session}")
            raise
        except TimeoutException as e:
            print(f"[ã‚¨ãƒ©ãƒ¼] ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ä¸­ã«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (è©¦è¡Œ {attempt + 1})ã€‚")
            save_screenshot(driver, f"login_timeout_{attempt+1}", screenshots_dir)
            if attempt == max_login_attempts - 1: raise Exception("ãƒ­ã‚°ã‚¤ãƒ³ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ") from e
            print("ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
            time.sleep(MEDIUM_WAIT)
        except WebDriverException as e:
            print(f"[ã‚¨ãƒ©ãƒ¼] ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ä¸­ã«WebDriverã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}): {e}")
            save_screenshot(driver, f"login_webdriver_error_{attempt+1}", screenshots_dir)
            if "net::ERR" in str(e) or "connection reset" in str(e).lower():
                print("     ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã¾ãŸã¯URLã®å•é¡Œã€ã¾ãŸã¯ãƒªãƒ¢ãƒ¼ãƒˆãƒ›ã‚¹ãƒˆã«ã‚ˆã‚‹åˆ‡æ–­ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            if attempt == max_login_attempts - 1: raise Exception("ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã«WebDriverã‚¨ãƒ©ãƒ¼") from e
            print("ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
            time.sleep(MEDIUM_WAIT)
        except Exception as e:
            print(f"[ã‚¨ãƒ©ãƒ¼] ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}): {e}")
            save_screenshot(driver, f"login_unknown_error_{attempt+1}", screenshots_dir)
            traceback.print_exc()
            if attempt == max_login_attempts - 1: raise Exception("ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼") from e
            print("ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™...")
            time.sleep(MEDIUM_WAIT)

    print("ãƒ­ã‚°ã‚¤ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    return False

def extract_auth_cookies(driver):
    """ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿ã®ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‹ã‚‰èªè¨¼Cookieã‚’å–å¾—ã™ã‚‹"""
    try:
        return driver.get_cookies()
    except Exception as e:
        print(f"[ã‚¨ãƒ©ãƒ¼] Cookieå–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def apply_cookies(driver, cookies):
    """ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã«Cookieã‚’é©ç”¨ã™ã‚‹"""
    if not cookies:
        return False
        
    try:
        # å¯¾è±¡ãƒ‰ãƒ¡ã‚¤ãƒ³ã«ä¸€åº¦ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹å¿…è¦ãŒã‚ã‚‹
        driver.get("https://gslbs.keio.jp")
        
        # Cookieã‚’é©ç”¨
        for cookie in cookies:
            try:
                driver.add_cookie(cookie)
            except Exception as e:
                print(f"[è­¦å‘Š] Cookie ({cookie.get('name', 'unknown')}) é©ç”¨ã‚¨ãƒ©ãƒ¼: {e}")
                
        # ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°ã—ã¦Cookieã‚’åæ˜ 
        driver.refresh()
        return True
    except Exception as e:
        print(f"[ã‚¨ãƒ©ãƒ¼] Cookieé©ç”¨ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return False

# --- check_session_timeout é–¢æ•° (å¤‰æ›´ãªã—) ---
def check_session_timeout(driver, screenshots_dir):
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒšãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã™ã‚‹"""
    try:
        current_url = driver.current_url
        page_title = driver.title
        page_source = driver.page_source.lower()
        timeout_keywords = ["ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ", "session timeout", "ãƒ­ã‚°ã‚¤ãƒ³ã—ç›´ã—ã¦ãã ã•ã„", "log back in"]
        error_page_url_part = "/syllabus/appMsg"
        is_session_timeout = False
        if error_page_url_part in current_url: is_session_timeout = True
        elif any(keyword in page_source for keyword in timeout_keywords): is_session_timeout = True
        elif "error" in page_title.lower() and any(keyword in page_source for keyword in timeout_keywords): is_session_timeout = True

        if is_session_timeout:
            print("[è­¦å‘Š] ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒšãƒ¼ã‚¸ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚")
            save_screenshot(driver, "session_timeout_detected", screenshots_dir)
            return True
        else:
            return False
    except (TimeoutException, StaleElementReferenceException):
        return False
    except WebDriverException as e:
        if "invalid session id" in str(e).lower() or "no such window" in str(e).lower():
            print(f"[ã‚¨ãƒ©ãƒ¼] ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒã‚§ãƒƒã‚¯ä¸­ã«è‡´å‘½çš„ãªWebDriverã‚¨ãƒ©ãƒ¼: {e}")
            raise
        else:
            print(f"[ã‚¨ãƒ©ãƒ¼] ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒã‚§ãƒƒã‚¯ä¸­ã«äºˆæœŸã›ã¬WebDriverã‚¨ãƒ©ãƒ¼: {e}")
            save_screenshot(driver, "session_check_webdriver_error", screenshots_dir)
            return False
    except Exception as e:
        print(f"[ã‚¨ãƒ©ãƒ¼] ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒã‚§ãƒƒã‚¯ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
        save_screenshot(driver, "session_check_unknown_error", screenshots_dir)
        traceback.print_exc()
        return False

def initialize_driver(driver_path, headless=False):
    """WebDriver (Chrome) ã‚’åˆæœŸåŒ–ã™ã‚‹"""
    print("\nWebDriverã‚’åˆæœŸåŒ–ã—ã¦ã„ã¾ã™...")
    options = webdriver.ChromeOptions()
    options.page_load_strategy = 'normal'
    
    # å…±é€šã®æœ€é©åŒ–è¨­å®šï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã®æœ‰ç„¡ã«é–¢ã‚ã‚‰ãšé©ç”¨ï¼‰
    prefs = {
        'profile.default_content_setting_values': { 
            'images': 2,  # ç”»åƒã‚’ç„¡åŠ¹åŒ–
            'plugins': 2,  # ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚’ç„¡åŠ¹åŒ–
            'popups': 2,   # ãƒãƒƒãƒ—ã‚¢ãƒƒãƒ—ã‚’ç„¡åŠ¹åŒ–
            'notifications': 2,  # é€šçŸ¥ã‚’ç„¡åŠ¹åŒ–
            'automatic_downloads': 2  # è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ç„¡åŠ¹åŒ–
        },
        'credentials_enable_service': False,
        'profile.password_manager_enabled': False
    }
    options.add_experimental_option('prefs', prefs)
    
    # ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰å›ºæœ‰ã®è¨­å®š
    if headless:
        options.add_argument('--headless')
        options.add_argument('--disable-gpu')
        options.add_argument('--window-size=1920,1080')
        options.add_argument('--blink-settings=imagesEnabled=false')
        print("ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™ã€‚")
    
    # å…±é€šã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–è¨­å®š
    options.add_argument('--disable-extensions')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-infobars')
    options.add_argument('--disable-blink-features=AutomationControlled')
    options.add_argument('--log-level=3')
    options.add_argument('--disable-background-networking')
    options.add_argument('--disable-default-apps')
    options.add_argument('--disable-sync')
    options.add_argument('--disable-translate')
    options.add_argument('--disable-popup-blocking')
    options.add_experimental_option('excludeSwitches', ['enable-automation', 'enable-logging'])
    options.add_experimental_option('useAutomationExtension', False)

    new_driver = None
    try:
        if driver_path and os.path.exists(driver_path):
            service = Service(executable_path=driver_path)
            new_driver = webdriver.Chrome(service=service, options=options)
            print(f"æŒ‡å®šã•ã‚ŒãŸChromeDriverã‚’ä½¿ç”¨: {driver_path}")
        else:
            print("ChromeDriverãƒ‘ã‚¹æœªæŒ‡å®š/ç„¡åŠ¹ã®ãŸã‚ã€è‡ªå‹•æ¤œå‡ºã—ã¾ã™ã€‚")
            service = Service()
            new_driver = webdriver.Chrome(service=service, options=options)
            print(f"è‡ªå‹•æ¤œå‡ºã•ã‚ŒãŸChromeDriverã‚’ä½¿ç”¨: {service.path}")
        new_driver.set_page_load_timeout(PAGE_LOAD_TIMEOUT)
        new_driver.implicitly_wait(5)
        print("WebDriverã®åˆæœŸåŒ–å®Œäº†ã€‚")
        return new_driver
    except Exception as e:
        print(f"[é‡å¤§ã‚¨ãƒ©ãƒ¼] WebDriverã®åˆæœŸåŒ–å¤±æ•—: {e}")
        traceback.print_exc()
        return None

# Add new recovery function here
def recover_webdriver(screenshots_dir):
    """WebDriverã‚’ãƒªã‚«ãƒãƒªãƒ¼ã—ã€å†ãƒ­ã‚°ã‚¤ãƒ³ã‚’è©¦ã¿ã‚‹"""
    retries = 3
    
    for attempt in range(retries):
        try:
            print(f"\n[æƒ…å ±] WebDriverå†åˆæœŸåŒ–è©¦è¡Œ ({attempt + 1}/{retries})...")
            
            # å¤ã„ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’é–‰ã˜ã‚‹
            try:
                if 'driver' in globals() and driver:
                    driver.quit()
            except Exception as e:
                print(f"[è­¦å‘Š] å¤ã„ãƒ‰ãƒ©ã‚¤ãƒãƒ¼çµ‚äº†ã‚¨ãƒ©ãƒ¼: {e}")
            
            # æ–°ã—ã„ãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’åˆæœŸåŒ–
            new_driver = initialize_driver(CHROME_DRIVER_PATH, HEADLESS_MODE)
            if not new_driver:
                print("[ã‚¨ãƒ©ãƒ¼] WebDriveråˆæœŸåŒ–å¤±æ•—")
                time.sleep(3)
                continue
                
            # ãƒ­ã‚°ã‚¤ãƒ³è©¦è¡Œ
            if not login(new_driver, USER_EMAIL, USER_PASSWORD, screenshots_dir):
                print("[ã‚¨ãƒ©ãƒ¼] ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—")
                if new_driver:
                    new_driver.quit()
                time.sleep(3)
                continue
                
            print("[æˆåŠŸ] WebDriverå†åˆæœŸåŒ–ã¨ãƒ­ã‚°ã‚¤ãƒ³å®Œäº†")
            return new_driver
            
        except Exception as e:
            print(f"[ã‚¨ãƒ©ãƒ¼] WebDriverãƒªã‚«ãƒãƒªãƒ¼ä¸­ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
            traceback.print_exc()
            time.sleep(3)
    
    print("[é‡å¤§ã‚¨ãƒ©ãƒ¼] WebDriverãƒªã‚«ãƒãƒªãƒ¼å¤±æ•—")
    return None

# --- â˜…â˜…â˜… JSONãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿é–¢æ•° (å¤‰æ›´ãªã—) â˜…â˜…â˜… ---
def write_json_data(data, path):
    """æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã«JSONãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã‚€"""
    print(f"\n'{path}' ã¸æ›¸ãè¾¼ã¿ä¸­ ({len(data)} ä»¶)...")
    try:
        os.makedirs(os.path.dirname(path), exist_ok=True)
        with open(path, mode='w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
        print(f"JSONæ›¸ãè¾¼ã¿å®Œäº†ã€‚")
    except Exception as e:
        print(f"[ã‚¨ãƒ©ãƒ¼] JSONæ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

# Missing function that I realized is referenced but wasn't included in the original code
def pause_on_error(error_message, exception=None, screenshot_path=None):
    """ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã«å‡¦ç†ã‚’ä¸€æ™‚åœæ­¢ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¶šè¡Œã™ã‚‹ã‹ç¢ºèªã™ã‚‹"""
    print(f"\n[ã‚¨ãƒ©ãƒ¼] {error_message}")
    if exception: print(f"ä¾‹å¤–è©³ç´°: {exception}")
    if screenshot_path: print(f"ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ: {screenshot_path}")
    
    # å¸¸ã«ç¶šè¡Œã™ã‚‹ (è‡ªå‹•å‡¦ç†ãƒ¢ãƒ¼ãƒ‰)
    return True
    
    # ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèªãŒå¿…è¦ãªå ´åˆã«ä½¿ç”¨
    # try:
    #     response = input("\nå‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/n): ").strip().lower()
    #     return response in ('y', 'yes', '')
    # except KeyboardInterrupt:
    #     print("\nã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å‰²ã‚Šè¾¼ã¿ã«ã‚ˆã‚Šä¸­æ–­ã€‚")
    #     return False

# --- â˜…â˜…â˜… ãƒ¡ã‚¤ãƒ³å‡¦ç† (é€æ¬¡å‡¦ç†ã«æˆ»ã™) â˜…â˜…â˜… ---
if __name__ == "__main__":
    output_dir, logs_dir, screenshots_dir = create_output_dirs(OUTPUT_DIR_NAME)
    resume_checkpoint = load_checkpoint()
    starting_year_index = 0
    starting_field_index = 0
    starting_page_num = 0
    processed_urls = set()
    if resume_checkpoint:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèª
        resume_choice = input(f"\nãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ (å¹´åº¦: {resume_checkpoint['year']}, åˆ†é‡: {resume_checkpoint['field_name']}, ãƒšãƒ¼ã‚¸: {resume_checkpoint['page_num']})ã€‚"
                            f"\nå†é–‹ã—ã¾ã™ã‹ï¼Ÿ (y/n): ").strip().lower()
        
        if resume_choice in ('y', 'yes', ''):
            # TARGET_YEARSã¨TARGET_FIELDSã‹ã‚‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ¤œç´¢
            if resume_checkpoint['year'] in TARGET_YEARS:
                starting_year_index = TARGET_YEARS.index(resume_checkpoint['year'])
            else:
                print(f"[è­¦å‘Š] ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®å¹´åº¦ {resume_checkpoint['year']} ã¯ç¾åœ¨ã®å¯¾è±¡å¹´åº¦ã«ã‚ã‚Šã¾ã›ã‚“ã€‚æœ€åˆã‹ã‚‰é–‹å§‹ã—ã¾ã™ã€‚")
                
            if resume_checkpoint['field_name'] in TARGET_FIELDS:
                starting_field_index = TARGET_FIELDS.index(resume_checkpoint['field_name'])
            else:
                print(f"[è­¦å‘Š] ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®åˆ†é‡ {resume_checkpoint['field_name']} ã¯ç¾åœ¨ã®å¯¾è±¡åˆ†é‡ã«ã‚ã‚Šã¾ã›ã‚“ã€‚ã“ã®å¹´åº¦ã®æœ€åˆã‹ã‚‰é–‹å§‹ã—ã¾ã™ã€‚")
                starting_field_index = 0
                
            starting_page_num = resume_checkpoint['page_num']
            processed_urls = set(resume_checkpoint['processed_urls'])
            print(f"\n[æƒ…å ±] ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å†é–‹: å¹´åº¦={resume_checkpoint['year']} (ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {starting_year_index}), "
                f"åˆ†é‡={resume_checkpoint['field_name']} (ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {starting_field_index}), ãƒšãƒ¼ã‚¸={starting_page_num}, å‡¦ç†æ¸ˆURLæ•°={len(processed_urls)}")
        else:
            print("\n[æƒ…å ±] æœ€åˆã‹ã‚‰é–‹å§‹ã—ã¾ã™ã€‚")

    start_time_dt = datetime.datetime.now()
    start_time_dt = datetime.datetime.now()
    output_json_path = os.path.join(output_dir, OUTPUT_JSON_FILE)
    driver = None
    scraped_data_all_years = []
    global_start_time = time.time()
    print(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–‹å§‹: {start_time_dt.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"å¯¾è±¡å¹´åº¦: {TARGET_YEARS}")
    print(f"å¯¾è±¡åˆ†é‡: {TARGET_FIELDS}")
    print(f"å‡ºåŠ›å…ˆJSON: {output_json_path}")
    print(f"ä¸¦åˆ—å‡¦ç†: ç„¡åŠ¹ (é€æ¬¡å‡¦ç†)") # ä¸¦åˆ—å‡¦ç†ã¯ç„¡åŠ¹

    driver = initialize_driver(CHROME_DRIVER_PATH, HEADLESS_MODE)
    if not driver:
        sys.exit("è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: WebDriverã‚’åˆæœŸåŒ–ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    try:
        if not login(driver, USER_EMAIL, USER_PASSWORD, screenshots_dir):
            sys.exit("è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: åˆæœŸãƒ­ã‚°ã‚¤ãƒ³ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        print("\nèªè¨¼æƒ…å ±ã‚’æŠ½å‡ºä¸­...")
        auth_cookies = extract_auth_cookies(driver)
        if auth_cookies:
            print(f"èªè¨¼Cookieå–å¾—æˆåŠŸ: {len(auth_cookies)}å€‹ã®Cookieã‚’å…±æœ‰ã—ã¾ã™")
        else:
            print("[è­¦å‘Š] èªè¨¼Cookieå–å¾—å¤±æ•—ã€‚å„ã‚¹ãƒ¬ãƒƒãƒ‰ãŒå€‹åˆ¥ã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã™ã€‚")
    except Exception as initial_login_e:
        print(f"è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: åˆæœŸãƒ­ã‚°ã‚¤ãƒ³ä¸­ã«äºˆæœŸã›ã¬ä¾‹å¤–ãŒç™ºç”Ÿ: {initial_login_e}")
        traceback.print_exc()
        if driver:
            try:
                save_screenshot(driver, "initial_login_fatal_error", screenshots_dir)
                driver.quit()
            except Exception as qe: print(f"åˆæœŸãƒ­ã‚°ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼å¾Œã®ãƒ–ãƒ©ã‚¦ã‚¶çµ‚äº†æ™‚ã‚¨ãƒ©ãƒ¼: {qe}")
        sys.exit(1)

# --- ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ— ---
    try:
        year_index = starting_year_index
        while year_index < len(TARGET_YEARS):
            year = TARGET_YEARS[year_index]
            print(f"\n<<<<< {year}å¹´åº¦ ã®å‡¦ç†é–‹å§‹ >>>>>")
            year_processed_successfully = True

            # ã™ã¹ã¦ã®å¹´åº¦ã§æ¨™æº–çš„ãªã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã‚’ä½¿ç”¨
            current_page_timeout = PAGE_LOAD_TIMEOUT
            current_element_timeout = ELEMENT_WAIT_TIMEOUT
            
            # ã“ã®å¹´åº¦ã®å‡¦ç†é–‹å§‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨­å®š
            field_index = starting_field_index if year_index == starting_year_index else 0
            
            while field_index < len(TARGET_FIELDS):
                field_name = TARGET_FIELDS[field_index]
                print(f"\n===== åˆ†é‡: {field_name} ({year}å¹´åº¦) ã®å‡¦ç†é–‹å§‹ =====")
                field_processed_successfully = True
                field_total_attempts = 0
                field_error_count = 0
                consecutive_errors = 0
                ttck_error_count = 0  # TTCKç§‘ç›®å°‚ç”¨ã®ã‚¨ãƒ©ãƒ¼ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼
                
                # ã“ã®åˆ†é‡ã®å‡¦ç†æ¸ˆã¿URLï¼ˆãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã€ã¾ãŸã¯æ–°è¦ä½œæˆï¼‰
                if year_index == starting_year_index and field_index == starting_field_index:
                    opened_links_this_year_field = processed_urls
                    # ã“ã®åˆ†é‡ã®é–‹å§‹ãƒšãƒ¼ã‚¸ç•ªå·ï¼ˆãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã€ã¾ãŸã¯æœ€åˆã‹ã‚‰ï¼‰
                    last_processed_page_num = starting_page_num
                else:
                    opened_links_this_year_field = set()
                    last_processed_page_num = 0
                    
                # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ãŸã®ã§ãƒªã‚»ãƒƒãƒˆï¼ˆæ¬¡ã®åˆ†é‡ã¨å¹´åº¦ã§ã¯æœ€åˆã‹ã‚‰é–‹å§‹ã™ã‚‹ãŸã‚ï¼‰
                if year_index == starting_year_index and field_index == starting_field_index:
                    starting_page_num = 0

                try:
                    if check_session_timeout(driver, screenshots_dir):
                        print("ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ¤œå‡ºã€‚å†ãƒ­ã‚°ã‚¤ãƒ³è©¦è¡Œ...")
                        if not login(driver, USER_EMAIL, USER_PASSWORD, screenshots_dir):
                            print("[ã‚¨ãƒ©ãƒ¼] å†ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—ã€‚ã“ã®åˆ†é‡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                            field_index += 1; continue

                    try:
                        current_url_check = driver.current_url
                        if "gslbs.keio.jp/syllabus/search" not in current_url_check:
                            print("æ¤œç´¢ãƒšãƒ¼ã‚¸ä»¥å¤–ã«ã„ã‚‹ãŸã‚ã€æ¤œç´¢ãƒšãƒ¼ã‚¸ã«ç§»å‹•ã—ã¾ã™ã€‚")
                            driver.get('https://gslbs.keio.jp/syllabus/search')
                            WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.url_contains("gslbs.keio.jp/syllabus/search"))
                            time.sleep(MEDIUM_WAIT)
                    except WebDriverException as e_url_check:
                        screenshot_path = save_screenshot(driver, f"url_check_error_{year}_{field_name}", screenshots_dir)
                        print(f"[è­¦å‘Š] ç¾åœ¨ã®URLç¢ºèªä¸­ã«ã‚¨ãƒ©ãƒ¼: {e_url_check}ã€‚")
                        
                        if not pause_on_error("WebDriver exception during URL check", e_url_check, screenshot_path):
                            print("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ä¸­æ–­ã€‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                            sys.exit(1)
                        
                        raise InvalidSessionIdException("URL check failed, likely closed window.") from e_url_check

                    # --- æ¤œç´¢æ¡ä»¶è¨­å®š (JSé«˜é€ŸåŒ– + Seleniumãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯) ---
                    js_search_success = False
                    try: # JavaScriptã§ã®è¨­å®šè©¦è¡Œ
                        fast_search_js = """
                            async function setSearchCriteria(year, fieldName) {
                                try {
                                    var yearSelect = document.querySelector('select[name="KEYWORD_TTBLYR"]');
                                    if (yearSelect) { yearSelect.value = year; yearSelect.dispatchEvent(new Event('change', {bubbles:true})); }
                                    else { console.error('Year select not found'); return false; }

                                    var toggleButton = document.querySelector('button[data-target*="screensearch-cond-option-toggle-target"]');
                                    if (toggleButton) {
                                        var toggleTarget = document.querySelector(toggleButton.getAttribute('data-target'));
                                        if (toggleTarget && !toggleTarget.classList.contains('show')) {
                                            toggleButton.click(); await new Promise(r => setTimeout(r, 700));
                                        }
                                    }

                                    var fieldSelect = document.querySelector('select[name="KEYWORD_FLD1CD"]');
                                    if (fieldSelect) {
                                        let fieldFound = false;
                                        for (let i = 0; i < fieldSelect.options.length; i++) {
                                            if (fieldSelect.options[i].text.trim() === fieldName) {
                                                fieldSelect.selectedIndex = i; fieldSelect.dispatchEvent(new Event('change', {bubbles:true}));
                                                fieldFound = true; break;
                                            }
                                        }
                                        if (!fieldFound) console.warn('Field option not found: ' + fieldName);
                                    } else { console.error('Field select not found'); return false; }

                                    var checkbox = document.querySelector('input[name="KEYWORD_LVL"][value="3"]');
                                    if (checkbox && checkbox.checked) { checkbox.checked = false; checkbox.dispatchEvent(new Event('change', {bubbles:true})); }

                                    return true;
                                } catch (error) { console.error('Error in setSearchCriteria:', error); return false; }
                            }
                            return await setSearchCriteria(arguments[0], arguments[1]);
                        """
                        result = driver.execute_script(fast_search_js, str(year), field_name)
                        if result:
                            print(f"   JavaScriptã§æ¤œç´¢æ¡ä»¶ã‚’ä¸€æ‹¬è¨­å®šã—ã¾ã—ãŸï¼ˆå¹´åº¦: {year}, åˆ†é‡: {field_name}ï¼‰")
                            time.sleep(MEDIUM_WAIT); js_search_success = True
                        else: print(f"   JavaScriptæ¤œç´¢è¨­å®šã§å•é¡Œç™ºç”Ÿã€‚é€šå¸¸æ–¹æ³•ã§è©¦è¡Œã—ã¾ã™ã€‚")
                    except Exception as js_err: print(f"   JavaScriptæ¤œç´¢è¨­å®šå¤±æ•—: {js_err}ã€‚é€šå¸¸æ–¹æ³•ã§è©¦è¡Œã—ã¾ã™ã€‚")

                    if not js_search_success: # Seleniumã§ã®è¨­å®š (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯)
                        # å¹´åº¦é¸æŠ
                        year_select_xpath = "//select[@name='KEYWORD_TTBLYR']"
                        year_select_element = WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.presence_of_element_located((By.XPATH, year_select_xpath)))
                        if not select_option_by_text(driver, year_select_element, str(year)):
                            print(f"     [è­¦å‘Š] å¹´åº¦ '{year}' ã®é¸æŠã«å¤±æ•—ã€‚ã“ã®åˆ†é‡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                            save_screenshot(driver, f"year_selection_failed_{year}_{field_name}", screenshots_dir); field_index += 1; continue
                        print(f"   å¹´åº¦ '{year}' ã‚’é¸æŠã—ã¾ã—ãŸã€‚"); time.sleep(SHORT_WAIT)
                        # è©³ç´°ã‚ªãƒ—ã‚·ãƒ§ãƒ³å±•é–‹
                        try:
                            adv_button_xpath = "//button[contains(@data-target, 'screensearch-cond-option-toggle-target')]"
                            advanced_options_button = WebDriverWait(driver, SHORT_WAIT).until(EC.element_to_be_clickable((By.XPATH, adv_button_xpath)))
                            target_selector = advanced_options_button.get_attribute('data-target')
                            target_element = driver.find_element(By.CSS_SELECTOR, target_selector)
                            if advanced_options_button and not target_element.is_displayed():
                                print("   å±•é–‹ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦è©³ç´°ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                                driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", advanced_options_button); time.sleep(0.5)
                                driver.execute_script("arguments[0].click();", advanced_options_button); time.sleep(1.5)
                            # else: print("   è©³ç´°ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¯æ—¢ã«å±•é–‹æ¸ˆã¿ã€ã¾ãŸã¯ãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚") # ãƒ­ã‚°çœç•¥å¯
                        except Exception as e: print(f"   è©³ç´°ã‚ªãƒ—ã‚·ãƒ§ãƒ³å±•é–‹ãƒœã‚¿ãƒ³ã®æ“ä½œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                        # åˆ†é‡é¸æŠ
                        field_select_xpath = "//select[@name='KEYWORD_FLD1CD']"
                        max_retries = 3; field_selected = False
                        for retry in range(max_retries):
                            try:
                                field_select_element = WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.element_to_be_clickable((By.XPATH, field_select_xpath)))
                                driver.execute_script("arguments[0].scrollIntoView({block: 'center', behavior: 'smooth'});", field_select_element); time.sleep(1.0)
                                if select_option_by_text(driver, field_select_element, field_name):
                                    print(f"   åˆ†é‡ '{field_name}' ã‚’é¸æŠã—ã¾ã—ãŸã€‚"); time.sleep(MEDIUM_WAIT); field_selected = True; break
                                else: print(f"   åˆ†é‡ '{field_name}' ã®é¸æŠã«å¤±æ•—ï¼ˆè©¦è¡Œ {retry+1}/{max_retries}ï¼‰")
                            except Exception as e:
                                print(f"   ãƒªãƒˆãƒ©ã‚¤ {retry+1}/{max_retries}: åˆ†é‡ '{field_name}' é¸æŠä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                                if retry < max_retries - 1:
                                     print("      ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ã—ã¦å†è©¦è¡Œã—ã¾ã™...")
                                     driver.refresh()
                                     WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.presence_of_element_located((By.TAG_NAME, "body"))); time.sleep(MEDIUM_WAIT)
                                     year_select_element_retry = WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.presence_of_element_located((By.XPATH, year_select_xpath)))
                                     select_option_by_text(driver, year_select_element_retry, str(year)); time.sleep(SHORT_WAIT)
                                else: print("      ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥å¾Œã®å†è©¦è¡Œã‚‚å¤±æ•—ã—ã¾ã—ãŸã€‚")
                                time.sleep(MEDIUM_WAIT)
                        if not field_selected:
                             print(f"     [è­¦å‘Š] åˆ†é‡ '{field_name}' ã®é¸æŠãŒ {max_retries} å›å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                             save_screenshot(driver, f"field_selection_failed_{field_name}_{year}", screenshots_dir); field_index += 1; continue
                        # å­¦å¹´ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹è§£é™¤
                        try:
                            cb_xpath = "//input[@name='KEYWORD_LVL' and @value='3']"
                            cb = WebDriverWait(driver, SHORT_WAIT).until(EC.presence_of_element_located((By.XPATH, cb_xpath)))
                            if cb.is_selected():
                                print("   å­¦å¹´ã€Œ3å¹´ã€ã®ãƒã‚§ãƒƒã‚¯ã‚’å¤–ã—ã¾ã™ã€‚")
                                driver.execute_script("arguments[0].click();", cb); time.sleep(0.5)
                        except TimeoutException: pass
                        except Exception as e_cb: print(f"           å­¦å¹´ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e_cb}")

                    # --- æ¤œç´¢å®Ÿè¡Œ ---
                    search_xpath = "//button[@data-action_id='SYLLABUS_SEARCH_KEYWORD_EXECUTE'] | //button[contains(text(), 'æ¤œç´¢')]"
                    search_button = WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.element_to_be_clickable((By.XPATH, search_xpath)))
                    print("   æ¤œç´¢ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã™...")
                    if not click_element(driver, search_button):
                        print("     [ã‚¨ãƒ©ãƒ¼] æ¤œç´¢ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯å¤±æ•—ã€‚ã“ã®åˆ†é‡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                        save_screenshot(driver, f"search_button_click_failed_{year}_{field_name}", screenshots_dir); field_index += 1; continue

                    # --- çµæœè¡¨ç¤ºå¾…æ©Ÿ ---
                    # æ‹¡å¼µã•ã‚ŒãŸçµæœã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼XPath
                    result_indicator_xpath = (
                        "//a[contains(@class, 'syllabus-detail')] | "
                        "//a[contains(@class, 'btn-info')] | "
                        "//div[contains(text(), 'è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“')] | "
                        "//ul[contains(@class, 'pagination')] | "
                        "//table[contains(@class, 'search-result')] | "
                        "//div[contains(text(), 'ä»¶') and contains(text(), 'ä¸­')] | "
                        "//div[@class='search-result-list']"
                    )
                    print("   æ¤œç´¢çµæœè¡¨ç¤ºå¾…æ©Ÿä¸­...")
                    # æ¤œç´¢çµæœã®å¾…æ©Ÿå‡¦ç†ã‚’æ”¹å–„ï¼ˆæœ€å¤§3å›ãƒªãƒˆãƒ©ã‚¤ï¼‰
                    max_search_retries = 3
                    for search_retry in range(max_search_retries):
                        try:
                            print(f"   æ¤œç´¢çµæœè¡¨ç¤ºå¾…æ©Ÿä¸­... (è©¦è¡Œ {search_retry + 1}/{max_search_retries})")
                            # ä¸€æ—¦çŸ­ã„ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã§è©¦ã—ã¦ã¿ã‚‹
                            try:
                                WebDriverWait(driver, min(30, current_element_timeout/2)).until(
                                    EC.presence_of_element_located((By.XPATH, result_indicator_xpath))
                                )
                                print("   æ¤œç´¢çµæœè¡¨ç¤ºå®Œäº†ã€‚")
                                break
                            except TimeoutException:
                                # ãƒšãƒ¼ã‚¸ãŒå®Œå…¨ã«èª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ãƒªãƒ­ãƒ¼ãƒ‰
                                if search_retry < max_search_retries - 1:
                                    print(f"   æ¤œç´¢çµæœè¡¨ç¤ºã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦å†è©¦è¡Œã—ã¾ã™... ({search_retry + 1}/{max_search_retries})")
                                    driver.refresh()
                                    time.sleep(MEDIUM_WAIT * 2)
                                    
                                    # æ¤œç´¢æ¡ä»¶ã‚’å†è¨­å®šã—ã¦æ¤œç´¢ãƒœã‚¿ãƒ³ã‚’å†åº¦ã‚¯ãƒªãƒƒã‚¯
                                    if not js_search_success:
                                        # å¹´åº¦é¸æŠ
                                        year_select_xpath = "//select[@name='KEYWORD_TTBLYR']"
                                        year_select_element = WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(
                                            EC.presence_of_element_located((By.XPATH, year_select_xpath))
                                        )
                                        select_option_by_text(driver, year_select_element, str(year))
                                        time.sleep(MEDIUM_WAIT)
                                        
                                        # åˆ†é‡é¸æŠ
                                        field_select_xpath = "//select[@name='KEYWORD_FLD1CD']"
                                        field_select_element = WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(
                                            EC.presence_of_element_located((By.XPATH, field_select_xpath))
                                        )
                                        select_option_by_text(driver, field_select_element, field_name)
                                        time.sleep(MEDIUM_WAIT)
                                    
                                    # æ¤œç´¢ãƒœã‚¿ãƒ³ã‚’å†ã‚¯ãƒªãƒƒã‚¯
                                    search_xpath = "//button[@data-action_id='SYLLABUS_SEARCH_KEYWORD_EXECUTE'] | //button[contains(text(), 'æ¤œç´¢')]"
                                    search_button = WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(
                                        EC.element_to_be_clickable((By.XPATH, search_xpath))
                                    )
                                    click_element(driver, search_button)
                                    
                                    # é•·ã‚ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã§æœ€çµ‚è©¦è¡Œ
                                    if search_retry == max_search_retries - 2:
                                        WebDriverWait(driver, current_element_timeout).until(
                                            EC.presence_of_element_located((By.XPATH, result_indicator_xpath))
                                        )
                                        print("   æ¤œç´¢çµæœè¡¨ç¤ºå®Œäº†ã€‚")
                                        break
                                else:
                                    # æœ€çµ‚è©¦è¡Œã§ã‚‚ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ãŸå ´åˆ
                                    raise TimeoutException(f"æ¤œç´¢çµæœã®è¡¨ç¤ºã« {max_search_retries} å›å¤±æ•—ã—ã¾ã—ãŸ")
                        except TimeoutException as e_timeout:
                            if search_retry == max_search_retries - 1:
                                print(f"     [ã‚¨ãƒ©ãƒ¼] æ¤œç´¢çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã›ã‚“ã€‚ã“ã®åˆ†é‡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                                save_screenshot(driver, f"search_timeout_{year}_{field_name}", screenshots_dir)
                                field_index += 1
                                field_processed_successfully = False
                                year_processed_successfully = False
                                break
                        except Exception as e_search:
                            print(f"     [ã‚¨ãƒ©ãƒ¼] æ¤œç´¢å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e_search}")
                            save_screenshot(driver, f"search_error_{year}_{field_name}", screenshots_dir)
                            field_index += 1
                            field_processed_successfully = False
                            year_processed_successfully = False
                            traceback.print_exc()
                            break

                    # ã‚ªãƒªã‚¸ãƒŠãƒ«ã‚³ãƒ¼ãƒ‰ã®ç¶šã (if field_processed_successfully ã‹ã‚‰)
                    time.sleep(MEDIUM_WAIT); print("   æ¤œç´¢çµæœè¡¨ç¤ºå®Œäº†ã€‚")

                    # --- è©²å½“ãªã—ãƒã‚§ãƒƒã‚¯ ---
                    try:
                        no_result_element = driver.find_element(By.XPATH, "//div[contains(text(), 'è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“')]")
                        if no_result_element.is_displayed():
                            print(f"   [æƒ…å ±] {year}å¹´åº¦ã€åˆ†é‡ '{field_name}' ã«è©²å½“ãƒ‡ãƒ¼ã‚¿ãªã—ã€‚")
                            field_index += 1; continue
                    except NoSuchElementException: pass

                    # --- ã‚½ãƒ¼ãƒˆé †å¤‰æ›´ (ç§‘ç›®åé †) ---
                    try:
                        sort_xpath = "//select[@name='SEARCH_RESULT_NARABIJUN']"
                        sort_element = WebDriverWait(driver, MEDIUM_WAIT).until(EC.presence_of_element_located((By.XPATH, sort_xpath)))
                        current_sort_value = Select(sort_element).first_selected_option.get_attribute('value')
                        if current_sort_value != '2':
                            print("   ã‚½ãƒ¼ãƒˆé †ã‚’ã€Œç§‘ç›®åé †ã€ã«å¤‰æ›´è©¦è¡Œ...")
                            if not select_option_by_text(driver, sort_element, "ç§‘ç›®åé †"):
                                try: Select(sort_element).select_by_value("2"); print("           ã‚½ãƒ¼ãƒˆé †ã‚’ Value='2' ã§é¸æŠã—ã¾ã—ãŸã€‚")
                                except Exception as e_sort_val:
                                    print(f"           [è­¦å‘Š] Value='2'ã§ã®ã‚½ãƒ¼ãƒˆå¤±æ•—: {e_sort_val}ã€‚JSã§è©¦è¡Œ...")
                                    try: driver.execute_script("arguments[0].value = '2'; arguments[0].dispatchEvent(new Event('change', { bubbles: true }));", sort_element); print("           JSã§ã‚½ãƒ¼ãƒˆé † Value='2' ã‚’è¨­å®šã—ã¾ã—ãŸã€‚")
                                    except Exception as e_js: print(f"           [è­¦å‘Š] JSã§ã®ã‚½ãƒ¼ãƒˆã‚‚å¤±æ•—: {e_js}")
                            else: print("           ã‚½ãƒ¼ãƒˆé †ã‚’ã€Œç§‘ç›®åé †ã€ã§é¸æŠã—ã¾ã—ãŸã€‚")
                            time.sleep(MEDIUM_WAIT)
                            WebDriverWait(driver, current_element_timeout).until(EC.presence_of_element_located((By.XPATH, result_indicator_xpath)))
                            time.sleep(MEDIUM_WAIT)
                        # else: print("   ã‚½ãƒ¼ãƒˆé †ã¯æ—¢ã«ã€Œç§‘ç›®åé †ã€ã§ã™ã€‚") # ãƒ­ã‚°çœç•¥å¯
                    except TimeoutException: pass
                    except Exception as e_sort: print(f"   [è­¦å‘Š] ã‚½ãƒ¼ãƒˆè¨­å®šã‚¨ãƒ©ãƒ¼: {e_sort}")

                    # --- ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ãƒ«ãƒ¼ãƒ— (é€æ¬¡å‡¦ç†) ---
                    last_processed_page_num = 0
                    processed_page_numbers = set()  # Add this to track which pages we've already processed

                    while True:
                        print(f"\n     --- ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ãƒ–ãƒ­ãƒƒã‚¯å‡¦ç†é–‹å§‹ (æœ€çµ‚å‡¦ç†ãƒšãƒ¼ã‚¸: {last_processed_page_num}) ---")
                        pagination_processed_in_block = False
                        current_page_links_processed_in_block = set()

                        # --- 1. ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒšãƒ¼ã‚¸å‡¦ç† ---
                        current_active_page_num = -1
                        try:
                            pagination_container = WebDriverWait(driver, MEDIUM_WAIT).until(EC.presence_of_element_located((By.XPATH, "//ul[contains(@class, 'pagination')]")))
                            try:
                                active_page_element = pagination_container.find_element(By.XPATH, ".//li[contains(@class, 'active')]/span | .//li[contains(@class, 'active')]/a")
                                current_active_page_num = int(normalize_text(active_page_element.text))
                                print(f"         ç¾åœ¨ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒšãƒ¼ã‚¸: {current_active_page_num}")
                            except (NoSuchElementException, ValueError) as e_active:
                                print(f"         ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒšãƒ¼ã‚¸ç•ªå·ã®å–å¾—ã«å¤±æ•—: {e_active}")
                                if last_processed_page_num == 0: print("         æœ€åˆã®ãƒšãƒ¼ã‚¸(1)ã¨ã—ã¦å‡¦ç†ã‚’è©¦ã¿ã¾ã™..."); current_active_page_num = 1
                                else: print("         [ã‚¨ãƒ©ãƒ¼] ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒšãƒ¼ã‚¸ã‚’ç‰¹å®šã§ããšã€å‡¦ç†ã‚’ç¶šè¡Œã§ãã¾ã›ã‚“ã€‚"); field_processed_successfully = False; year_processed_successfully = False; break

                            # Add check for already processed pages to avoid infinite loops
                            if current_active_page_num in processed_page_numbers:
                                print(f"         ãƒšãƒ¼ã‚¸ {current_active_page_num} ã¯æ—¢ã«å‡¦ç†æ¸ˆã¿ã§ã™ã€‚æ¬¡ã®ãƒšãƒ¼ã‚¸ã‚’è©¦è¡Œã—ã¾ã™ã€‚")
                            elif current_active_page_num > 0:  # Don't rely on last_processed_page_num check
                                print(f"         ãƒšãƒ¼ã‚¸ {current_active_page_num} ã‚’å‡¦ç†ã—ã¾ã™...")
                                # --- ãƒªãƒ³ã‚¯å–å¾—ã¨è©³ç´°å‡¦ç† (é€æ¬¡) ---
                                syllabus_link_xpath = ""
                                # For 2025 and later
                                if year >= 2025:
                                    syllabus_link_xpath = (
                                        "//a[contains(@class, 'syllabus-detail')] | "
                                        "//a[contains(@href, 'syllabus')] | "
                                        "//a[contains(@href, 'detail')] | "
                                        "//a[contains(@href, 'entno=')] | "  # Added for entno parameter
                                        "//a[contains(@onclick, 'syllabus')] | "
                                        "//a[contains(@onclick, 'detail')] | "
                                        "//a[contains(@onclick, 'entno=')] | "  # Added for entno parameter
                                        "//button[contains(@onclick, 'syllabus')] | "
                                        "//button[contains(@onclick, 'detail')] | "
                                        "//tr//td//a[contains(@href, 'syllabus') or contains(@href, 'entno=') or contains(@href, 'detail')]"  # Specific to table cells
                                    )
                                else:
                                    # For 2024 and earlier
                                    syllabus_link_xpath = (
                                        "//a[contains(@class, 'btn-info')] | "
                                        "//a[contains(@class, 'fa-book')] | "
                                        "//td//a[contains(@href, 'syllabus')] | "
                                        "//td//a[contains(@href, 'courses')] | "
                                        "//td//a[contains(@href, 'entno=')] | "  # Added for entno parameter
                                        "//a[contains(@title, 'ã‚·ãƒ©ãƒã‚¹')] | "
                                        "//span/a[contains(@href, 'syllabus') or contains(@href, 'courses') or contains(@href, 'entno=')] | "
                                        "//tr//td//a"  # This will capture all links in table cells for more thorough checking
                                    )

                                urls_on_page = []
                                buttons_on_page = []
                                processed_count_on_page = 0

                                try:
                                    # ã¾ãšä¸€èˆ¬çš„ãªãƒªãƒ³ã‚¯ãŒã‚ã‚‹ã‹ã‚’ç¢ºèª
                                    WebDriverWait(driver, MEDIUM_WAIT).until(EC.presence_of_element_located((By.TAG_NAME, "a")))
                                    print("         ãƒšãƒ¼ã‚¸ã®å®Œå…¨ãªãƒ­ãƒ¼ãƒ‰ã‚’å¾…æ©Ÿä¸­...")
                                    time.sleep(2)  # ã‚·ãƒ©ãƒã‚¹ãƒªãƒ³ã‚¯æŠ½å‡ºå‰ã«2ç§’ã®è¿½åŠ å¾…æ©Ÿ
                                    # ã™ã¹ã¦ã®ãƒªãƒ³ã‚¯ã‚’å–å¾—ã—ã¦èª¿æŸ»
                                    all_links = driver.find_elements(By.TAG_NAME, "a")
                                    print(f"         ãƒšãƒ¼ã‚¸ä¸Šã®ãƒªãƒ³ã‚¯æ•°: {len(all_links)}")
                                    
                                    # ã‚µãƒ³ãƒ—ãƒ«ãƒªãƒ³ã‚¯ã‚’è¡¨ç¤º
                                    for i, link in enumerate(all_links[:5]):
                                        link_text = link.text.strip() if link.text else "ãƒ†ã‚­ã‚¹ãƒˆãªã—"
                                        link_class = link.get_attribute("class") or "ã‚¯ãƒ©ã‚¹ãªã—"
                                        link_href = link.get_attribute("href") or "ãƒªãƒ³ã‚¯ãªã—"
                                        link_onclick = link.get_attribute("onclick") or "ãªã—"
                                        print(f"         ãƒªãƒ³ã‚¯{i+1}: ãƒ†ã‚­ã‚¹ãƒˆ={link_text}, ã‚¯ãƒ©ã‚¹={link_class}, URL={link_href}, onClick={link_onclick}")
                                    
                                    # ã‚·ãƒ©ãƒã‚¹è©³ç´°ãƒªãƒ³ã‚¯ã®æ¤œç´¢
                                    buttons_on_page = driver.find_elements(By.XPATH, syllabus_link_xpath)
                                    print(f"         ã‚·ãƒ©ãƒã‚¹ãƒªãƒ³ã‚¯æ•°: {len(buttons_on_page)}")
                                    
                                    # onclickå±æ€§ã‹ã‚‰URLã‚’å–å¾—ï¼ˆJSã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã®ãŸã‚ï¼‰
                                    js_urls = []
                                    try:
                                        # Replace the existing js_check script with this enhanced version
                                        js_check = r"""
                                        // å…¨ãƒšãƒ¼ã‚¸å†…ã®ã‚·ãƒ©ãƒã‚¹ãƒªãƒ³ã‚¯ã‚’å¾¹åº•çš„ã«æ¤œç´¢ã™ã‚‹æ‹¡å¼µç‰ˆ
                                        const syllabusUrls = [];

                                        // 1. ã™ã¹ã¦ã®ãƒ†ãƒ¼ãƒ–ãƒ«å†…ã®ãƒªãƒ³ã‚¯ã‚’æ¤œç´¢
                                        const tables = document.querySelectorAll('table');
                                        tables.forEach(table => {
                                            const elements = table.querySelectorAll('a, button');
                                            for (const el of elements) {
                                                // onClickå±æ€§ãŒã‚ã‚‹å ´åˆ - ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‹¡å¼µ
                                                if (el.onclick) {
                                                    const onclickStr = el.onclick.toString();
                                                    // ã‚·ãƒ©ãƒã‚¹é–¢é€£ã®æ–‡å­—åˆ—ã‚’å«ã‚€ã‹ç¢ºèª
                                                    if (onclickStr.includes('syllabus') || onclickStr.includes('detail') || 
                                                        onclickStr.includes('course') || onclickStr.includes('entno')) {
                                                        // è¤‡æ•°ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
                                                        let urlMatch = onclickStr.match(/window\.open\(['"]([^'"]+)['"]/);
                                                        if (!urlMatch) urlMatch = onclickStr.match(/location\.href=['"]([^'"]+)['"]/);
                                                        if (!urlMatch) urlMatch = onclickStr.match(/location\.assign\(['"]([^'"]+)['"]/);
                                                        if (urlMatch && urlMatch[1]) {
                                                            syllabusUrls.push(urlMatch[1]);
                                                        }
                                                    }
                                                }
                                                
                                                // hrefå±æ€§ãŒã‚ã‚‹å ´åˆ
                                                if (el.href) {
                                                    const href = el.href.toString();
                                                    if (href.includes('syllabus') || href.includes('detail') || 
                                                        href.includes('course') || href.includes('entno=')) {
                                                        syllabusUrls.push(href);
                                                    }
                                                }
                                            }
                                        });

                                        // 2. ãƒ†ãƒ¼ãƒ–ãƒ«å¤–ã‚‚å«ã‚ãŸå…¨ãƒšãƒ¼ã‚¸å†…ã®é–¢é€£ãƒªãƒ³ã‚¯ã‚’æ¤œç´¢
                                        const allLinks = document.querySelectorAll('a');
                                        allLinks.forEach(link => {
                                            if (link.href) {
                                                const href = link.href.toString();
                                                if (href.includes('syllabus') || href.includes('detail') || 
                                                    href.includes('course') || href.includes('entno=')) {
                                                    syllabusUrls.push(href);
                                                }
                                            }
                                        });

                                        // 3. data-hrefå±æ€§ã‚’æŒã¤è¦ç´ ã‚‚æ¤œç´¢
                                        const dataHrefElements = document.querySelectorAll('[data-href]');
                                        dataHrefElements.forEach(el => {
                                            const dataHref = el.getAttribute('data-href');
                                            if (dataHref && (dataHref.includes('syllabus') || dataHref.includes('detail') || 
                                                            dataHref.includes('course') || dataHref.includes('entno='))) {
                                                syllabusUrls.push(dataHref);
                                            }
                                        });

                                        // é‡è¤‡ã‚’é™¤å»ã—ã¦è¿”ã™
                                        return [...new Set(syllabusUrls)];
                                        """
                                        js_urls = driver.execute_script(js_check)
                                        print(f"         JavaScriptã§æ¤œå‡ºã—ãŸURLæ•°: {len(js_urls)}")
                                        for i, url in enumerate(js_urls[:3]):
                                            print(f"         JS-URL{i+1}: {url}")
                                    except Exception as js_e:
                                        print(f"         [è­¦å‘Š] JavaScript URLæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {js_e}")
                                    
                                    # SeleniumçµŒç”±ã§é€šå¸¸ã®URLã‚’æŠ½å‡º
                                    for button in buttons_on_page:
                                        href = button.get_attribute("href")
                                        if href and href.strip():
                                            urls_on_page.append(href)
                                        else:
                                            # onclickãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
                                            onclick = button.get_attribute("onclick")
                                            if onclick and ("syllabus" in onclick or "detail" in onclick):
                                                # onclick="window.open('URL')" ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰URLã‚’æŠ½å‡º
                                                match = re.search(r"window\.open\(['\"]([^'\"]+)['\"]", onclick)
                                                if match:
                                                    extracted_url = match.group(1)
                                                    urls_on_page.append(extracted_url)
                                    
                                    # JSã§å–å¾—ã—ãŸURLã‚‚è¿½åŠ 
                                    for js_url in js_urls:
                                        if js_url and js_url not in urls_on_page:
                                            urls_on_page.append(js_url)
                                    
                                    # é‡è¤‡ã‚’å‰Šé™¤
                                    urls_on_page = list(set(urls_on_page))

                                    print(f"         æœ€çµ‚çš„ã«æŠ½å‡ºã—ãŸURLæ•°: {len(urls_on_page)}")
                                    for i, url in enumerate(urls_on_page[:5]):
                                        print(f"         URL{i+1}: {url}")

                                    # Add debug logging for URL detection
                                    if not urls_on_page:
                                        print("         [è­¦å‘Š] ãƒšãƒ¼ã‚¸ä¸Šã®ã‚·ãƒ©ãƒã‚¹ãƒªãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚HTMLæ§‹é€ ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚")
                                        try:
                                            # ãƒšãƒ¼ã‚¸ã®ä¸»è¦æ§‹é€ ã‚’å‡ºåŠ›
                                            js_debug = """
                                            const tables = document.querySelectorAll('table');
                                            let tableInfo = [];
                                            tables.forEach((table, idx) => {
                                                tableInfo.push({
                                                    index: idx,
                                                    rows: table.rows.length,
                                                    links: table.querySelectorAll('a').length,
                                                    buttons: table.querySelectorAll('button').length
                                                });
                                            });
                                            return {
                                                tables: tableInfo,
                                                allLinks: document.querySelectorAll('a').length,
                                                allButtons: document.querySelectorAll('button').length,
                                                bodyHTML: document.body.innerHTML.substring(0, 500) + '...'  // å…ˆé ­500æ–‡å­—ã®ã¿
                                            };
                                            """
                                            debug_info = driver.execute_script(js_debug)
                                            print(f"         ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {len(debug_info['tables'])}")
                                            for i, table in enumerate(debug_info['tables']):
                                                print(f"         ãƒ†ãƒ¼ãƒ–ãƒ« #{i+1}: {table['rows']}è¡Œ, {table['links']}ãƒªãƒ³ã‚¯, {table['buttons']}ãƒœã‚¿ãƒ³")
                                            print(f"         ç·ãƒªãƒ³ã‚¯æ•°: {debug_info['allLinks']}, ç·ãƒœã‚¿ãƒ³æ•°: {debug_info['allButtons']}")
                                            print(f"         HTMLæ§‹é€ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {debug_info['bodyHTML']}")
                                            
                                            # ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’ä¿å­˜
                                            save_screenshot(driver, f"no_links_found_{year}_{field_name}_page{current_active_page_num}", screenshots_dir)
                                        except Exception as debug_e:
                                            print(f"         [è­¦å‘Š] ãƒ‡ãƒãƒƒã‚°æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {debug_e}")
                                    
                                    if len(urls_on_page) > 0:
                                        print(f"         {len(urls_on_page)} ä»¶ã®URLã‚’å‡¦ç†ã—ã¾ã™...")
                                        processed_count_on_page = 0
                                        field_total_attempts = 0
                                        field_error_count = 0
                                        consecutive_errors = 0
                                        
                                        # å„URLã‚’å‡¦ç†ï¼ˆé€æ¬¡ï¼‰
                                            # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦æœªå‡¦ç†ã®URLã®ã¿ã‚’å¯¾è±¡ã«ã™ã‚‹
                                        urls_to_process = []
                                        with OPENED_LINKS_LOCK:  # Properly use the lock when accessing shared state
                                            for url in urls_on_page:
                                                if url not in opened_links_this_year_field:
                                                    urls_to_process.append(url)
                                                    opened_links_this_year_field.add(url)  # Mark as processed immediately

                                        print(f"           {len(urls_to_process)} ä»¶ã®æœªå‡¦ç†URLã‚’å‡¦ç†ã—ã¾ã™...")

                                        # Sequential processing
                                        for index, url in enumerate(urls_to_process):
                                            print(f"           URL {index+1}/{len(urls_to_process)} å‡¦ç†ä¸­: {url}")
                                            try:
                                                details = process_single_url(
                                                    url, 
                                                    year, 
                                                    screenshots_dir, 
                                                    opened_links_this_year_field,
                                                    auth_cookies
                                                )
                                                if details:
                                                    scraped_data_all_years.append(details)
                                                    processed_count_on_page += 1
                                                    consecutive_errors = 0
                                                    print(f"           âœ… æˆåŠŸ: {url}")
                                                else:
                                                    print(f"           âŒ å¤±æ•— (è©³ç´°ãªã—): {url}")
                                                    field_error_count += 1
                                                    consecutive_errors += 1
                                            except Exception as e:
                                                print(f"           âŒ ã‚¨ãƒ©ãƒ¼: {url}: {str(e)}")
                                                field_error_count += 1
                                                consecutive_errors += 1
                                                
                                            # é€£ç¶šã‚¨ãƒ©ãƒ¼ã®ãƒã‚§ãƒƒã‚¯
                                            if ENABLE_AUTO_HALT and consecutive_errors >= CONSECUTIVE_ERROR_THRESHOLD:
                                                print(f"           [!!!] é€£ç¶šã‚¨ãƒ©ãƒ¼ ({consecutive_errors}å›) ã«ã‚ˆã‚Šå‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™")
                                                raise SystemExit(f"é€£ç¶šã‚¨ãƒ©ãƒ¼ ({consecutive_errors}å›) ã«ã‚ˆã‚Šåœæ­¢")
                                                
                                            # çŸ­ã„å¾…æ©Ÿï¼ˆã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›ï¼‰
                                            time.sleep(1)  # 1ç§’ã®å¾…æ©Ÿ
                                                    #try:
                                                        #details = future.result()
                                                        #if details:
                                                            #scraped_data_all_years.append(details)
                                                            #processed_count_on_page += 1
                                                            #consecutive_errors = 0
                                                            #print(f"           âœ… æˆåŠŸ: {url}")
                                                        #else:
                                                            #print(f"           âŒ å¤±æ•— (è©³ç´°ãªã—): {url}")
                                                            #field_error_count += 1
                                                    #except Exception as e:
                                                        #print(f"           âŒ ã‚¨ãƒ©ãƒ¼: {url}: {str(e)}")
                                                        #field_error_count += 1
                                                        #consecutive_errors += 1
                                                        
                                                    # é€£ç¶šã‚¨ãƒ©ãƒ¼ã®ãƒã‚§ãƒƒã‚¯
                                            # ãƒšãƒ¼ã‚¸å‡¦ç†å®Œäº†æ™‚ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
                                            if processed_count_on_page > 0:
                                                save_checkpoint(year, field_name, current_active_page_num, opened_links_this_year_field)
                                                print(f"         ãƒšãƒ¼ã‚¸ {current_active_page_num} ã®ä¸¦åˆ—å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ: {processed_count_on_page}ä»¶å‡¦ç†æ¸ˆ")
                                            
                                        # æœ€å¤§é€£ç¶šã‚¨ãƒ©ãƒ¼æ•°ã®ãƒã‚§ãƒƒã‚¯
                                        if ENABLE_AUTO_HALT and consecutive_errors >= CONSECUTIVE_ERROR_THRESHOLD:
                                            print(f"           [!!!] é€£ç¶šã‚¨ãƒ©ãƒ¼ ({consecutive_errors}å›) ã«ã‚ˆã‚Šå‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™")
                                            raise SystemExit(f"é€£ç¶šã‚¨ãƒ©ãƒ¼ ({consecutive_errors}å›) ã«ã‚ˆã‚Šåœæ­¢")
                                        
                                        field_total_attempts += 1
                                    
                                    # ãƒšãƒ¼ã‚¸å‡¦ç†å®Œäº†æ™‚ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜
                                    if processed_count_on_page > 0:
                                        save_checkpoint(year, field_name, current_active_page_num, opened_links_this_year_field)
                                        print(f"         ãƒšãƒ¼ã‚¸ {current_active_page_num} ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ: {processed_count_on_page}ä»¶å‡¦ç†æ¸ˆ")
                                    else:
                                        print(f"         å‡¦ç†å¯¾è±¡ã®URLãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

                                except TimeoutException:
                                    print(f"         [è­¦å‘Š] ã‚·ãƒ©ãƒã‚¹ãƒªãƒ³ã‚¯ã®èª­ã¿è¾¼ã¿ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
                                    buttons_on_page = []
                                except Exception as e:
                                    print(f"         [è­¦å‘Š] ã‚·ãƒ©ãƒã‚¹ãƒªãƒ³ã‚¯ã®å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                                    traceback.print_exc()
                                    buttons_on_page = []

                                # Mark this page as processed and update the last processed page number
                                processed_page_numbers.add(current_active_page_num)
                                last_processed_page_num = current_active_page_num
                                current_page_links_processed_in_block.add(current_active_page_num)
                                pagination_processed_in_block = True
                                print(f"         ãƒšãƒ¼ã‚¸ {current_active_page_num} ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

                            # --- 2. ã‚¯ãƒªãƒƒã‚¯å¯èƒ½ãªãƒšãƒ¼ã‚¸ç•ªå·å‡¦ç† ---
                            page_number_elements_info = []
                            page_number_links_xpath = ".//li[not(contains(@class, 'active')) and not(contains(@class, 'disabled'))]/a[number(text()) = number(text())]"
                            try:
                                pagination_container_refresh = WebDriverWait(driver, SHORT_WAIT).until(EC.presence_of_element_located((By.XPATH, "//ul[contains(@class, 'pagination')]")))
                                page_number_elements = pagination_container_refresh.find_elements(By.XPATH, page_number_links_xpath)
                            except (TimeoutException, NoSuchElementException): page_number_elements = []

                            for link_element in page_number_elements:
                                try:
                                    page_num = int(normalize_text(link_element.text))
                                    # Only add unprocessed pages to the navigation targets
                                    if page_num not in processed_page_numbers and page_num not in current_page_links_processed_in_block:
                                        page_number_elements_info.append((page_num, link_element))
                                except (ValueError, StaleElementReferenceException): continue

                        except (NoSuchElementException, TimeoutException) as e_paginate_find:
                            if len(processed_page_numbers) <= 1 and current_active_page_num <= 1:
                                print("         ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³è¦ç´ ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€æœ€åˆã®ãƒšãƒ¼ã‚¸ã®ã¿ã§ã™ã€‚")
                                if current_active_page_num > 0: pagination_processed_in_block = True
                            else: print(f"         [è­¦å‘Š] ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³è¦ç´ ã®å–å¾—ã«å¤±æ•—: {e_paginate_find}ã€‚")
                            if len(processed_page_numbers) > 0 and all(p in processed_page_numbers for p in range(1, max(processed_page_numbers) + 1)):
                                print("         ã™ã¹ã¦ã®ãƒšãƒ¼ã‚¸ã‚’å‡¦ç†ã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                                break
                            break
                        except Exception as e_paginate_outer:
                            print(f"         [ã‚¨ãƒ©ãƒ¼] ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e_paginate_outer}"); traceback.print_exc()
                            field_processed_successfully = False; year_processed_successfully = False; break

                        # Sort page elements by number to ensure we process them in order
                        page_number_elements_info.sort(key=lambda x: x[0])
                        clicked_page_link = False
                        
                        if page_number_elements_info:
                            print(f"         æœªå‡¦ç†ãƒšãƒ¼ã‚¸: {', '.join(str(p[0]) for p in page_number_elements_info)}")
                            for page_num, link_element_stub in page_number_elements_info:
                                print(f"         ãƒšãƒ¼ã‚¸ {page_num} ã¸ã®é·ç§»ã‚’è©¦ã¿ã¾ã™...")
                                try:
                                    link_to_click = WebDriverWait(driver, SHORT_WAIT).until(EC.element_to_be_clickable((By.XPATH, f"//ul[contains(@class, 'pagination')]//li/a[normalize-space(text())='{page_num}']")))
                                    if click_element(driver, link_to_click):
                                        print(f"         ãƒšãƒ¼ã‚¸ {page_num} ã¸é·ç§»ã€‚çµæœå¾…æ©Ÿä¸­...")
                                        WebDriverWait(driver, current_element_timeout).until(EC.presence_of_element_located((By.XPATH, result_indicator_xpath)))
                                        time.sleep(MEDIUM_WAIT)
                                        clicked_page_link = True
                                        break
                                    else: print(f"         [è­¦å‘Š] ãƒšãƒ¼ã‚¸ {page_num} ã®ã‚¯ãƒªãƒƒã‚¯ã«å¤±æ•—ã€‚æ¬¡ã®ãƒšãƒ¼ã‚¸ç•ªå·ã‚’è©¦ã—ã¾ã™ã€‚"); continue
                                except (TimeoutException, StaleElementReferenceException, NoSuchElementException) as e_click:
                                    print(f"         [è­¦å‘Š] ãƒšãƒ¼ã‚¸ {page_num} ã®æ¤œç´¢/ã‚¯ãƒªãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e_click}ã€‚æ¬¡ã®ãƒšãƒ¼ã‚¸ç•ªå·ã‚’è©¦ã—ã¾ã™ã€‚"); continue
                                except Exception as e_proc_outer:
                                    print(f"         [ã‚¨ãƒ©ãƒ¼] ãƒšãƒ¼ã‚¸ {page_num} ã®å‡¦ç†ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e_proc_outer}"); traceback.print_exc()
                                    field_processed_successfully = False; year_processed_successfully = False; break

                        if not field_processed_successfully: break
                        if clicked_page_link: continue

                        # --- 3. ã€Œæ¬¡ã¸ã€ãƒœã‚¿ãƒ³å‡¦ç† - only if no other pages to process ---
                        if not clicked_page_link and not page_number_elements_info:
                            try:
                                pagination_container_next = WebDriverWait(driver, SHORT_WAIT).until(EC.presence_of_element_located((By.XPATH, "//ul[contains(@class, 'pagination')]")))
                                next_xpath = ".//li[not(contains(@class, 'disabled'))]/a[contains(text(), 'æ¬¡') or contains(., 'Next')]"
                                next_button = pagination_container_next.find_element(By.XPATH, next_xpath)
                                print(f"\n         ã€Œæ¬¡ã¸ã€ãƒœã‚¿ãƒ³ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚ã‚¯ãƒªãƒƒã‚¯ã‚’è©¦ã¿ã¾ã™...")
                                if click_element(driver, next_button):
                                    print("         ã€Œæ¬¡ã¸ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã—ãŸã€‚çµæœå¾…æ©Ÿä¸­...")
                                    WebDriverWait(driver, current_element_timeout).until(EC.presence_of_element_located((By.XPATH, result_indicator_xpath)))
                                    time.sleep(MEDIUM_WAIT)
                                    pagination_processed_in_block = True
                                    continue
                                else: print("         [è­¦å‘Š] ã€Œæ¬¡ã¸ã€ãƒœã‚¿ãƒ³ã®ã‚¯ãƒªãƒƒã‚¯ã«å¤±æ•—ã€‚ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã™ã€‚"); break
                            except (NoSuchElementException, TimeoutException):
                                print(f"\n         ã€Œæ¬¡ã¸ã€ãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ç„¡åŠ¹ã§ã™ã€‚ã™ã¹ã¦ã®ãƒšãƒ¼ã‚¸ã‚’å‡¦ç†å®Œäº†ã—ã¾ã—ãŸã€‚"); break
                            except Exception as e_next:
                                print(f"         [ã‚¨ãƒ©ãƒ¼] ã€Œæ¬¡ã¸ã€ãƒœã‚¿ãƒ³ã®æ¤œç´¢/ã‚¯ãƒªãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e_next}ã€‚ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã™ã€‚"); traceback.print_exc(); break
                                
                        # --- ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ãƒ«ãƒ¼ãƒ—åˆ¤å®š ---
                        if not pagination_processed_in_block and len(page_number_elements_info) == 0:
                            print("         ã“ã®ãƒ–ãƒ­ãƒƒã‚¯ã§ãƒšãƒ¼ã‚¸å‡¦ç†ãŒè¡Œã‚ã‚Œãšã€æœªå‡¦ç†ãƒšãƒ¼ã‚¸ã‚‚ã‚ã‚Šã¾ã›ã‚“ã€‚ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                            break

                except (InvalidSessionIdException, NoSuchWindowException) as e_session_field:
                    print(f"\n[!!!] åˆ†é‡ '{field_name}' ({year}å¹´åº¦) å‡¦ç†ä¸­ã‚»ãƒƒã‚·ãƒ§ãƒ³/ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚¨ãƒ©ãƒ¼: {e_session_field}ã€‚WebDriverå†èµ·å‹•è©¦è¡Œã€‚")
                    # --- ä»¥ä¸‹ã®ifæ–‡ã‚’å‰Šé™¤ ---
                    # if not pause_on_error(f"WebDriver session error during field '{field_name}' processing", e_session_field, screenshot_path):
                    #     print("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ä¸­æ–­ã€‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                    #     sys.exit(1)
                    # --- ã“ã“ã¾ã§å‰Šé™¤ ---
                    if driver:
                        try: driver.quit()
                        except Exception as quit_err: print(f" WebDriverçµ‚äº†ã‚¨ãƒ©ãƒ¼: {quit_err}")
                    driver = None
                    driver = initialize_driver(CHROME_DRIVER_PATH, HEADLESS_MODE)
                    # Rest of existing code...
                    if not driver: print("[!!!] WebDriverå†åˆæœŸåŒ–å¤±æ•—ã€‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚"); raise Exception("WebDriverå†åˆæœŸåŒ–å¤±æ•—ã€‚")
                    try:
                        if not login(driver, USER_EMAIL, USER_PASSWORD, screenshots_dir): print("[!!!] å†ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—ã€‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚"); raise Exception("å†ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—ã€‚")
                    except Exception as relogin_e: print(f"[!!!] å†ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã«ã‚¨ãƒ©ãƒ¼: {relogin_e}"); raise
                    print(f" WebDriverå†èµ·å‹•ãƒ»å†ãƒ­ã‚°ã‚¤ãƒ³å®Œäº†ã€‚åˆ†é‡ '{field_name}' ({year}å¹´åº¦) å†è©¦è¡Œã€‚")
                    field_index -= 1; field_processed_successfully = False; year_processed_successfully = False
                except Exception as e_field_main:
                    print(f"     [ã‚¨ãƒ©ãƒ¼] åˆ†é‡ '{field_name}' ({year}å¹´åº¦) å‡¦ç†ä¸­ã‚¨ãƒ©ãƒ¼: {e_field_main}"); traceback.print_exc()
                    save_screenshot(driver, f"field_main_error_{year}_{field_name}", screenshots_dir); print(" ã“ã®åˆ†é‡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                    field_processed_successfully = False; year_processed_successfully = False
                finally:
                    if field_processed_successfully: print(f"===== åˆ†é‡: {field_name} ({year}å¹´åº¦) æ­£å¸¸çµ‚äº† =====")
                    else: print(f"===== åˆ†é‡: {field_name} ({year}å¹´åº¦) å‡¦ç†ä¸­æ–­ã¾ãŸã¯å¤±æ•— =====")
                    # åˆ†é‡å®Œäº†ã”ã¨ã€ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã«JSONæ›¸ãè¾¼ã¿
                    if scraped_data_all_years:
                        print(f"\n--- JSONãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–° ({'ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ç‚¹' if not field_processed_successfully else 'åˆ†é‡å®Œäº†æ™‚ç‚¹'}) ---")
                        final_data = aggregate_syllabus_data(scraped_data_all_years)
                        write_json_data(final_data, output_json_path)
                    # else: print("åé›†ãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚JSONã¯æ›´æ–°ã•ã‚Œã¾ã›ã‚“ã€‚") # ãƒ­ã‚°çœç•¥å¯

                field_index += 1
            # --- åˆ†é‡ãƒ«ãƒ¼ãƒ—çµ‚äº† ---

            if not year_processed_successfully: print(f"<<<<< {year}å¹´åº¦ ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Šã¾ã—ãŸãŒã€æ¬¡ã®å¹´åº¦ã¸é€²ã¿ã¾ã™ >>>>>")
            else: print(f"<<<<< {year}å¹´åº¦ ã®å‡¦ç†æ­£å¸¸çµ‚äº† >>>>>")
            year_index += 1
        # --- å¹´åº¦ãƒ«ãƒ¼ãƒ—çµ‚äº† ---

    # --- ã‚°ãƒ­ãƒ¼ãƒãƒ« try/except/finally ---
    except KeyboardInterrupt: print("\nã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å‰²ã‚Šè¾¼ã¿ã«ã‚ˆã‚Šå‡¦ç†ä¸­æ–­ã€‚")
    except SystemExit as e: print(f"\nã‚¹ã‚¯ãƒªãƒ—ãƒˆåœæ­¢ (çµ‚äº†ã‚³ãƒ¼ãƒ‰: {e.code})ã€‚")
    except Exception as e_global:
        print(f"\nâ˜…â˜…â˜… é‡å¤§ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã€å‡¦ç†ä¸­æ–­: {e_global} â˜…â˜…â˜…"); traceback.print_exc()
        if driver:
            print("é‡å¤§ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã®ãŸã‚ã€ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆã‚’è©¦ã¿ã¾ã™...")
            try: save_screenshot(driver, "fatal_error_global", screenshots_dir)
            except Exception as ss_err: print(f"[è­¦å‘Š] ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿå¾Œã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {ss_err}")
    finally:
        if driver:
            try: driver.quit(); print("\nãƒ–ãƒ©ã‚¦ã‚¶çµ‚äº†ã€‚")
            except Exception as qe: print(f"\nãƒ–ãƒ©ã‚¦ã‚¶çµ‚äº†æ™‚ã‚¨ãƒ©ãƒ¼: {qe}")

        print("\n=== æœ€çµ‚å‡¦ç†: JSONãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ ===")
        if scraped_data_all_years:
            print(f"åˆè¨ˆ {len(scraped_data_all_years)} ä»¶ã®ç”Ÿãƒ‡ãƒ¼ã‚¿å–å¾—ã€‚")
            print("\næœ€çµ‚ãƒ‡ãƒ¼ã‚¿é›†ç´„ä¸­...")
            final_json_data = aggregate_syllabus_data(scraped_data_all_years)
            if final_json_data: write_json_data(final_json_data, output_json_path)
            else: print("é›†ç´„å¾Œãƒ‡ãƒ¼ã‚¿ãªã—ã€‚JSONæœªä½œæˆã€‚")
        else: print("\næœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿åé›†ã•ã‚Œãšã€‚JSONæœªä½œæˆã€‚")

        end_time = time.time()
        elapsed_time = end_time - global_start_time
        print(f"\nå‡¦ç†æ™‚é–“: {elapsed_time:.2f} ç§’")
        print(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°çµ‚äº†: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")