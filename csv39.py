# -*- coding: utf-8 -*-
# --- „É©„Ç§„Éñ„É©„É™„Ç§„É≥„Éù„Éº„Éà ---
#Windows Virtual Environment Activation: .\.venv\Scripts\activate.ps1
#Mac Virtual Environment Activation: source .venv/bin/activate
from threading import Lock  # <-- ADD THIS
import json
import os
import sys # sys.exit()„ÅÆ„Åü„ÇÅ„Å´ËøΩÂä†
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait, Select
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import (
    NoSuchElementException, TimeoutException, ElementClickInterceptedException,
    WebDriverException, NoSuchWindowException, StaleElementReferenceException,
    InvalidSessionIdException
)
import time
import re
import traceback
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse
import random
import pickle
import datetime
# pprint „Çí„Ç§„É≥„Éù„Éº„Éà„Åó„Å¶„Çø„Éº„Éü„Éä„É´Âá∫Âäõ„ÇíÊï¥ÂΩ¢ („Ç™„Éó„Ç∑„Éß„É≥)
# from pprint import pprint
# ‚òÖ‚òÖ‚òÖ ‰∏¶ÂàóÂá¶ÁêÜ„É©„Ç§„Éñ„É©„É™„ÅØÂâäÈô§ ‚òÖ‚òÖ‚òÖ
#from concurrent.futures import ThreadPoolExecutor
#import concurrent.futures


# --- „Ç∞„É≠„Éº„Éê„É´Â§âÊï∞„ÉªË®≠ÂÆö ---
CHROME_DRIVER_PATH = None # ChromeDriver„ÅÆ„Éë„Çπ (None„ÅÆÂ†¥Âêà„ÅØËá™ÂãïÊ§úÂá∫)
OPENED_LINKS_LOCK = Lock()  # <-- ADD THIS
USER_EMAIL = 'Username' # „É≠„Ç∞„Ç§„É≥„Å´‰ΩøÁî®„Åô„Çã„É°„Éº„É´„Ç¢„Éâ„É¨„Çπ
USER_PASSWORD = 'Password' # „É≠„Ç∞„Ç§„É≥„Å´‰ΩøÁî®„Åô„Çã„Éë„Çπ„ÉØ„Éº„Éâ
OUTPUT_DIR_NAME = 'syllabus_output' # Âá∫Âäõ„Éá„Ç£„É¨„ÇØ„Éà„É™Âêç
OUTPUT_JSON_FILE = 'syllabus_data.json' # Âá∫ÂäõJSON„Éï„Ç°„Ç§„É´Âêç
TARGET_FIELDS = ["ÁâπË®≠ÁßëÁõÆ"] # „Çπ„ÇØ„É¨„Ç§„Éî„É≥„Ç∞ÂØæË±°„ÅÆÂàÜÈáé
#TARGET_FIELDS = ["Âü∫Áõ§ÁßëÁõÆ", "ÂÖàÁ´ØÁßëÁõÆ", "ÁâπË®≠ÁßëÁõÆ"] # „Çπ„ÇØ„É¨„Ç§„Éî„É≥„Ç∞ÂØæË±°„ÅÆÂàÜÈáé
TARGET_YEARS = [2024] # „Çπ„ÇØ„É¨„Ç§„Éî„É≥„Ç∞ÂØæË±°„ÅÆÂπ¥Â∫¶
#TARGET_YEARS = [2025, 2024, 2023] # „Çπ„ÇØ„É¨„Ç§„Éî„É≥„Ç∞ÂØæË±°„ÅÆÂπ¥Â∫¶
CONSECUTIVE_ERROR_THRESHOLD = 10  # ÈÄ£Á∂ö„Ç®„É©„Éº„ÅÆÊúÄÂ§ßË®±ÂÆπÊï∞ (ÂÄ§„ÇíÂ¢óÂä†)
ERROR_RATE_THRESHOLD = 0.8  # „Ç®„É©„ÉºÁéá„ÅÆË®±ÂÆπÈñæÂÄ§Ôºà80%„Å´Â¢óÂä†Ôºâ
MIN_SAMPLES_BEFORE_CHECK = 20  # „Ç®„É©„ÉºÁéá„ÉÅ„Çß„ÉÉ„ÇØÂâç„ÅÆÊúÄÂ∞è„Çµ„É≥„Éó„É´Êï∞ (Â¢óÂä†)
ENABLE_AUTO_HALT = True  # Ëá™ÂãïÂÅúÊ≠¢Ê©üËÉΩ„ÅÆÊúâÂäπ/ÁÑ°Âäπ
# ‚òÖ‚òÖ‚òÖ „Éò„ÉÉ„Éâ„É¨„Çπ„É¢„Éº„Éâ„ÇíÊúâÂäπÂåñ„Åó„Å¶È´òÈÄüÂåñ ‚òÖ‚òÖ‚òÖ
HEADLESS_MODE = False # True„Å´„Åô„Çã„Å®„Éò„ÉÉ„Éâ„É¨„Çπ„É¢„Éº„Éâ„ÅßÂÆüË°å
PAGE_LOAD_TIMEOUT = 60 # „Çø„Ç§„É†„Ç¢„Ç¶„ÉàÊôÇÈñìÂçäÊ∏õ (60‚Üí30Áßí)
ELEMENT_WAIT_TIMEOUT = 90 # Ë¶ÅÁ¥†ÂæÖÊ©üÊôÇÈñìÂçäÊ∏õ (90‚Üí45Áßí)
# ‚òÖ‚òÖ‚òÖ ÂæÖÊ©üÊôÇÈñì„ÇíÂ§ßÂπÖÁü≠Á∏Æ ‚òÖ‚òÖ‚òÖ
SHORT_WAIT = 0.4 # Áü≠„ÅÑÂæÖÊ©üÊôÇÈñì„ÇíÁü≠Á∏Æ (1.0‚Üí0.3Áßí)
MEDIUM_WAIT = 1.0 # ‰∏≠Á®ãÂ∫¶„ÅÆÂæÖÊ©üÊôÇÈñì„ÇíÁü≠Á∏Æ (1.3‚Üí0.5Áßí)
LONG_WAIT = 2.0 # Èï∑„ÅÑÂæÖÊ©üÊôÇÈñì„ÇíÁü≠Á∏Æ (1.5‚Üí0.7Áßí)
# ‚òÖ‚òÖ‚òÖ Ëã±Ë™û„Éö„Éº„Ç∏„Åß„ÅÆJS„É¨„É≥„ÉÄ„É™„É≥„Ç∞ÂæÖÊ©üÊôÇÈñìÁü≠Á∏Æ ‚òÖ‚òÖ‚òÖ
JS_RENDER_WAIT = 0.4 # Áßí (Â§ßÂπÖÁü≠Á∏Æ 1.0‚Üí0.3Áßí)

# --- ‚òÖ „Ç´„Çπ„Çø„É†‰æãÂ§ñ„ÇØ„É©„Çπ ‚òÖ ---
class MissingCriticalDataError(Exception):
    """ÂøÖÈ†à„Éá„Éº„Çø„Åæ„Åü„ÅØÂÆöÁæ©Ê∏à„Åø„Éá„Éº„Çø„ÅåÂèñÂæó„Åß„Åç„Å™„Åã„Å£„ÅüÂ†¥Âêà„Å´Áô∫Áîü„Åï„Åõ„Çã‰æãÂ§ñ"""
    pass

# --- XPathÂÆöÁæ© ---

# === Êó•Êú¨Ë™û„Éö„Éº„Ç∏Áî® XPath ===
# ‚òÖ‚òÖ‚òÖ 2025Âπ¥‰ª•ÈôçÁî® (Êó•Êú¨Ë™û) ‚òÖ‚òÖ‚òÖ
INFO_MAP_JA_2025 = {
    'name': ("ÁßëÁõÆÂêç", "//h2[@class='class-name']", "ÂêçÁß∞‰∏çÊòé"),
    'semester': ("Â≠¶Êúü", "//tr[th[normalize-space()='Âπ¥Â∫¶„ÉªÂ≠¶Êúü']]/td", "Â≠¶Êúü‰∏çÊòé"),
    'professor': ("ÊãÖÂΩìËÄÖÂêç", "//tr[th[contains(text(),'ÊãÖÂΩìËÄÖÂêç')]]/td", ""),
    'credits': ("Âçò‰Ωç", "//tr[th[contains(text(),'Âçò‰Ωç')]]/td", "Âçò‰Ωç‰∏çÊòé"),
    'field': ("ÂàÜÈáé", "//tr[th[contains(text(),'ÂàÜÈáé')]]/td", "ÂàÜÈáé‰∏çÊòé"),
    'location': ("ÊïôÂÆ§", "//tr[th[contains(text(),'ÊïôÂÆ§') or contains(text(),'ÈñãË¨õÂ†¥ÊâÄ')]]/td", "ÊïôÂÆ§‰∏çÊòé"),
    'day_period': ("ÊõúÊó•ÊôÇÈôê", "//tr[th[contains(text(),'ÊõúÊó•ÊôÇÈôê')]]/td", "ÊõúÊó•ÊôÇÈôê‰∏çÊòé"), # ÊõúÊó•ÊôÇÈôê„ÅÆXPath
    'selection_method': ("ÈÅ∏ÊäúÊñπÊ≥ï", "//tr[th[contains(text(),'ÈÅ∏ÊäúÊñπÊ≥ï')]]/td", ""), # ÈÅ∏ÊäúÊñπÊ≥ï„ÅÆXPath
    'class_format': ("ÊéàÊ•≠ÂÆüÊñΩÂΩ¢ÊÖã", "//tr[th[contains(text(),'ÊéàÊ•≠ÂÆüÊñΩÂΩ¢ÊÖã')]]/td", ""),
    'course_id_fallback': ("ÁôªÈå≤Áï™Âè∑(Ë°®)", "//tr[th[normalize-space()='ÁôªÈå≤Áï™Âè∑']]/td", None)
}

INFO_MAP_JA_2023_2024 = {
    'name': ("ÁßëÁõÆÂêç", "//h2/span[@class='title']", "ÂêçÁß∞‰∏çÊòé"),
    'semester': ("Â≠¶Êúü", "//div[contains(@class,'syllabus-info')]//dl/dt[normalize-space()='ÈñãË¨õÂπ¥Â∫¶„ÉªÂ≠¶Êúü']/following-sibling::dd[1]", "Â≠¶Êúü‰∏çÊòé"),
    'professor': ("ÊãÖÂΩìËÄÖÂêç", "//div[contains(@class,'syllabus-info')]//dl/dt[normalize-space()='ÊéàÊ•≠ÊïôÂì°Âêç']/following-sibling::dd[1]", ""),
    'credits': ("Âçò‰Ωç", "//div[contains(@class,'subject')]//dl/dt[normalize-space()='Âçò‰Ωç']/following-sibling::dd[1]", "Âçò‰Ωç‰∏çÊòé"),
    'field': ("ÂàÜÈáé", "//div[contains(@class,'subject')]//dl/dt[normalize-space()='ÂàÜÈáé']/following-sibling::dd[1]", "ÂàÜÈáé‰∏çÊòé"),
    'location': ("ÊïôÂÆ§", "//div[contains(@class,'syllabus-info')]//dl/dt[normalize-space()='ÈñãË¨õÂ†¥ÊâÄ']/following-sibling::dd[1]", "ÊïôÂÆ§‰∏çÊòé"),
    'day_period': ("ÊõúÊó•ÊôÇÈôê", "//div[contains(@class,'syllabus-info')]//dl/dt[normalize-space()='ÊõúÊó•„ÉªÊôÇÈôê']/following-sibling::dd[1]", "ÊõúÊó•ÊôÇÈôê‰∏çÊòé"),
    'selection_method': ("ÈÅ∏ÊäúÊñπÊ≥ï", "//div[contains(@class,'subject')]//dl/dt[normalize-space()='ÈÅ∏ÊäúÊñπÊ≥ï']/following-sibling::dd[1]", ""),
    'class_format': ("ÊéàÊ•≠ÂÆüÊñΩÂΩ¢ÊÖã", "//div[contains(@class,'syllabus-info')]//dl/dt[normalize-space()='ÂÆüÊñΩÂΩ¢ÊÖã']/following-sibling::dd[1]", ""),
    'course_id_fallback': ("ÁôªÈå≤Áï™Âè∑(Ë°®)", "//div[contains(@class,'subject')]//dl/dt[normalize-space()='ÁôªÈå≤Áï™Âè∑']/following-sibling::dd[1]", None)
}

# === ‚òÖ‚òÖ‚òÖ Ëã±Ë™û„Éö„Éº„Ç∏Áî® XPath (ÂÜçÂÆöÁæ©) ‚òÖ‚òÖ‚òÖ ===
# ‚òÖ‚òÖ‚òÖ 2025Âπ¥‰ª•ÈôçÁî® (Ëã±Ë™û) - „É≠„Ç∞„ÅÆHTML„Å´Âü∫„Å•„ÅÑ„Å¶‰øÆÊ≠£ ‚òÖ‚òÖ‚òÖ
INFO_MAP_EN_2025 = {
    'name': ("Course Title", "//h2[@class='class-name']", "Name Unknown"),
    'semester': ("Year/Semester", "//tr[th[normalize-space()='Academic Year/Semester']]/td", "Semester Unknown"),
    'professor': ("Lecturer(s)", "//tr[th[normalize-space()='Lecturer(s)']]/td", ""), # HTML„Åß„ÅØLecturer(s)„Å†„Å£„Åü
    'credits': ("Credits", "//tr[th[normalize-space()='Credit(s)']]/td", "Credits Unknown"),
    'field': ("Field", "//tr[th[normalize-space()='Field']]/td", "Field Unknown"),
    'location': ("Classroom", "//tr[th[normalize-space()='Classroom']]/td", "Classroom Unknown"),
    'day_period': ("Day/Period", "//tr[th[normalize-space()='Day/Period']]/td", "Day/Period Unknown"), # ÊõúÊó•ÊôÇÈôê„ÅÆXPath (Ëã±)
    'selection_method': ("Selection Method", "//tr[th[normalize-space()='Selection Method']]/td", ""), # Changed from 'Lottery Method'
    'class_format': ("Class Format", "//tr[th[normalize-space()='Class Format']]/td", ""),
    'course_id_fallback': ("Registration Number", "//tr[th[normalize-space()='Registration Number']]/td", None)
}

INFO_MAP_EN_2023_2024 = {
    'name': ("Course Title", "//h2/span[@class='title']", "Name Unknown"),
    'semester': ("Year/Semester", "//div[contains(@class,'syllabus-info')]//dl/dt[normalize-space()='Year/Semester']/following-sibling::dd[1]", "Semester Unknown"),
    'professor': ("Lecturer(s)", "//div[contains(@class,'syllabus-info')]//dl/dt[normalize-space()='Lecturer Name']/following-sibling::dd[1]", ""),
    'credits': ("Credits", "//div[contains(@class,'subject')]//dl/dt[normalize-space()='Unit']/following-sibling::dd[1]", "Credits Unknown"),
    'field': ("Field", "//div[contains(@class,'subject')]//dl/dt[normalize-space()='Field']/following-sibling::dd[1]", "Field Unknown"),
    'location': ("Classroom", "//div[contains(@class,'syllabus-info')]//dl/dt[normalize-space()='Location']/following-sibling::dd[1]", "Classroom Unknown"),
    'day_period': ("Day/Period", "//div[contains(@class,'syllabus-info')]//dl/dt[normalize-space()='Day of Week„ÉªPeriod']/following-sibling::dd[1]", "Day/Period Unknown"),
    'selection_method': ("Selection Method", "//div[contains(@class,'subject')]//dl/dt[normalize-space()='Selection Method']/following-sibling::dd[1]", ""),
    'class_format': ("Class Format", "//div[contains(@class,'syllabus-info')]//dl/dt[contains(text(),'Class Format')]/following-sibling::dd[1]", ""),
    'course_id_fallback': ("Registration Number", "//div[contains(@class,'subject')]//dl/dt[normalize-space()='Course Registration Number']/following-sibling::dd[1]", None)
}


# --- „Éò„É´„Éë„ÉºÈñ¢Êï∞ ---

def load_credentials():
    try:
        # Store this file outside the code directory or add to .gitignore
        config_path = os.path.join(os.path.dirname(__file__), 'config.json')
        with open(config_path, 'r') as f:
            config = json.load(f)
            return config.get('username'), config.get('password')
    except Exception as e:
        print(f"Error loading credentials: {e}")
        return None, None

USER_EMAIL, USER_PASSWORD = load_credentials()

if not USER_EMAIL or not USER_PASSWORD:
    print("Error: Couldn't load credentials from config.json")
    sys.exit(1)


def create_output_dirs(base_dir=OUTPUT_DIR_NAME):
    """Âá∫Âäõ„Éá„Ç£„É¨„ÇØ„Éà„É™„Çí‰ΩúÊàê„Åô„Çã"""
    logs_dir = os.path.join(base_dir, "logs")
    screenshots_dir = os.path.join(base_dir, "screenshots")
    for dir_path in [base_dir, logs_dir, screenshots_dir]:
        os.makedirs(dir_path, exist_ok=True)
    return base_dir, logs_dir, screenshots_dir

# È´òÈÄüÂåñÁâàÈñ¢Êï∞Áæ§

def save_screenshot(driver, prefix="screenshot", dir_path="screenshots"):
    """„Çπ„ÇØ„É™„Éº„É≥„Ç∑„Éß„ÉÉ„Éà„Çí‰øùÂ≠ò„Åô„Çã - ÈáçË¶Å„Å™„Ç®„É©„Éº„ÅÆ„Åø"""
    # ÈáçË¶Å„Å™„Ç®„É©„Éº„ÅÆ„Åø„Çπ„ÇØ„É™„Éº„É≥„Ç∑„Éß„ÉÉ„Éà
    if "critical" not in prefix and "error" not in prefix:
        return None  # Skip non-critical screenshots
    try:
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"{prefix}_{timestamp}.png"
        filepath = os.path.join(dir_path, filename)
        driver.save_screenshot(filepath)
        return filepath
    except:
        return None

def get_text_by_xpath(driver, xpath, default=""):
    """Get text from element using standard Selenium methods instead of JavaScript"""
    if not xpath:
        return default
    try:
        # Simple, reliable approach
        element = WebDriverWait(driver, SHORT_WAIT).until(
            EC.presence_of_element_located((By.XPATH, xpath))
        )
        text = element.text
        return normalize_text(text) if text else default
    except Exception:
        return default

def get_multiple_elements_text(driver, xpaths_dict):
    """Multiple XPaths to text values in a single JS call"""
    js_script = """
        function getTexts(xpaths) {
            var results = {};
            for (var key in xpaths) {
                try {
                    var element = document.evaluate(xpaths[key], document, null, 
                                XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;
                    results[key] = element ? element.textContent.trim() : "";
                } catch(e) {
                    results[key] = "";
                }
            }
            return results;
        }
        return getTexts(arguments[0]);
    """
    try:
        # Create dictionary of only xpath values
        xpath_values = {k: v[1] for k, v in xpaths_dict.items() if k != 'course_id_fallback'}
        results = driver.execute_script(js_script, xpath_values)
        
        # Apply normalization
        for key in results:
            results[key] = normalize_text(results[key])
            
        return results
    except:
        # Fallback to traditional method
        return {k: get_text_by_xpath(driver, v[1], v[2]) 
                for k, v in xpaths_dict.items() if k != 'course_id_fallback'}


def process_single_url(syllabus_url, year, screenshots_dir, opened_links_this_year_field, auth_cookies=None):
    """Process a single syllabus URL with session recovery capabilities"""
    url_start_time = time.time()
    course_id = "unknown"
    original_url = None  # Initialize outside try-block to avoid scope issues
    max_retries = 2  # Add retry limit
    
    for attempt in range(max_retries):
        try:
            driver = globals()['driver']
            # Store original URL FIRST before any operations that might fail
            original_url = driver.current_url
            
            print(f"\n[{time.strftime('%H:%M:%S')}] üîç Processing URL: {syllabus_url}")
            
            # Direct navigation instead of tab-based approach
            driver.get(syllabus_url)
            
            # Wait for page to load properly
            WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            time.sleep(MEDIUM_WAIT)
            
            # Process the syllabus details
            print(f"[{time.strftime('%H:%M:%S')}] üìä Extracting syllabus details")
            details = get_syllabus_details(driver, year, screenshots_dir)
            
            # Extract identifying information for logging
            if details:
                course_id = details.get('course_id', 'unknown')
                course_name = details.get('translations', {}).get('ja', {}).get('name', 'Unknown')
                professor = details.get('professor_ja', 'Unknown')
                field = details.get('field_ja', 'Unknown')
            
            # Return to search results page
            print(f"[{time.strftime('%H:%M:%S')}] üîô Returning to search results page")
            driver.get(original_url)
            time.sleep(SHORT_WAIT)
            
            # Calculate elapsed time
            elapsed_time = time.time() - url_start_time
            
            # Log the result
            if details:
                print(f"[{time.strftime('%H:%M:%S')}] ‚úÖ SUCCESS ({elapsed_time:.2f}s): ID:{course_id} | {course_name} | Prof:{professor} | Field:{field}")
                return details
            else:
                print(f"[{time.strftime('%H:%M:%S')}] ‚ùå FAILED ({elapsed_time:.2f}s): {syllabus_url}")
                # If we've tried multiple times already, give up
                if attempt == max_retries - 1:
                    return None
                # Otherwise try again
                print(f"[{time.strftime('%H:%M:%S')}] üîÑ Retrying... (Attempt {attempt+2}/{max_retries})")
                time.sleep(MEDIUM_WAIT)
                
        except InvalidSessionIdException as e_session:
            elapsed_time = time.time() - url_start_time
            print(f"[{time.strftime('%H:%M:%S')}] üîÑ SESSION ERROR ({elapsed_time:.2f}s): {str(e_session)} | URL: {syllabus_url}")
            
            # Try to recover the WebDriver session
            if recover_driver_session():
                # If recovery succeeded and this wasn't our last attempt, retry
                if attempt < max_retries - 1:
                    print(f"[{time.strftime('%H:%M:%S')}] üîÑ Session recovered, retrying... (Attempt {attempt+2}/{max_retries})")
                    try:
                        # Navigate back to search results
                        driver = globals()['driver']  # Get the new driver
                        driver.get('https://gslbs.keio.jp/syllabus/search')
                        time.sleep(MEDIUM_WAIT)
                        
                        # Re-execute the search with the same criteria
                        js_script = """
                            async function setSearchCriteria(year, fieldName) {
                                try {
                                    var yearSelect = document.querySelector('select[name="KEYWORD_TTBLYR"]');
                                    if (yearSelect) { 
                                        yearSelect.value = year; 
                                        yearSelect.dispatchEvent(new Event('change', {bubbles:true})); 
                                    }
                                    
                                    var toggleButton = document.querySelector('button[data-target*="screensearch-cond-option-toggle-target"]');
                                    if (toggleButton) {
                                        var toggleTarget = document.querySelector(toggleButton.getAttribute('data-target'));
                                        if (toggleTarget && !toggleTarget.classList.contains('show')) {
                                            toggleButton.click(); 
                                            await new Promise(r => setTimeout(r, 700));
                                        }
                                    }
                                    
                                    var fieldSelect = document.querySelector('select[name="KEYWORD_FLD1CD"]');
                                    if (fieldSelect) {
                                        for (let i = 0; i < fieldSelect.options.length; i++) {
                                            if (fieldSelect.options[i].text.trim() === fieldName) {
                                                fieldSelect.selectedIndex = i; 
                                                fieldSelect.dispatchEvent(new Event('change', {bubbles:true}));
                                                break;
                                            }
                                        }
                                    }
                                    
                                    // Click search button
                                    var searchBtn = document.querySelector('button[data-action_id="SYLLABUS_SEARCH_KEYWORD_EXECUTE"]');
                                    if (searchBtn) {
                                        searchBtn.click();
                                        return true;
                                    }
                                    return false;
                                } catch (error) { 
                                    return false; 
                                }
                            }
                            return await setSearchCriteria(arguments[0], arguments[1]);
                        """
                        driver.execute_script(js_script, str(year), "ÁâπË®≠ÁßëÁõÆ")
                        time.sleep(MEDIUM_WAIT * 2)  # Wait for search results
                        
                        # Continue to next attempt
                        continue
                    except Exception as e_recovery:
                        print(f"[{time.strftime('%H:%M:%S')}] ‚ö†Ô∏è Recovery navigation failed: {str(e_recovery)}")
                else:
                    print(f"[{time.strftime('%H:%M:%S')}] ‚ùå Max retries reached for this URL")
            
            # If recovery failed or max retries reached, return None
            return None
            
        except Exception as e:
            # Calculate elapsed time for errors too
            elapsed_time = time.time() - url_start_time
            print(f"[{time.strftime('%H:%M:%S')}] ‚ùå ERROR ({elapsed_time:.2f}s): {str(e)} | URL: {syllabus_url}")
            
            # Try to recover by returning to the original page if possible
            if original_url:  # Only attempt if original_url was successfully captured
                try:
                    driver.get(original_url)
                    time.sleep(SHORT_WAIT)
                except Exception as e_recovery:
                    print(f"[{time.strftime('%H:%M:%S')}] ‚ö†Ô∏è Recovery failed: {str(e_recovery)}")
            
            # If we've tried multiple times already, give up
            if attempt == max_retries - 1:
                return None
            # Otherwise try again after a short delay
            print(f"[{time.strftime('%H:%M:%S')}] üîÑ Retrying... (Attempt {attempt+2}/{max_retries})")
            time.sleep(MEDIUM_WAIT)
    
    # If we've gone through all retries and still failed
    return None

def select_option_by_text(driver, select_element, text):
    """„Çª„É¨„ÇØ„ÉàË¶ÅÁ¥†„Åã„ÇâÊåáÂÆö„Åï„Çå„Åü„ÉÜ„Ç≠„Çπ„Éà„ÅÆ„Ç™„Éó„Ç∑„Éß„É≥„ÇíÈÅ∏Êäû„Åô„Çã (ÊúÄÈÅ©ÂåñÁâà)"""
    try:
        # JavaScript„ÅßÁõ¥Êé•ÈÅ∏Êäû (È´òÈÄüÂåñ)
        js_script = """
            // È´òÈÄü„Çª„É¨„ÇØ„Ç∑„Éß„É≥
            let found = false;
            let select = arguments[0];
            let targetText = arguments[1];
            
            // „Åæ„ÅöÂÆåÂÖ®‰∏ÄËá¥„ÇíË©¶„ÅôÔºàÊúÄÈÄüÔºâ
            for(let i = 0; i < select.options.length; i++) {
                if(select.options[i].text.trim() === targetText) {
                    select.selectedIndex = i;
                    select.dispatchEvent(new Event('change', {bubbles:true}));
                    return true;
                }
            }
            
            // ÈÉ®ÂàÜ‰∏ÄËá¥„ÇíË©¶„Åô
            for(let i = 0; i < select.options.length; i++) {
                if(select.options[i].text.trim().includes(targetText)) {
                    select.selectedIndex = i;
                    select.dispatchEvent(new Event('change', {bubbles:true}));
                    return true;
                }
            }
            
            return false;
        """
        result = driver.execute_script(js_script, select_element, text)
        if result:
            return True
            
        # JavaScript„ÅßÂ§±Êïó„Åó„ÅüÂ†¥Âêà„ÅÆ„ÅøSelenium„ÇíË©¶„Åô
        # ÂÖÉ„ÅÆ„Ç≥„Éº„Éâ„ÇíÊÆã„Çä„Å®„Åó„Å¶‰ΩøÁî®
        
        return False
    except Exception:
        return False

def normalize_text(text):
    """„ÉÜ„Ç≠„Çπ„Éà„ÇíÊ≠£Ë¶èÂåñ„Åô„Çã (ÂÖ®Ëßí„Çπ„Éö„Éº„Çπ„ÇíÂçäËßí„Å´„ÄÅÈÄ£Á∂öÁ©∫ÁôΩ„Çí1„Å§„Å´)"""
    if isinstance(text, str):
        text = text.replace('„ÄÄ', ' ')
        text = re.sub(r'\s+', ' ', text)
        return text.strip()
    return ""

def normalize_field(field_text):
    """ÂàÜÈáéË°®Ë®ò„ÇíÊ≠£Ë¶èÂåñ„Åô„Çã"""
    if not field_text:
        return field_text
        
    # ÂÖàÁ´ØÁßëÁõÆÁí∞Â¢ÉÊÉÖÂ†±Á≥ª ‚Üí ÂÖàÁ´ØÁßëÁõÆ-Áí∞Â¢ÉÊÉÖÂ†±Á≥ª
    if 'ÂÖàÁ´ØÁßëÁõÆ' in field_text and '-' not in field_text:
        # Find where the prefix ends and add the hyphen
        for i in range(len('ÂÖàÁ´ØÁßëÁõÆ'), len(field_text)):
            if field_text[i] in 'Áí∞ÂÖàÁ∑èÊîøÊÉÖÁµå':  # Common first characters of field names
                return field_text[:i] + '-' + field_text[i:]
    return field_text

def normalize_credits(credits_text, language='en'):
    """Âçò‰ΩçË°®Ë®ò„ÇíÊ≠£Ë¶èÂåñ„Åô„Çã"""
    if not credits_text:
        return credits_text
        
    # Extract just the number using regex
    number_match = re.search(r'\d+', credits_text)
    if not number_match:
        return credits_text  # If no number found, return as-is
    
    number = number_match.group()
    
    # Format according to language
    if language == 'en':
        return f"{number} Credits"
    else:  # Japanese
        return f"{number}Âçò‰Ωç"

def parse_professor_names(ja_names_text, en_names_text=None):
    """ÊïôÊéàÂêç„Çí„Çª„Éü„Ç≥„É≠„É≥„ÅßÂå∫Âàá„Å£„Å¶Ê≠£„Åó„Åè„Éë„Éº„Çπ„Åó„ÄÅÊó•Ëã±„ÅÆÂêçÂâç„ÇíÂØæÂøú‰ªò„Åë„Çã"""
    ja_names = []
    en_names = []
    
    # Parse Japanese names
    if ja_names_text:
        if ';' in ja_names_text:
            ja_names = [name.strip() for name in ja_names_text.split(';') if name.strip()]
        else:
            ja_names = [name.strip() for name in ja_names_text.split(',') if name.strip()]
            # If there's only one entry but it has a space (like "‰∏Ä„ÉéÁÄ¨ ÂèãÂçö"), treat it as one name
            if len(ja_names) == 1 and ' ' in ja_names[0]:
                ja_names = [ja_names[0]]
    
    # Parse English names
    if en_names_text:
        if ';' in en_names_text:
            en_names = [name.strip() for name in en_names_text.split(';') if name.strip()]
        else:
            # For English names with format "LASTNAME, FIRSTNAME"
            # we need special handling to avoid splitting a single name
            if ',' in en_names_text and ';' not in en_names_text:
                # Try to detect if this is multiple professors or just one with lastname, firstname format
                comma_parts = en_names_text.split(',')
                if len(comma_parts) == 2 and not any(p.strip().isupper() for p in comma_parts):
                    # Likely a single name in "Lastname, Firstname" format
                    en_names = [en_names_text.strip()]
                else:
                    # Multiple names separated by commas
                    en_names = [name.strip() for name in comma_parts if name.strip()]
            else:
                en_names = [en_names_text.strip()]
    
    # Match names or use defaults
    num_ja_names = len(ja_names)
    num_en_names = len(en_names)
    
    # Create pairs of names
    professors = []
    for i in range(max(num_ja_names, num_en_names)):
        ja_name = ja_names[i] if i < num_ja_names else ""
        en_name = en_names[i] if i < num_en_names else ja_name
        
        professors.append({
            "ja": ja_name,
            "en": en_name
        })
    
    return professors
    return professors

def click_element(driver, element, wait_time=SHORT_WAIT):
    """Click an element with safer approach"""
    try:
        WebDriverWait(driver, wait_time).until(EC.element_to_be_clickable(element))
        element.click()
        time.sleep(SHORT_WAIT)  # Give time for the click to register
        return True
    except Exception:
        try:
            # Only use JavaScript click as fallback
            driver.execute_script("arguments[0].scrollIntoView(true);", element)
            time.sleep(SHORT_WAIT)
            driver.execute_script("arguments[0].click();", element)
            time.sleep(SHORT_WAIT)
            return True
        except Exception:
            return False


def generate_english_url(current_url):
    """ÁèæÂú®„ÅÆURL„Å´ lang=en „Éë„É©„É°„Éº„Çø„ÇíËøΩÂä†/ÁΩÆÊèõ„Åó„Å¶Ëã±Ë™û„Éö„Éº„Ç∏„ÅÆURL„ÇíÁîüÊàê„Åô„Çã"""
    try:
        parsed_url = urlparse(current_url)
        query_params = parse_qs(parsed_url.query)
        query_params['lang'] = ['en'] # lang„Éë„É©„É°„Éº„Çø„Çíen„Å´Ë®≠ÂÆöÔºàÂ≠òÂú®„Åô„Çå„Å∞‰∏äÊõ∏„ÅçÔºâ
        new_query = urlencode(query_params, doseq=True) # „ÇØ„Ç®„É™ÊñáÂ≠óÂàó„ÇíÂÜçÊßãÁØâ
        # Êñ∞„Åó„ÅÑ„ÇØ„Ç®„É™„ÅßURL„ÇíÂÜçÊßãÁØâ
        english_url = urlunparse((
            parsed_url.scheme, parsed_url.netloc, parsed_url.path,
            parsed_url.params, new_query, parsed_url.fragment
        ))
        return english_url
    except Exception as e:
        print(f"     [Ë≠¶Âëä] Ëã±Ë™ûURL„ÅÆÁîüÊàê„Å´Â§±Êïó: {e}„ÄÇÂÖÉ„ÅÆURL„ÇíËøî„Åó„Åæ„Åô: {current_url}")
        return current_url

# --- ‚òÖ‚òÖ‚òÖ ËøΩÂä†: Â≠¶ÊúüÊäΩÂá∫„Éò„É´„Éë„ÉºÈñ¢Êï∞ ‚òÖ‚òÖ‚òÖ ---
def extract_season(semester_text):
    """Â≠¶ÊúüÊñáÂ≠óÂàó„Åã„ÇâÂ≠£ÁØÄ ("spring", "fall", "full year", "summer", "winter", "unknown") „ÇíÊäΩÂá∫„Åô„Çã"""
    if not isinstance(semester_text, str):
        return "unknown"

    text_lower = semester_text.lower()

    # Ëã±Ë™û„ÅÆÂ≠£ÁØÄ„ÇíÂÑ™ÂÖà
    if "spring" in text_lower: return "spring"
    if "fall" in text_lower or "autumn" in text_lower: return "fall"
    if "summer" in text_lower: return "summer" # Summer„ÇÇËÄÉÊÖÆ
    if "winter" in text_lower: return "winter" # Winter„ÇÇËÄÉÊÖÆ
    if "full year" in text_lower or "ÈÄöÂπ¥" in semester_text: return "full year" # ÈÄöÂπ¥„ÇÇËÄÉÊÖÆ

    # Êó•Êú¨Ë™û„ÅÆÂ≠£ÁØÄ
    if "Êò•" in semester_text: return "spring"
    if "Áßã" in semester_text: return "fall"
    if "Â§è" in semester_text: return "summer"
    if "ÂÜ¨" in semester_text: return "winter"

    # „Å©„Å°„Çâ„Åß„ÇÇ„Å™„Åë„Çå„Å∞‰∏çÊòé
    return "unknown"

def display_scraped_info(syllabus_details, title="Scraped Syllabus Information"):
    """Display scraped syllabus information in a readable format for visual verification"""
    if not syllabus_details:
        print("\n=== No syllabus details found ===\n")
        return
        
    print(f"\n{'='*60}")
    print(f"=== {title} ===")
    print(f"{'='*60}")
    
    print(f"Course ID: {syllabus_details.get('course_id', 'N/A')}")
    print(f"Year: {syllabus_details.get('year_scraped', 'N/A')}")
    print(f"Semester: {syllabus_details.get('semester', 'N/A')}")
    
    # Display Japanese data
    print("\n--- JAPANESE DATA ---")
    ja_data = syllabus_details.get('translations', {}).get('ja', {})
    for key, value in ja_data.items():
        print(f"{key}: {value}")
    
    # Display English data
    print("\n--- ENGLISH DATA ---")
    en_data = syllabus_details.get('translations', {}).get('en', {})
    for key, value in en_data.items():
        print(f"{key}: {value}")
    
    # Display other important fields
    print(f"\nProfessor (JA): {syllabus_details.get('professor_ja', 'N/A')}")
    print(f"Name (JA): {syllabus_details.get('name_ja', 'N/A')}")
    print(f"Field (JA): {syllabus_details.get('field_ja', 'N/A')}")
    print(f"Credits (JA): {syllabus_details.get('credits_ja', 'N/A')}")
    
    print(f"{'='*60}\n")

def is_error_page(driver):
    """
    Ê§úÂá∫„Åó„Åü„Éö„Éº„Ç∏„Åå„Ç®„É©„Éº„Éö„Éº„Ç∏„Åã„Å©„ÅÜ„Åã„ÇíÁ¢∫Ë™ç„Åô„Çã
    """
    try:
        # „Çø„Ç§„Éà„É´„ÉÅ„Çß„ÉÉ„ÇØ
        page_title = driver.title
        if "Error" in page_title or "404" in page_title:
            print("           [ÊÉÖÂ†±] „Ç®„É©„Éº„Éö„Éº„Ç∏„ÅÆ„Çø„Ç§„Éà„É´„ÇíÊ§úÂá∫„Åó„Åæ„Åó„Åü„ÄÇ„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åô„ÄÇ")
            return True
            
        # „Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„ÅÆÊ§úÂá∫
        error_messages = [
            "//h1[contains(text(), 'Error')]",
            "//p[contains(text(), '„Éö„Éº„Ç∏„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì')]",
            "//p[contains(text(), 'Page Not Found')]",
            "//div[contains(text(), '„Éö„Éº„Ç∏„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì')]",
            "//div[contains(text(), 'Page Not Found')]"
        ]
        
        for xpath in error_messages:
            try:
                elements = driver.find_elements(By.XPATH, xpath)
                if elements and any(element.is_displayed() for element in elements):
                    print(f"           [ÊÉÖÂ†±] „Ç®„É©„Éº„Éö„Éº„Ç∏„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÊ§úÂá∫„Åó„Åæ„Åó„Åü: {xpath}")
                    return True
            except Exception:
                continue
                
        # URL„ÉÅ„Çß„ÉÉ„ÇØ
        current_url = driver.current_url
        if "error" in current_url.lower() or "appMsg" in current_url:
            print(f"           [ÊÉÖÂ†±] „Ç®„É©„Éº„Éö„Éº„Ç∏„ÅÆURL„Éë„Çø„Éº„É≥„ÇíÊ§úÂá∫: {current_url}")
            return True
            
        return False
    except Exception as e:
        print(f"           [Ë≠¶Âëä] „Ç®„É©„Éº„Éö„Éº„Ç∏„ÉÅ„Çß„ÉÉ„ÇØ‰∏≠„Å´‰æãÂ§ñ„ÅåÁô∫Áîü: {e}")
        return False

# „Çπ„ÇØ„É™„Éó„ÉàÂÜÖ„ÅßÁâπÂÆö„ÅÆURL„Çí„ÉÜ„Çπ„Éà„Åô„ÇãÂ†¥Âêà„Å´ËøΩÂä†„Åß„Åç„Çã„Éá„Éê„ÉÉ„Ç∞„Ç≥„Éº„Éâ

def test_error_page_detection(driver, test_url):
    """
    „Ç®„É©„Éº„Éö„Éº„Ç∏Ê§úÂá∫Ê©üËÉΩ„Çí„ÉÜ„Çπ„Éà„Åô„ÇãÈñ¢Êï∞
    """
    print(f"\n=== „Ç®„É©„Éº„Éö„Éº„Ç∏Ê§úÂá∫„ÉÜ„Çπ„ÉàÈñãÂßã: {test_url} ===")
    try:
        # URL„Å´ÁßªÂãï
        driver.get(test_url)
        WebDriverWait(driver, min(30, ELEMENT_WAIT_TIMEOUT)).until(EC.presence_of_element_located((By.TAG_NAME, "body")))
        # time.sleepÂâäÈô§ - Âç≥ÊôÇÂá¶ÁêÜ„Å´Â§âÊõ¥
        
        # „Éö„Éº„Ç∏ÊÉÖÂ†±Âá∫Âäõ
        print(f"„Éö„Éº„Ç∏„Çø„Ç§„Éà„É´: {driver.title}")
        print(f"URL: {driver.current_url}")
        
        # „Ç®„É©„Éº„Éö„Éº„Ç∏Ê§úÂá∫„ÉÜ„Çπ„Éà
        is_error = is_error_page(driver)
        print(f"„Ç®„É©„Éº„Éö„Éº„Ç∏Âà§ÂÆöÁµêÊûú: {'„Ç®„É©„Éº„Éö„Éº„Ç∏„Åß„Åô' if is_error else '„Ç®„É©„Éº„Éö„Éº„Ç∏„Åß„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì'}")
        
        # „Éö„Éº„Ç∏„ÅÆHTMLÊßãÈÄ†„Çí„Éá„Éê„ÉÉ„Ç∞Âá∫Âäõ
        try:
            h1_elements = driver.find_elements(By.TAG_NAME, "h1")
            print(f"H1Ë¶ÅÁ¥†Êï∞: {len(h1_elements)}")
            for i, el in enumerate(h1_elements):
                print(f"  H1 #{i+1}: {el.text}")
            
            p_elements = driver.find_elements(By.TAG_NAME, "p")
            print(f"pË¶ÅÁ¥†Êï∞: {len(p_elements)}")
            for i, el in enumerate(p_elements[:5]):  # ÊúÄÂàù„ÅÆ5„Å§„Å†„ÅëË°®Á§∫
                print(f"  p #{i+1}: {el.text}")
            
            # „Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏„Å´Èñ¢ÈÄ£„Åô„ÇãË¶ÅÁ¥†„ÇíÁâπÂÆö
            print("\n„Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏Èñ¢ÈÄ£Ë¶ÅÁ¥†:")
            error_selectors = [
                "//h1[contains(text(), 'Error')]",
                "//p[contains(text(), '„Éö„Éº„Ç∏„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì')]",
                "//p[contains(text(), 'Page Not Found')]",
                "//div[contains(text(), '„Éö„Éº„Ç∏„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì')]",
                "//div[contains(text(), 'Page Not Found')]"
            ]
            
            for selector in error_selectors:
                elements = driver.find_elements(By.XPATH, selector)
                if elements:
                    print(f"  {selector}: {len(elements)}ÂÄã„ÅÆË¶ÅÁ¥†„ÇíÊ§úÂá∫")
                    for i, el in enumerate(elements):
                        print(f"    Ë¶ÅÁ¥† #{i+1}: {el.text}, Ë°®Á§∫Áä∂ÊÖã: {el.is_displayed()}")
                else:
                    print(f"  {selector}: Ë©≤ÂΩìË¶ÅÁ¥†„Å™„Åó")
            
        except Exception as e:
            print(f"HTMLÊßãÈÄ†Âá∫Âäõ‰∏≠„Å´„Ç®„É©„Éº: {e}")
        
    except Exception as e:
        print(f"„ÉÜ„Çπ„ÉàÂÆüË°å‰∏≠„Å´„Ç®„É©„Éº: {e}")
        traceback.print_exc()
    
    print("=== „Ç®„É©„Éº„Éö„Éº„Ç∏Ê§úÂá∫„ÉÜ„Çπ„ÉàÁµÇ‰∫Ü ===\n")
    return

# „ÉÜ„Çπ„ÉàÂÆüË°å‰æã
# test_error_page_detection(driver, "https://syllabus.sfc.keio.ac.jp/error")

def save_checkpoint(year, field_name, page_num, processed_urls):
    """ÈÄ≤ÊçóÁä∂Ê≥Å„Çí„ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„Éï„Ç°„Ç§„É´„Å´‰øùÂ≠ò„Åô„Çã"""
    checkpoint = {
        'year': year,
        'field_name': field_name,
        'page_num': page_num,
        'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'processed_urls': list(processed_urls)  # set„Çí„É™„Çπ„Éà„Å´Â§âÊèõ
    }
    
    checkpoint_file = os.path.join(OUTPUT_DIR_NAME, 'checkpoint.pkl')
    with open(checkpoint_file, 'wb') as f:
        pickle.dump(checkpoint, f)
    print(f"\n[ÊÉÖÂ†±] „ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà‰øùÂ≠ò: Âπ¥Â∫¶={year}, ÂàÜÈáé={field_name}, „Éö„Éº„Ç∏={page_num}, URLÊï∞={len(processed_urls)}")

def load_checkpoint():
    """ÊúÄÂæå„ÅÆ„ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„ÇíË™≠„ÅøËæº„ÇÄÔºàÂ≠òÂú®„Åô„ÇãÂ†¥ÂêàÔºâ"""
    checkpoint_file = os.path.join(OUTPUT_DIR_NAME, 'checkpoint.pkl')
    if os.path.exists(checkpoint_file):
        try:
            with open(checkpoint_file, 'rb') as f:
                checkpoint = pickle.load(f)
            print(f"\n[ÊÉÖÂ†±] „ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„ÉàË™≠Ëæº: Âπ¥Â∫¶={checkpoint['year']}, ÂàÜÈáé={checkpoint['field_name']}, "
                  f"„Éö„Éº„Ç∏={checkpoint['page_num']}, ‰øùÂ≠òÊó•ÊôÇ={checkpoint['timestamp']}")
            return checkpoint
        except Exception as e:
            print(f"\n[Ë≠¶Âëä] „ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„ÉàË™≠ËæºÂ§±Êïó: {e}")
    return None

def get_syllabus_details(driver, current_year, screenshots_dir):
    """
    „Ç∑„É©„Éê„ÇπË©≥Á¥∞„Éö„Éº„Ç∏„Åã„ÇâÊåáÂÆö„Åï„Çå„ÅüÊó•Êú¨Ë™û„Å®Ëã±Ë™û„ÅÆÊÉÖÂ†±„ÇíÂèñÂæó„ÄÇ
    Êó•Êú¨Ë™û„Éö„Éº„Ç∏„Å®Ëã±Ë™û„Éö„Éº„Ç∏„ÇíÂÄãÂà•„Å´Âá¶ÁêÜ„Åó„ÄÅ„Åù„Çå„Åû„Çå„ÅÆË®ÄË™û„ÅÆÊÉÖÂ†±„ÇíÊ†ºÁ¥ç„Åô„Çã„ÄÇ
    Âπ¥Â∫¶„Å®„Ç∑„Çπ„ÉÜ„É†„Çø„Ç§„Éó„Å´Âøú„Åò„Å¶ÈÅ©Âàá„Å™XPath„Éû„ÉÉ„Éó„Çí‰ΩøÁî®„Åô„Çã„ÄÇ
    """
    # Add timer for detailed logging
    detail_start_time = time.time()
    
    ja_data = {}  # Êó•Êú¨Ë™û„Éö„Éº„Ç∏„Åã„ÇâÂèñÂæó„Åó„Åü„Éá„Éº„Çø
    en_data = {}  # Ëã±Ë™û„Éö„Éº„Ç∏„Åã„ÇâÂèñÂæó„Åó„Åü„Éá„Éº„Çø
    course_id = None
    japanese_url = "N/A"
    english_url = "N/A"  # Ëã±Ë™ûURL„ÇÇÂàùÊúüÂåñ

    # „Ç∑„Çπ„ÉÜ„É†„Çø„Ç§„Éó„ÇíÂà§ÂÆö
    current_url = driver.current_url
    is_old_system = "syllabus.sfc.keio.ac.jp" in current_url
    is_new_system = "gslbs.keio.jp" in current_url
    
    if is_old_system or (current_year <= 2024 and not is_new_system):
        print(f"    [{time.strftime('%H:%M:%S')}] üìã Processing old system syllabus (pre-2024)")
        # Êóß„Ç∑„Çπ„ÉÜ„É†Áî®„ÅÆXPathÂÆöÁæ©ÔºàSFC 2024Âπ¥ÂØæÂøúÁâàÔºâ
        ja_map_to_use = INFO_MAP_JA_2023_2024.copy()  # Use the 2023/2024 mapping
        en_map_to_use = INFO_MAP_EN_2023_2024.copy()  # Use the 2023/2024 mapping
    else:
        print(f"    [{time.strftime('%H:%M:%S')}] üìã Processing new system syllabus (2025+)")
        # Êñ∞„Ç∑„Çπ„ÉÜ„É†Áî®„ÅÆXPathÂÆöÁæ©Ôºà2025Âπ¥‰ª•ÈôçÁî®Ôºâ
        ja_map_to_use = INFO_MAP_JA_2025.copy()
        en_map_to_use = INFO_MAP_EN_2025.copy()

    # --- Course ID ÂèñÂæó ---
    print(f"    [{time.strftime('%H:%M:%S')}] üî¢ Extracting course ID")
    try:
        # Êóß„Ç∑„Çπ„ÉÜ„É†„Å®Êñ∞„Ç∑„Çπ„ÉÜ„É†„ÅßÁï∞„Å™„Çã„Éë„Çø„Éº„É≥„Çí‰ΩøÁî®
        if is_old_system or current_year <= 2024:
            # Êóß„Ç∑„Çπ„ÉÜ„É†Áî®„ÅÆ„Ç≥„Éº„ÇπIDÂèñÂæó„Éë„Çø„Éº„É≥
            id_match = re.search(r'/courses/\d+_(\d+)', current_url) or \
                    re.search(r'\?id=(\d+)', current_url)
        else:
            # Êñ∞„Ç∑„Çπ„ÉÜ„É†Áî®„ÅÆ„Ç≥„Éº„ÇπIDÂèñÂæó„Éë„Çø„Éº„É≥ - 2025 format
            id_match = re.search(r'[?&](?:id|entno)=(\d+)', current_url) or \
                    re.search(r'/courses/\d+_(\d+)', current_url) or \
                    re.search(r'/syllabus/(\d+)', current_url) or \
                    re.search(r'ttblyr=\d+&entno=(\d+)', current_url) 
            
        if id_match:
            course_id = id_match.group(1)
        else:
            course_id_xpath = ja_map_to_use.get('course_id_fallback', [None, None])[1]
            if course_id_xpath:
                print(f"               URL„Åã„ÇâIDÂèñÂæóÂ§±Êïó„ÄÇXPath„ÅßË©¶Ë°å: {course_id_xpath}")
                reg_num = get_text_by_xpath(driver, course_id_xpath)
                if reg_num and reg_num.isdigit():
                    course_id = reg_num
                else:
                    try:
                        hidden_elements = driver.find_elements(By.XPATH, "//input[@type='hidden' and (contains(@name, 'id') or contains(@name, 'entno'))]")
                        for hidden in hidden_elements:
                            value = hidden.get_attribute('value')
                            if value and value.isdigit():
                                course_id = value
                                print(f"               Èö†„ÅóË¶ÅÁ¥†„Åã„ÇâIDÂèñÂæó: {value}")
                                break
                    except Exception: pass
    except Exception as e:
        print(f"    [{time.strftime('%H:%M:%S')}] ‚ö†Ô∏è Error during Course ID extraction: {e}")

    if course_id:
        print(f"    [{time.strftime('%H:%M:%S')}] ‚úÖ Course ID found: {course_id}")
    else:
        print(f"    [{time.strftime('%H:%M:%S')}] ‚ö†Ô∏è Failed to find Course ID, trying alternative methods")

    if not course_id:
        print(f"    [{time.strftime('%H:%M:%S')}] ‚ùå Critical: Failed to find Course ID")
        raise MissingCriticalDataError(f"ÂøÖÈ†à„Éá„Éº„Çø(Course ID)„ÅÆÂèñÂæó„Å´Â§±Êïó (URL: {japanese_url})")
    print(f"               Course ID: {course_id}")

    # --- Êó•Êú¨Ë™ûÊÉÖÂ†±ÂèñÂæó„É´„Éº„Éó ---
    print(f"    [{time.strftime('%H:%M:%S')}] üìù Extracting Japanese syllabus data")
    name_default_ja = f"ÂêçÁß∞‰∏çÊòé-{course_id}"
    name_tuple_ja = ja_map_to_use['name']
    ja_map_to_use['name'] = (name_tuple_ja[0], name_tuple_ja[1], name_default_ja)

    INVALID_COURSE_NAME_PATTERNS = ["ÊÖ∂ÊáâÁæ©Â°æÂ§ßÂ≠¶ „Ç∑„É©„Éê„Çπ„ÉªÊôÇÈñìÂâ≤", "SFC Course Syllabus"]
    critical_data_missing_ja = False  # Êó•Êú¨Ë™û„Éá„Éº„ÇøÁî®„ÅÆ„Éï„É©„Ç∞
    missing_details_ja = []  # Êó•Êú¨Ë™û„Éá„Éº„ÇøÁî®„ÅÆ„É™„Çπ„Éà

    print("           --- Êó•Êú¨Ë™ûÊÉÖÂ†±ÂèñÂæóÈñãÂßã ---")
    for key, (label, xpath, default_value, *_) in ja_map_to_use.items():
        if key == 'course_id_fallback': continue
        ja_data[key] = get_text_by_xpath(driver, xpath, default_value)

        # ÂøÖÈ†à„ÉÅ„Çß„ÉÉ„ÇØ (TTCK/OnlineÂá¶ÁêÜÂâç)
        optional_keys = ['professor', 'selection_method', 'class_format', 'location', 'day_period'] 
        if key not in optional_keys:
            if key == 'name':
                if ja_data[key] == default_value or any(pattern in ja_data[key] for pattern in INVALID_COURSE_NAME_PATTERNS):
                    critical_data_missing_ja = True
                    missing_details_ja.append(f"{label}(ja): ‰∏çÈÅ©Âàá„Äå{ja_data[key]}„Äç")
            elif ja_data[key] == default_value or not ja_data[key]:
                if xpath:  # XPath„ÅåÂÆöÁæ©„Åï„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÅÆ„Åø„Ç®„É©„ÉºÂØæË±°
                    critical_data_missing_ja = True
                    missing_details_ja.append(f"{label}(ja): Êú™ÂèñÂæó/Á©∫")

        # --- Online/TTCKÂá¶ÁêÜ (Êó•Êú¨Ë™û) ---
        is_ttck_ja = "TTCK" in ja_data.get('name', '')
        is_online_ja = "„Ç™„É≥„É©„Ç§„É≥" in ja_data.get('class_format', '') or "„Ç™„É≥„Éá„Éû„É≥„Éâ" in ja_data.get('class_format', '')

        if is_ttck_ja:
            print("               Êó•Êú¨Ë™û: TTCK„Ç≥„Éº„ÇπÊ§úÂá∫„ÄÇÊïôÂÆ§„Å®ÊõúÊó•ÊôÇÈôê„ÇíË™øÊï¥„Åó„Åæ„Åô„ÄÇ")
            ja_data['location'] = "TTCK"
            if not ja_data.get('day_period') or ja_data.get('day_period') == "ÊõúÊó•ÊôÇÈôê‰∏çÊòé":
                ja_data['day_period'] = "ÁâπÂÆöÊúüÈñìÈõÜ‰∏≠"
        elif is_online_ja:
            print("               Êó•Êú¨Ë™û: „Ç™„É≥„É©„Ç§„É≥ÊéàÊ•≠Ê§úÂá∫„ÄÇÊïôÂÆ§„Å®ÊõúÊó•ÊôÇÈôê„ÇíË™øÊï¥„Åó„Åæ„Åô„ÄÇ")
            ja_data['location'] = "„Ç™„É≥„É©„Ç§„É≥"
            if not ja_data.get('day_period') or ja_data.get('day_period') == "ÊõúÊó•ÊôÇÈôê‰∏çÊòé":
                ja_data['day_period'] = "„Ç™„É≥„É©„Ç§„É≥ÊéàÊ•≠"

        # --- ÂøÖÈ†à„Éá„Éº„ÇøÊúÄÁµÇ„ÉÅ„Çß„ÉÉ„ÇØ (Êó•Êú¨Ë™û) ---
        if not is_ttck_ja:
            if not ja_data.get('location') or ja_data.get('location') == "ÊïôÂÆ§‰∏çÊòé":
                 if not is_online_ja:
                    critical_data_missing_ja = True
                    missing_details_ja.append("ÊïôÂÆ§(ja): Êú™ÂèñÂæó/Á©∫")
            if not ja_data.get('day_period') or ja_data.get('day_period') == "ÊõúÊó•ÊôÇÈôê‰∏çÊòé":
                critical_data_missing_ja = True
                missing_details_ja.append("ÊõúÊó•ÊôÇÈôê(ja): Êú™ÂèñÂæó/Á©∫")

        if critical_data_missing_ja:
            raise MissingCriticalDataError(f"ÂøÖÈ†àÊó•Êú¨Ë™û„Éá„Éº„ÇøÂèñÂæóÂ§±Êïó (URL: {japanese_url}): {'; '.join(missing_details_ja)}")

        print("           --- Êó•Êú¨Ë™ûÊÉÖÂ†±ÂèñÂæóÂÆå‰∫Ü ---")

        # After Japanese extraction
        ja_elapsed = time.time() - detail_start_time
        print(f"    [{time.strftime('%H:%M:%S')}] ‚úÖ Japanese data extracted ({ja_elapsed:.2f}s)")
        
        # --- 2. Ëã±Ë™û„Éö„Éº„Ç∏„ÅÆÊÉÖÂ†±„ÇíÂèñÂæó ---
        # English page processing
        english_start_time = time.time()
        print(f"    [{time.strftime('%H:%M:%S')}] üá¨üáß Processing English page")

        # Generate English URL
        if is_old_system or current_year <= 2024:
            # Old system URL generation (unchanged)
            if "locale=ja" in current_url:
                english_url = current_url.replace("locale=ja", "locale=en")
            elif "locale=" not in current_url:
                english_url = current_url + ("&" if "?" in current_url else "?") + "locale=en"
            else:
                english_url = current_url
        else:
            # New system URL generation (2025+)
            if "lang=jp" in current_url:
                english_url = current_url.replace("lang=jp", "lang=en")
            elif "lang=" not in current_url:
                english_url = current_url + ("&" if "?" in current_url else "?") + "lang=en"
            else:
                english_url = current_url

        print(f"           Ëã±Ë™û„Éö„Éº„Ç∏Âá¶ÁêÜ‰∏≠: {english_url}")
        try:
            print(f"           Ëã±Ë™û„Éö„Éº„Ç∏„Å´Âàá„ÇäÊõø„Åà‰∏≠...")
            # Use JavaScript to switch to English page
            js_switch_to_en = """
                // Optimized language switching function
                function switchToEnglish() {
                    // Find language button
                    const langBtn = document.querySelector('a[hreflang="en"], a.lang-en, a[onclick*="lang=en"]');
                    if (langBtn) {
                        langBtn.click();
                        return true;
                    } else {
                        // No button found, try URL modification instead
                        const url = new URL(window.location.href);
                        url.searchParams.set('lang', 'en');
                        window.location.href = url.toString();
                        return false;
                    }
                }
                return switchToEnglish();
            """
            used_button = driver.execute_script(js_switch_to_en)
            
            # Wait for page to be ready using conditional waiting instead of fixed sleep
            if used_button:
                # For button click, wait for a visual change indicating English is loaded
                # Note: No sleep needed, wait for a specific English indicator instead
                try:
                    WebDriverWait(driver, SHORT_WAIT).until(
                        EC.presence_of_element_located((By.XPATH, "//h2[@class='class-name']"))
                    )
                except TimeoutException:
                    # If timeout, the element might already be present or have a different structure
                    pass
            else:
                # For URL navigation, we need to wait for body to load
                WebDriverWait(driver, min(10, ELEMENT_WAIT_TIMEOUT)).until(
                    EC.presence_of_element_located((By.TAG_NAME, "body"))
                )
            
            # Check if this is an error page
            if is_error_page(driver):
                print(f"           [ÊÉÖÂ†±] Ëã±Ë™û„Éö„Éº„Ç∏„Åß„Ç®„É©„Éº„Éö„Éº„Ç∏„ÇíÊ§úÂá∫„Åó„Åæ„Åó„Åü„ÄÇËã±Ë™ûÊÉÖÂ†±„ÅØ‰∏ÄÈÉ®Ê¨†ËêΩ„Åó„Åæ„Åô„ÄÇ")
                save_screenshot(driver, f"error_page_english_{current_year}_{course_id}", screenshots_dir)
                print("           Ëã±Ë™û„Éö„Éº„Ç∏„ÅØ„Çπ„Ç≠„ÉÉ„Éó„Åó„Å¶Êó•Êú¨Ë™ûÊÉÖÂ†±„ÅÆ„Åø„ÅßÈÄ≤„ÇÅ„Åæ„Åô„ÄÇ")
                # Set default English data
                en_data = {}
                name_default_en = f"Name Unknown-{course_id}"
                for key, (_, _, default_value_en, *_) in en_map_to_use.items():
                    en_data[key] = default_value_en if key != 'name' else name_default_en
            else:
                # No need for JS rendering wait - directly proceed to data extraction
                print(f"           Ëã±Ë™û„Éö„Éº„Ç∏Ë™≠„ÅøËæº„ÅøÂÆå‰∫Ü„ÄÇÊÉÖÂ†±ÂèñÂæóË©¶Ë°å...")
                print("           --- Ëã±Ë™ûÊÉÖÂ†±ÂèñÂæóÈñãÂßã ---")
                
                # Batch retrieval of English data using JavaScript
                print("           Ëã±Ë™ûÊÉÖÂ†±„Çí‰∏ÄÊã¨ÂèñÂæó‰∏≠...")
                en_data = {}
                name_default_en = f"Name Unknown-{course_id}"
                
                # Create dictionary of XPaths to query in a single JavaScript execution
                xpath_dict = {}
                for key, (label, xpath, default_value, *_) in en_map_to_use.items():
                    if key != 'course_id_fallback':
                        xpath_dict[key] = xpath
                
                # Optimized JavaScript for faster DOM queries 
                try:
                    js_script = """
                    function getElementTexts(xpathDict) {
                        const results = {};
                        // Process all XPaths in one pass
                        for (const [key, xpath] of Object.entries(xpathDict)) {
                            try {
                                // Fast DOM query using evaluate
                                const element = document.evaluate(
                                    xpath, 
                                    document, 
                                    null, 
                                    XPathResult.FIRST_ORDERED_NODE_TYPE, 
                                    null
                                ).singleNodeValue;
                                
                                // Store the text content if found, empty string if not
                                results[key] = element ? element.textContent.trim() : "";
                            } catch(e) {
                                results[key] = "";
                            }
                        }
                        return results;
                    }
                    return getElementTexts(arguments[0]);
                    """
                    
                    batch_results = driver.execute_script(js_script, xpath_dict)
                    
                    # Process results with normalization
                    for key, (_, _, default_value, *_) in en_map_to_use.items():
                        if key != 'course_id_fallback':
                            value = batch_results.get(key, "")
                            en_data[key] = normalize_text(value) if value else (default_value if key != 'name' else name_default_en)
                    
                    print("           Ëã±Ë™ûÊÉÖÂ†±„ÅÆ‰∏ÄÊã¨ÂèñÂæó„Å´ÊàêÂäü„Åó„Åæ„Åó„Åü„ÄÇ")
                except Exception as e:
                    print(f"           [Ë≠¶Âëä] JavaScript‰∏ÄÊã¨ÂèñÂæó‰∏≠„Å´„Ç®„É©„Éº: {e}")
                    print("           ÂæìÊù•„ÅÆÊñπÊ≥ï„ÅßÂÄãÂà•„Å´ÂèñÂæó„Åó„Åæ„Åô...")
                    
                    # Fall back to original method
                    for key, (_, _, default_value_en, *_) in en_map_to_use.items():
                        en_data[key] = default_value_en if key != 'name' else name_default_en

                    for key, (label, xpath, default_value, *_) in en_map_to_use.items():
                        if key == 'course_id_fallback': continue
                        en_data[key] = get_text_by_xpath(driver, xpath, default_value)

                    for key, (label, xpath, default_value, *_) in en_map_to_use.items():
                        if key == 'course_id_fallback': continue
                        en_data[key] = get_text_by_xpath(driver, xpath, default_value)

                # --- Online/TTCKÂá¶ÁêÜ (Ëã±Ë™û) ---
                is_ttck_en = ("TTCK" in en_data.get('name', '')) or is_ttck_ja
                en_class_format_lower = en_data.get('class_format', '').lower()
                is_online_en = "online" in en_class_format_lower or "remote" in en_class_format_lower

                if is_ttck_en:
                    print("               Ëã±Ë™û: TTCK„Ç≥„Éº„ÇπÊ§úÂá∫„ÄÇÊïôÂÆ§„Å®ÊõúÊó•ÊôÇÈôê„ÇíË™øÊï¥„Åó„Åæ„Åô„ÄÇ")
                    en_data['location'] = "TTCK"
                    if not en_data.get('day_period') or en_data.get('day_period') == "Day/Period Unknown":
                        en_data['day_period'] = "Intensive Course"
                elif is_online_en:
                    print("               Ëã±Ë™û: „Ç™„É≥„É©„Ç§„É≥ÊéàÊ•≠Ê§úÂá∫„ÄÇÊïôÂÆ§„ÇíË™øÊï¥„Åó„Åæ„Åô„ÄÇ")
                    en_data['location'] = "Online"

                print("           --- Ëã±Ë™ûÊÉÖÂ†±ÂèñÂæóÂÆå‰∫Ü ---")

        except TimeoutException as e_timeout_en:
            print(f"     [Ë≠¶Âëä] Ëã±Ë™û„Éö„Éº„Ç∏({english_url})„ÅÆË™≠„ÅøËæº„Åø„Çø„Ç§„É†„Ç¢„Ç¶„Éà„ÄÇËã±Ë™ûÊÉÖÂ†±„ÅØ‰∏ÄÈÉ®Ê¨†ËêΩ„Åó„Åæ„Åô„ÄÇ {e_timeout_en}")
            save_screenshot(driver, f"detail_en_load_timeout_{current_year}_{course_id or 'unknownID'}", screenshots_dir)
        except (InvalidSessionIdException, NoSuchWindowException) as e_session:
            print(f"     [„Ç®„É©„Éº] Ëã±Ë™û„Éö„Éº„Ç∏Âá¶ÁêÜ‰∏≠„Å´„Çª„ÉÉ„Ç∑„Éß„É≥/„Ç¶„Ç£„É≥„Éâ„Ç¶„Ç®„É©„Éº: {e_session}")
            raise
        except Exception as e_en:
            print(f"     [Ë≠¶Âëä] Ëã±Ë™û„Éö„Éº„Ç∏({english_url})„ÅÆÂá¶ÁêÜ‰∏≠„Å´‰∫àÊúü„Åõ„Å¨„Ç®„É©„Éº: {e_en}„ÄÇËã±Ë™ûÊÉÖÂ†±„ÅØ‰∏ÄÈÉ®Ê¨†ËêΩ„Åó„Åæ„Åô„ÄÇ")
            save_screenshot(driver, f"detail_en_unknown_error_{current_year}_{course_id or 'unknownID'}", screenshots_dir)
            traceback.print_exc()
            # „Ç®„É©„ÉºÊôÇ„ÅØËã±Ë™û„Éá„Éº„Çø„Çí„Éá„Éï„Ç©„É´„ÉàÂÄ§„Å´Êàª„Åô
            en_data = {}
            name_default_en = f"Name Unknown-{course_id}"
            for key, (_, _, default_value_en, *_) in en_map_to_use.items():
                en_data[key] = default_value_en if key != 'name' else name_default_en

        # After English extraction
        en_elapsed = time.time() - english_start_time
        print(f"    [{time.strftime('%H:%M:%S')}] ‚úÖ English data extracted ({en_elapsed:.2f}s)")
        
        # Final data construction
        print(f"    [{time.strftime('%H:%M:%S')}] üîÑ Building final data object")
        
        # --- 3. ÊúÄÁµÇ„Éá„Éº„ÇøÊßãÁØâ ---
        final_details = {
            'course_id': course_id,
            'year_scraped': current_year,
            'translations': {
                'ja': {},
                'en': {}
            }
        }

        all_keys_to_copy = [k for k in ja_map_to_use.keys() if k != 'course_id_fallback']

        # Êó•Êú¨Ë™û„Éá„Éº„Çø„ÇíÊßãÊàê
        for key in all_keys_to_copy:
            final_details['translations']['ja'][key] = ja_data.get(key, "")

        # Ëã±Ë™û„Éá„Éº„Çø„ÇíÊßãÊàê
        for key in all_keys_to_copy:
            final_details['translations']['en'][key] = en_data.get(key, "")

        # --- „Éà„ÉÉ„Éó„É¨„Éô„É´„ÅÆÊÉÖÂ†±„ÇíË®≠ÂÆö (Ë£úË∂≥Áî®) ---
        semester_en_raw = final_details['translations']['en'].get('semester', '')
        semester_ja_raw = final_details['translations']['ja'].get('semester', '')
        final_details['semester'] = extract_season(semester_en_raw) if extract_season(semester_en_raw) != "unknown" else extract_season(semester_ja_raw)
        final_details['professor_ja'] = final_details['translations']['ja'].get('professor', '')
        final_details['name_ja'] = final_details['translations']['ja'].get('name', '')
        final_details['field_ja'] = final_details['translations']['ja'].get('field', '')
        final_details['credits_ja'] = final_details['translations']['ja'].get('credits', '')

        total_elapsed = time.time() - detail_start_time
        print(f"    [{time.strftime('%H:%M:%S')}] ‚úÖ Complete syllabus details extracted ({total_elapsed:.2f}s)")
        
        # Display visual verification of scraped data
        display_scraped_info(final_details, f"Syllabus ID: {final_details.get('course_id', 'N/A')}")
        
        return final_details

# --- ‚òÖ‚òÖ‚òÖ aggregate_syllabus_data Èñ¢Êï∞ (Â§âÊõ¥„Å™„Åó) ‚òÖ‚òÖ‚òÖ ---
def aggregate_syllabus_data(all_raw_data):
    """
    Ë§áÊï∞Âπ¥Â∫¶„Å´„Çè„Åü„ÇãÁîü„Éá„Éº„Çø„ÇíÈõÜÁ¥Ñ„Åó„ÄÅÊåáÂÆö„Åï„Çå„ÅüJSONÂΩ¢Âºè„Å´Êï¥ÂΩ¢„Åô„Çã„ÄÇ
    ‚òÖ‚òÖ‚òÖ ÈõÜÁ¥Ñ„Ç≠„Éº: ÊãÖÂΩìËÄÖÂêç(Êó•), ÁßëÁõÆÂêç(Êó•), Â≠¶Êúü(Â≠£ÁØÄ„ÅÆ„Åø), ÂàÜÈáé(Êó•), Âçò‰Ωç(Êó•) ‚òÖ‚òÖ‚òÖ (ÁôªÈå≤Áï™Âè∑„ÇíÈô§Â§ñ)
    Ë§áÊï∞Âπ¥Â∫¶„ÅÇ„ÇãÂ†¥Âêà„ÅØ„ÄÅÊúÄÊñ∞Âπ¥Â∫¶„ÅÆ„Éá„Éº„Çø„ÇíÂü∫Êú¨„Å®„Åó„ÄÅyear „Å® available_years „ÇíÊõ¥Êñ∞„Åô„Çã„ÄÇ
    """
    if not all_raw_data: return []
    grouped_by_key = {}
    skipped_count = 0
    print("\n--- „Éá„Éº„ÇøÈõÜÁ¥ÑÈñãÂßã ---")
    for item in all_raw_data:
        course_id = item.get('course_id')
        professor_ja_key = item.get('professor_ja', '')
        professors_tuple = tuple(sorted([p.strip() for p in re.split('[/,]', professor_ja_key) if p.strip()]))
        name_ja_key = item.get('name_ja', '')
        semester_agg_key = item.get('semester', 'unknown')
        field_ja_key = item.get('field_ja', '')
        credits_ja_key = item.get('credits_ja', '')

        agg_key = (
            professors_tuple, name_ja_key, semester_agg_key, field_ja_key, credits_ja_key
        )

        if not name_ja_key or not field_ja_key or not credits_ja_key or semester_agg_key == "unknown":
            error_msg = f"ÈõÜÁ¥Ñ„Ç≠„Éº„Å´ÂøÖË¶Å„Å™ÊÉÖÂ†±„Åå‰∏çË∂≥„Åæ„Åü„ÅØÂ≠¶Êúü‰∏çÊòé (Course ID: {course_id}, Year: {item.get('year_scraped')}, Semester: {semester_agg_key})"
            print(f"[Ë≠¶Âëä] {error_msg}")
            
            if not pause_on_error(f"Missing critical aggregation data: {error_msg}"):
                print("„É¶„Éº„Ç∂„Éº„Å´„Çà„Çã‰∏≠Êñ≠„ÄÇ„Çπ„ÇØ„É™„Éó„Éà„ÇíÁµÇ‰∫Ü„Åó„Åæ„Åô„ÄÇ")
                sys.exit(1)
            
            skipped_count += 1
            continue

        if agg_key not in grouped_by_key: grouped_by_key[agg_key] = []
        grouped_by_key[agg_key].append(item)

    if skipped_count > 0: print(f"„Ç≠„ÉºÊÉÖÂ†±‰∏çË∂≥„Åæ„Åü„ÅØÂ≠¶Êúü‰∏çÊòé„Å´„Çà„Çä {skipped_count} ‰ª∂„ÅÆ„Éá„Éº„Çø„ÅåÈõÜÁ¥Ñ„Åã„Çâ„Çπ„Ç≠„ÉÉ„Éó„Åï„Çå„Åæ„Åó„Åü„ÄÇ")
    print(f"{len(grouped_by_key)} ‰ª∂„Å´ÈõÜÁ¥Ñ„Åï„Çå„Åæ„Åó„Åü„ÄÇ")

    final_list = []
    item_count = 0
    for agg_key, year_data_list in grouped_by_key.items():
        item_count += 1
        if item_count % 100 == 0:
             print(f"   ÈõÜÁ¥ÑÂá¶ÁêÜ‰∏≠... {item_count}/{len(grouped_by_key)}")

        year_data_list.sort(key=lambda x: x['year_scraped'], reverse=True)
        latest_data = year_data_list[0]
        years_scraped_int = sorted(list(set(d['year_scraped'] for d in year_data_list)), reverse=True)
        available_years_str = [str(y) for y in years_scraped_int]

        trans_ja = latest_data.get('translations', {}).get('ja', {})
        trans_en = latest_data.get('translations', {}).get('en', {})
        semester_final = agg_key[2]

        professors_list = []
        prof_ja_raw = trans_ja.get('professor', '')
        prof_en_raw = trans_en.get('professor', '')

        # Use the new parsing function
        prof_ja_names = parse_professor_names(prof_ja_raw)
        prof_en_names = parse_professor_names(prof_en_raw)

        num_professors = len(prof_ja_names)
        if len(prof_en_names) < num_professors:
            prof_en_names.extend([""] * (num_professors - len(prof_en_names)))
        elif len(prof_en_names) > num_professors:
            prof_en_names = prof_en_names[:num_professors]

        # FIX: Set default empty values for department
        dept_ja = ""
        dept_en = ""

        for i in range(num_professors):
            prof_obj = {
                "name": {
                    "ja": prof_ja_names[i],
                    "en": prof_en_names[i] if i < len(prof_en_names) and prof_en_names[i] else prof_ja_names[i]
                },
                "department": { "ja": dept_ja, "en": dept_en }
            }
            professors_list.append(prof_obj)

        # Normalize field and credits
        field_ja = normalize_field(trans_ja.get('field', ''))
        field_en = normalize_field(trans_en.get('field', ''))
        credits_ja = normalize_credits(trans_ja.get('credits', ''), 'ja')
        credits_en = normalize_credits(trans_en.get('credits', ''), 'en')

        aggregated_item = {
            "course_id": latest_data['course_id'],
            "year": "&".join(available_years_str),
            "semester": semester_final,
            "translations": {
                "ja": {
                    "name": trans_ja.get('name', ''), 
                    "field": field_ja,
                    "credits": credits_ja, 
                    "semester": trans_ja.get('semester', ''),
                    "Classroom": trans_ja.get('location', ''), 
                    "day_period": trans_ja.get('day_period', ''),
                    "selection_method": trans_ja.get('selection_method', '')
                },
                "en": {
                    "name": trans_en.get('name', ''), 
                    "field": field_en,
                    "credits": credits_en, 
                    "semester": trans_en.get('semester', ''),
                    "Classroom": trans_en.get('location', ''), 
                    "day_period": trans_en.get('day_period', ''),
                    "selection_method": trans_en.get('selection_method', '')
                }
            },
            "professors": professors_list,
            "available_years": available_years_str
        }
        final_list.append(aggregated_item)
    print("--- „Éá„Éº„ÇøÈõÜÁ¥ÑÂÆå‰∫Ü ---")
    return final_list
# --- login Èñ¢Êï∞ (Â§âÊõ¥„Å™„Åó) ---
def login(driver, email, password, screenshots_dir):
    """ÊåáÂÆö„Åï„Çå„ÅüÊÉÖÂ†±„Åß„É≠„Ç∞„Ç§„É≥Âá¶ÁêÜ„ÇíË°å„ÅÜ"""
    login_url = 'https://gslbs.keio.jp/syllabus/search'
    max_login_attempts = 2
    for attempt in range(max_login_attempts):
        print(f"\n„É≠„Ç∞„Ç§„É≥Ë©¶Ë°å {attempt + 1}/{max_login_attempts}...")
        try:
            driver.get(login_url)
            WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.presence_of_element_located((By.XPATH, "//input[@type='email' or @name='identifier']")))
            time.sleep(SHORT_WAIT)
            username_field = WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.visibility_of_element_located((By.XPATH, "//input[@type='email' or @name='identifier']")))
            username_field.clear(); username_field.send_keys(email); time.sleep(0.5)

            next_button_selectors = ["//button[contains(., 'Next')]", "//button[contains(., 'Ê¨°„Å∏')]", "//button[@type='submit']", "//input[@type='submit' and (contains(@value, 'Next') or contains(@value, 'Ê¨°„Å∏'))]", "//div[@role='button' and (contains(., 'Next') or contains(., 'Ê¨°„Å∏'))]" ]
            next_button = None
            for selector in next_button_selectors:
                try:
                    next_button = WebDriverWait(driver, SHORT_WAIT).until(EC.element_to_be_clickable((By.XPATH, selector)))
                    if click_element(driver, next_button): break
                    else: next_button = None
                except TimeoutException: continue
                except StaleElementReferenceException: time.sleep(1); continue
                except (InvalidSessionIdException, NoSuchWindowException) as e_session: raise e_session

            if not next_button:
                try:
                    print("     „ÄåÊ¨°„Å∏„Äç„Éú„Çø„É≥„ÅåË¶ã„Å§„Åã„Çâ„Å™„ÅÑ„Åü„ÇÅ„ÄÅEnter„Ç≠„Éº„ÇíÈÄÅ‰ø°„Åó„Åæ„Åô„ÄÇ")
                    username_field.send_keys(Keys.RETURN)
                    time.sleep(MEDIUM_WAIT)
                except Exception as e_enter: print(f"     Enter„Ç≠„ÉºÈÄÅ‰ø°‰∏≠„Å´„Ç®„É©„Éº: {e_enter}"); save_screenshot(driver, f"login_next_button_error_{attempt+1}", screenshots_dir); raise Exception("„ÄåÊ¨°„Å∏„Äç„Éú„Çø„É≥Âá¶ÁêÜÂ§±Êïó")

            WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.visibility_of_element_located((By.XPATH, "//input[@type='password']")))
            time.sleep(SHORT_WAIT)
            password_field = WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.visibility_of_element_located((By.XPATH, "//input[@type='password']")))
            password_field.clear(); password_field.send_keys(password); time.sleep(0.5)

            signin_button_selectors = ["//button[contains(., 'Sign in')]", "//button[contains(., '„Çµ„Ç§„É≥„Ç§„É≥')]", "//button[contains(., 'Verify')]", "//button[@type='submit']", "//input[@type='submit' and (contains(@value, 'Sign in') or contains(@value, '„Çµ„Ç§„É≥„Ç§„É≥') or contains(@value, 'Verify'))]", "//div[@role='button' and (contains(., 'Sign in') or contains(., '„Çµ„Ç§„É≥„Ç§„É≥') or contains(., 'Verify'))]" ]
            signin_button = None
            for selector in signin_button_selectors:
                try:
                    signin_button = WebDriverWait(driver, SHORT_WAIT).until(EC.element_to_be_clickable((By.XPATH, selector)))
                    if click_element(driver, signin_button): break
                    else: signin_button = None
                except TimeoutException: continue
                except StaleElementReferenceException: time.sleep(1); continue
                except (InvalidSessionIdException, NoSuchWindowException) as e_session: raise e_session

            if not signin_button:
                try:
                    print("     „Äå„Çµ„Ç§„É≥„Ç§„É≥„Äç„Éú„Çø„É≥„ÅåË¶ã„Å§„Åã„Çâ„Å™„ÅÑ„Åü„ÇÅ„ÄÅEnter„Ç≠„Éº„ÇíÈÄÅ‰ø°„Åó„Åæ„Åô„ÄÇ")
                    password_field.send_keys(Keys.RETURN)
                    time.sleep(LONG_WAIT)
                except Exception as e_enter: print(f"     Enter„Ç≠„ÉºÈÄÅ‰ø°‰∏≠„Å´„Ç®„É©„Éº: {e_enter}"); save_screenshot(driver, f"login_signin_button_error_{attempt+1}", screenshots_dir); raise Exception("„Äå„Çµ„Ç§„É≥„Ç§„É≥„Äç„Éú„Çø„É≥Âá¶ÁêÜÂ§±Êïó")

            print("     „É≠„Ç∞„Ç§„É≥Âæå„ÅÆ„Éö„Éº„Ç∏ÈÅ∑ÁßªÂæÖÊ©ü‰∏≠...")
            WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT + LONG_WAIT).until(EC.any_of(
                EC.url_contains("gslbs.keio.jp/syllabus/search"),
                EC.presence_of_element_located((By.XPATH, "//button[contains(text(), 'Ê§úÁ¥¢')] | //button[@data-action_id='SYLLABUS_SEARCH_KEYWORD_EXECUTE']"))
            ))

            current_url = driver.current_url
            if "gslbs.keio.jp/syllabus/search" in current_url:
                print("„É≠„Ç∞„Ç§„É≥ÊàêÂäü„ÄÅÊ§úÁ¥¢„Éö„Éº„Ç∏„Å´Âà∞ÈÅî„Åó„Åæ„Åó„Åü„ÄÇ")
                try:
                    WebDriverWait(driver, MEDIUM_WAIT).until(EC.element_to_be_clickable((By.XPATH, "//button[@data-action_id='SYLLABUS_SEARCH_KEYWORD_EXECUTE'] | //button[contains(text(),'Ê§úÁ¥¢')]")))
                except TimeoutException:
                    print("[Ë≠¶Âëä] Ê§úÁ¥¢ÁîªÈù¢„ÅÆ‰∏ªË¶ÅË¶ÅÁ¥†Á¢∫Ë™ç„Çø„Ç§„É†„Ç¢„Ç¶„Éà„ÄÇ")
                return True
            else:
                print(f"[Ë≠¶Âëä] „É≠„Ç∞„Ç§„É≥Âæå„ÅÆURL„ÅåÊúüÂæÖ„Åó„ÅüÊ§úÁ¥¢„Éö„Éº„Ç∏„Åß„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ URL: {current_url}")
                save_screenshot(driver, f"login_unexpected_page_{attempt+1}", screenshots_dir)
                if "auth" in current_url or "verify" in current_url or "duo" in current_url or "device" in current_url:
                    print("[ÊÉÖÂ†±] 2ÊÆµÈöéË™çË®º„Åæ„Åü„ÅØ„Éá„Éê„Ç§„ÇπÁ¢∫Ë™ç„Éö„Éº„Ç∏„Å´ÈÅ∑Áßª„Åó„ÅüÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ")
                    raise Exception("2ÊÆµÈöéË™çË®º/„Éá„Éê„Ç§„ÇπÁ¢∫Ë™çÊ§úÂá∫")
                print("     ‰∫àÊúü„Åõ„Å¨„Éö„Éº„Ç∏„Å´ÈÅ∑Áßª„Åó„Åæ„Åó„Åü„ÄÇ„É≠„Ç∞„Ç§„É≥Â§±Êïó„Å®Âà§Êñ≠„Åó„Åæ„Åô„ÄÇ")

        except (InvalidSessionIdException, NoSuchWindowException) as e_session:
            print(f"[„Ç®„É©„Éº] „É≠„Ç∞„Ç§„É≥Âá¶ÁêÜ‰∏≠„Å´„Çª„ÉÉ„Ç∑„Éß„É≥/„Ç¶„Ç£„É≥„Éâ„Ç¶„Ç®„É©„Éº (Ë©¶Ë°å {attempt + 1}): {e_session}")
            raise
        except TimeoutException as e:
            print(f"[„Ç®„É©„Éº] „É≠„Ç∞„Ç§„É≥Âá¶ÁêÜ‰∏≠„Å´„Çø„Ç§„É†„Ç¢„Ç¶„Éà (Ë©¶Ë°å {attempt + 1})„ÄÇ")
            save_screenshot(driver, f"login_timeout_{attempt+1}", screenshots_dir)
            if attempt == max_login_attempts - 1: raise Exception("„É≠„Ç∞„Ç§„É≥„Çø„Ç§„É†„Ç¢„Ç¶„Éà") from e
            print("„É™„Éà„É©„Ç§„Åó„Åæ„Åô...")
            time.sleep(MEDIUM_WAIT)
        except WebDriverException as e:
            print(f"[„Ç®„É©„Éº] „É≠„Ç∞„Ç§„É≥Âá¶ÁêÜ‰∏≠„Å´WebDriver„Ç®„É©„Éº (Ë©¶Ë°å {attempt + 1}): {e}")
            save_screenshot(driver, f"login_webdriver_error_{attempt+1}", screenshots_dir)
            if "net::ERR" in str(e) or "connection reset" in str(e).lower():
                print("     „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÊé•Á∂ö„Åæ„Åü„ÅØURL„ÅÆÂïèÈ°å„ÄÅ„Åæ„Åü„ÅØ„É™„É¢„Éº„Éà„Éõ„Çπ„Éà„Å´„Çà„ÇãÂàáÊñ≠„ÅÆÂèØËÉΩÊÄß„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ")
            if attempt == max_login_attempts - 1: raise Exception("„É≠„Ç∞„Ç§„É≥‰∏≠„Å´WebDriver„Ç®„É©„Éº") from e
            print("„É™„Éà„É©„Ç§„Åó„Åæ„Åô...")
            time.sleep(MEDIUM_WAIT)
        except Exception as e:
            print(f"[„Ç®„É©„Éº] „É≠„Ç∞„Ç§„É≥Âá¶ÁêÜ‰∏≠„Å´‰∫àÊúü„Åõ„Å¨„Ç®„É©„Éº (Ë©¶Ë°å {attempt + 1}): {e}")
            save_screenshot(driver, f"login_unknown_error_{attempt+1}", screenshots_dir)
            traceback.print_exc()
            if attempt == max_login_attempts - 1: raise Exception("„É≠„Ç∞„Ç§„É≥‰∏≠„Å´‰∫àÊúü„Åõ„Å¨„Ç®„É©„Éº") from e
            print("„É™„Éà„É©„Ç§„Åó„Åæ„Åô...")
            time.sleep(MEDIUM_WAIT)

    print("„É≠„Ç∞„Ç§„É≥„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ")
    return False

def extract_auth_cookies(driver):
    """„É≠„Ç∞„Ç§„É≥Ê∏à„Åø„ÅÆ„Éâ„É©„Ç§„Éê„Éº„Åã„ÇâË™çË®ºCookie„ÇíÂèñÂæó„Åô„Çã"""
    try:
        return driver.get_cookies()
    except Exception as e:
        print(f"[„Ç®„É©„Éº] CookieÂèñÂæó‰∏≠„Å´„Ç®„É©„Éº: {e}")
        return None

def apply_cookies(driver, cookies):
    """„Éâ„É©„Ç§„Éê„Éº„Å´Cookie„ÇíÈÅ©Áî®„Åô„Çã"""
    if not cookies:
        return False
        
    try:
        # ÂØæË±°„Éâ„É°„Ç§„É≥„Å´‰∏ÄÂ∫¶„Ç¢„ÇØ„Çª„Çπ„Åô„ÇãÂøÖË¶Å„Åå„ÅÇ„Çã
        driver.get("https://gslbs.keio.jp")
        
        # Cookie„ÇíÈÅ©Áî®
        for cookie in cookies:
            try:
                driver.add_cookie(cookie)
            except Exception as e:
                print(f"[Ë≠¶Âëä] Cookie ({cookie.get('name', 'unknown')}) ÈÅ©Áî®„Ç®„É©„Éº: {e}")
                
        # „Éö„Éº„Ç∏„ÇíÊõ¥Êñ∞„Åó„Å¶Cookie„ÇíÂèçÊò†
        driver.refresh()
        return True
    except Exception as e:
        print(f"[„Ç®„É©„Éº] CookieÈÅ©Áî®‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {e}")
        return False

# --- check_session_timeout Èñ¢Êï∞ (Â§âÊõ¥„Å™„Åó) ---
def check_session_timeout(driver, screenshots_dir):
    """„Çª„ÉÉ„Ç∑„Éß„É≥„Çø„Ç§„É†„Ç¢„Ç¶„Éà„Éö„Éº„Ç∏„ÅåË°®Á§∫„Åï„Çå„Å¶„ÅÑ„Çã„ÅãÁ¢∫Ë™ç„Åô„Çã"""
    try:
        current_url = driver.current_url
        page_title = driver.title
        page_source = driver.page_source.lower()
        timeout_keywords = ["„Çª„ÉÉ„Ç∑„Éß„É≥„Çø„Ç§„É†„Ç¢„Ç¶„Éà", "session timeout", "„É≠„Ç∞„Ç§„É≥„ÅóÁõ¥„Åó„Å¶„Åè„Å†„Åï„ÅÑ", "log back in"]
        error_page_url_part = "/syllabus/appMsg"
        is_session_timeout = False
        if error_page_url_part in current_url: is_session_timeout = True
        elif any(keyword in page_source for keyword in timeout_keywords): is_session_timeout = True
        elif "error" in page_title.lower() and any(keyword in page_source for keyword in timeout_keywords): is_session_timeout = True

        if is_session_timeout:
            print("[Ë≠¶Âëä] „Çª„ÉÉ„Ç∑„Éß„É≥„Çø„Ç§„É†„Ç¢„Ç¶„Éà„Éö„Éº„Ç∏„ÅåÊ§úÂá∫„Åï„Çå„Åæ„Åó„Åü„ÄÇ")
            save_screenshot(driver, "session_timeout_detected", screenshots_dir)
            return True
        else:
            return False
    except (TimeoutException, StaleElementReferenceException):
        return False
    except WebDriverException as e:
        if "invalid session id" in str(e).lower() or "no such window" in str(e).lower():
            print(f"[„Ç®„É©„Éº] „Çª„ÉÉ„Ç∑„Éß„É≥„Çø„Ç§„É†„Ç¢„Ç¶„Éà„ÉÅ„Çß„ÉÉ„ÇØ‰∏≠„Å´Ëá¥ÂëΩÁöÑ„Å™WebDriver„Ç®„É©„Éº: {e}")
            raise
        else:
            print(f"[„Ç®„É©„Éº] „Çª„ÉÉ„Ç∑„Éß„É≥„Çø„Ç§„É†„Ç¢„Ç¶„Éà„ÉÅ„Çß„ÉÉ„ÇØ‰∏≠„Å´‰∫àÊúü„Åõ„Å¨WebDriver„Ç®„É©„Éº: {e}")
            save_screenshot(driver, "session_check_webdriver_error", screenshots_dir)
            return False
    except Exception as e:
        print(f"[„Ç®„É©„Éº] „Çª„ÉÉ„Ç∑„Éß„É≥„Çø„Ç§„É†„Ç¢„Ç¶„Éà„ÉÅ„Çß„ÉÉ„ÇØ‰∏≠„Å´‰∫àÊúü„Åõ„Å¨„Ç®„É©„Éº: {e}")
        save_screenshot(driver, "session_check_unknown_error", screenshots_dir)
        traceback.print_exc()
        return False

def initialize_driver(driver_path, headless=False):
    """WebDriver (Chrome) „ÇíÂàùÊúüÂåñ„Åô„Çã"""
    print("\nWebDriver„ÇíÂàùÊúüÂåñ„Åó„Å¶„ÅÑ„Åæ„Åô...")
    options = webdriver.ChromeOptions()
    options.page_load_strategy = 'normal'
    
    # ÂÖ±ÈÄö„ÅÆÊúÄÈÅ©ÂåñË®≠ÂÆöÔºà„Éò„ÉÉ„Éâ„É¨„Çπ„É¢„Éº„Éâ„ÅÆÊúâÁÑ°„Å´Èñ¢„Çè„Çâ„ÅöÈÅ©Áî®Ôºâ
    prefs = {
        'profile.default_content_setting_values': { 
            'images': 2,  # ÁîªÂÉè„ÇíÁÑ°ÂäπÂåñ
            'plugins': 2,  # „Éó„É©„Ç∞„Ç§„É≥„ÇíÁÑ°ÂäπÂåñ
            'popups': 2,   # „Éù„ÉÉ„Éó„Ç¢„ÉÉ„Éó„ÇíÁÑ°ÂäπÂåñ
            'notifications': 2,  # ÈÄöÁü•„ÇíÁÑ°ÂäπÂåñ
            'automatic_downloads': 2  # Ëá™Âãï„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„ÇíÁÑ°ÂäπÂåñ
        },
        'credentials_enable_service': False,
        'profile.password_manager_enabled': False
    }
    options.add_experimental_option('prefs', prefs)
    
    # „Éò„ÉÉ„Éâ„É¨„Çπ„É¢„Éº„ÉâÂõ∫Êúâ„ÅÆË®≠ÂÆö
    if headless:
        options.add_argument('--headless')
        options.add_argument('--disable-gpu')
        options.add_argument('--window-size=1920,1080')
        options.add_argument('--blink-settings=imagesEnabled=false')
        print("„Éò„ÉÉ„Éâ„É¨„Çπ„É¢„Éº„Éâ„ÅßÂÆüË°å„Åó„Åæ„Åô„ÄÇ")
    
    # ÂÖ±ÈÄö„ÅÆ„Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÊúÄÈÅ©ÂåñË®≠ÂÆö
    options.add_argument('--disable-extensions')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-infobars')
    options.add_argument('--disable-blink-features=AutomationControlled')
    options.add_argument('--log-level=3')
    options.add_argument('--disable-background-networking')
    options.add_argument('--disable-default-apps')
    options.add_argument('--disable-sync')
    options.add_argument('--disable-translate')
    options.add_argument('--disable-popup-blocking')
    options.add_experimental_option('excludeSwitches', ['enable-automation', 'enable-logging'])
    options.add_experimental_option('useAutomationExtension', False)

    new_driver = None
    try:
        if driver_path and os.path.exists(driver_path):
            service = Service(executable_path=driver_path)
            new_driver = webdriver.Chrome(service=service, options=options)
            print(f"ÊåáÂÆö„Åï„Çå„ÅüChromeDriver„Çí‰ΩøÁî®: {driver_path}")
        else:
            print("ChromeDriver„Éë„ÇπÊú™ÊåáÂÆö/ÁÑ°Âäπ„ÅÆ„Åü„ÇÅ„ÄÅËá™ÂãïÊ§úÂá∫„Åó„Åæ„Åô„ÄÇ")
            service = Service()
            new_driver = webdriver.Chrome(service=service, options=options)
            print(f"Ëá™ÂãïÊ§úÂá∫„Åï„Çå„ÅüChromeDriver„Çí‰ΩøÁî®: {service.path}")
        new_driver.set_page_load_timeout(PAGE_LOAD_TIMEOUT)
        new_driver.implicitly_wait(5)
        print("WebDriver„ÅÆÂàùÊúüÂåñÂÆå‰∫Ü„ÄÇ")
        return new_driver
    except Exception as e:
        print(f"[ÈáçÂ§ß„Ç®„É©„Éº] WebDriver„ÅÆÂàùÊúüÂåñÂ§±Êïó: {e}")
        traceback.print_exc()
        return None


def recover_driver_session():
    """Recover an invalid WebDriver session by reinitializing the WebDriver"""
    print(f"[{time.strftime('%H:%M:%S')}] üîÑ Attempting to recover driver session...")
    try:
        global driver
        
        # Try to close the existing driver if it exists
        try:
            if 'driver' in globals() and driver:
                driver.quit()
        except Exception as e:
            print(f"[{time.strftime('%H:%M:%S')}] ‚ö†Ô∏è Error closing existing driver: {e}")
        
        # Initialize a new driver
        driver = initialize_driver(CHROME_DRIVER_PATH, HEADLESS_MODE)
        if not driver:
            print(f"[{time.strftime('%H:%M:%S')}] ‚ùå Failed to initialize new driver")
            return False
            
        # Attempt login
        if not login(driver, USER_EMAIL, USER_PASSWORD, screenshots_dir):
            print(f"[{time.strftime('%H:%M:%S')}] ‚ùå Failed to login with new driver")
            return False
            
        print(f"[{time.strftime('%H:%M:%S')}] ‚úÖ Driver session successfully recovered")
        globals()['driver'] = driver  # Ensure global driver is updated
        return True
        
    except Exception as e:
        print(f"[{time.strftime('%H:%M:%S')}] ‚ùå Session recovery failed: {str(e)}")
        return False

# Add new recovery function here
def recover_webdriver(screenshots_dir):
    """WebDriver„Çí„É™„Ç´„Éê„É™„Éº„Åó„ÄÅÂÜç„É≠„Ç∞„Ç§„É≥„ÇíË©¶„Åø„Çã"""
    retries = 3
    
    for attempt in range(retries):
        try:
            print(f"\n[ÊÉÖÂ†±] WebDriverÂÜçÂàùÊúüÂåñË©¶Ë°å ({attempt + 1}/{retries})...")
            
            # Âè§„ÅÑ„Éâ„É©„Ç§„Éê„Éº„ÇíÈñâ„Åò„Çã
            try:
                if 'driver' in globals() and driver:
                    driver.quit()
            except Exception as e:
                print(f"[Ë≠¶Âëä] Âè§„ÅÑ„Éâ„É©„Ç§„Éê„ÉºÁµÇ‰∫Ü„Ç®„É©„Éº: {e}")
            
            # Êñ∞„Åó„ÅÑ„Éâ„É©„Ç§„Éê„Éº„ÇíÂàùÊúüÂåñ
            new_driver = initialize_driver(CHROME_DRIVER_PATH, HEADLESS_MODE)
            if not new_driver:
                print("[„Ç®„É©„Éº] WebDriverÂàùÊúüÂåñÂ§±Êïó")
                time.sleep(3)
                continue
                
            # „É≠„Ç∞„Ç§„É≥Ë©¶Ë°å
            if not login(new_driver, USER_EMAIL, USER_PASSWORD, screenshots_dir):
                print("[„Ç®„É©„Éº] „É≠„Ç∞„Ç§„É≥Â§±Êïó")
                if new_driver:
                    new_driver.quit()
                time.sleep(3)
                continue
                
            print("[ÊàêÂäü] WebDriverÂÜçÂàùÊúüÂåñ„Å®„É≠„Ç∞„Ç§„É≥ÂÆå‰∫Ü")
            return new_driver
            
        except Exception as e:
            print(f"[„Ç®„É©„Éº] WebDriver„É™„Ç´„Éê„É™„Éº‰∏≠„ÅÆ‰∫àÊúü„Åõ„Å¨„Ç®„É©„Éº: {e}")
            traceback.print_exc()
            time.sleep(3)
    
    print("[ÈáçÂ§ß„Ç®„É©„Éº] WebDriver„É™„Ç´„Éê„É™„ÉºÂ§±Êïó")
    return None

# --- ‚òÖ‚òÖ‚òÖ JSON„Éï„Ç°„Ç§„É´Êõ∏„ÅçËæº„ÅøÈñ¢Êï∞ (Â§âÊõ¥„Å™„Åó) ‚òÖ‚òÖ‚òÖ ---
def write_json_data(data, path):
    """ÊåáÂÆö„Åï„Çå„Åü„Éë„Çπ„Å´JSON„Éá„Éº„Çø„ÇíÊõ∏„ÅçËæº„ÇÄ"""
    print(f"\n'{path}' „Å∏Êõ∏„ÅçËæº„Åø‰∏≠ ({len(data)} ‰ª∂)...")
    try:
        os.makedirs(os.path.dirname(path), exist_ok=True)
        with open(path, mode='w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)
        print(f"JSONÊõ∏„ÅçËæº„ÅøÂÆå‰∫Ü„ÄÇ")
    except Exception as e:
        print(f"[„Ç®„É©„Éº] JSONÊõ∏„ÅçËæº„Åø„Ç®„É©„Éº: {e}")

# Missing function that I realized is referenced but wasn't included in the original code
def pause_on_error(error_message, exception=None, screenshot_path=None):
    """„Ç®„É©„ÉºÁô∫ÁîüÊôÇ„Å´Âá¶ÁêÜ„Çí‰∏ÄÊôÇÂÅúÊ≠¢„Åó„ÄÅ„É¶„Éº„Ç∂„Éº„Å´Á∂öË°å„Åô„Çã„ÅãÁ¢∫Ë™ç„Åô„Çã"""
    print(f"\n[„Ç®„É©„Éº] {error_message}")
    if exception: print(f"‰æãÂ§ñË©≥Á¥∞: {exception}")
    if screenshot_path: print(f"„Çπ„ÇØ„É™„Éº„É≥„Ç∑„Éß„ÉÉ„Éà: {screenshot_path}")
    
    # Â∏∏„Å´Á∂öË°å„Åô„Çã (Ëá™ÂãïÂá¶ÁêÜ„É¢„Éº„Éâ)
    return True
    
    # ‰ª•‰∏ã„ÅÆ„Ç≥„Éº„Éâ„ÅØ„É¶„Éº„Ç∂„ÉºÁ¢∫Ë™ç„ÅåÂøÖË¶Å„Å™Â†¥Âêà„Å´‰ΩøÁî®
    # try:
    #     response = input("\nÂá¶ÁêÜ„ÇíÁ∂öË°å„Åó„Åæ„Åô„ÅãÔºü (y/n): ").strip().lower()
    #     return response in ('y', 'yes', '')
    # except KeyboardInterrupt:
    #     print("\n„Ç≠„Éº„Éú„Éº„ÉâÂâ≤„ÇäËæº„Åø„Å´„Çà„Çä‰∏≠Êñ≠„ÄÇ")
    #     return False

# --- ‚òÖ‚òÖ‚òÖ „É°„Ç§„É≥Âá¶ÁêÜ (ÈÄêÊ¨°Âá¶ÁêÜ„Å´Êàª„Åô) ‚òÖ‚òÖ‚òÖ ---
if __name__ == "__main__":
    output_dir, logs_dir, screenshots_dir = create_output_dirs(OUTPUT_DIR_NAME)
    resume_checkpoint = load_checkpoint()
    starting_year_index = 0
    starting_field_index = 0
    starting_page_num = 0
    processed_urls = set()
    if resume_checkpoint:
        # „É¶„Éº„Ç∂„ÉºÁ¢∫Ë™ç
        resume_choice = input(f"\n„ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åó„Åü (Âπ¥Â∫¶: {resume_checkpoint['year']}, ÂàÜÈáé: {resume_checkpoint['field_name']}, „Éö„Éº„Ç∏: {resume_checkpoint['page_num']})„ÄÇ"
                            f"\nÂÜçÈñã„Åó„Åæ„Åô„ÅãÔºü (y/n): ").strip().lower()
        
        if resume_choice in ('y', 'yes', ''):
            # TARGET_YEARS„Å®TARGET_FIELDS„Åã„Çâ„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„ÇíÊ§úÁ¥¢
            if resume_checkpoint['year'] in TARGET_YEARS:
                starting_year_index = TARGET_YEARS.index(resume_checkpoint['year'])
            else:
                print(f"[Ë≠¶Âëä] „ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„ÅÆÂπ¥Â∫¶ {resume_checkpoint['year']} „ÅØÁèæÂú®„ÅÆÂØæË±°Âπ¥Â∫¶„Å´„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇÊúÄÂàù„Åã„ÇâÈñãÂßã„Åó„Åæ„Åô„ÄÇ")
                
            if resume_checkpoint['field_name'] in TARGET_FIELDS:
                starting_field_index = TARGET_FIELDS.index(resume_checkpoint['field_name'])
            else:
                print(f"[Ë≠¶Âëä] „ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„ÅÆÂàÜÈáé {resume_checkpoint['field_name']} „ÅØÁèæÂú®„ÅÆÂØæË±°ÂàÜÈáé„Å´„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ„Åì„ÅÆÂπ¥Â∫¶„ÅÆÊúÄÂàù„Åã„ÇâÈñãÂßã„Åó„Åæ„Åô„ÄÇ")
                starting_field_index = 0
                
            starting_page_num = resume_checkpoint['page_num']
            processed_urls = set(resume_checkpoint['processed_urls'])
            print(f"\n[ÊÉÖÂ†±] „ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„Åã„ÇâÂÜçÈñã: Âπ¥Â∫¶={resume_checkpoint['year']} („Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ: {starting_year_index}), "
                f"ÂàÜÈáé={resume_checkpoint['field_name']} („Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ: {starting_field_index}), „Éö„Éº„Ç∏={starting_page_num}, Âá¶ÁêÜÊ∏àURLÊï∞={len(processed_urls)}")
        else:
            print("\n[ÊÉÖÂ†±] ÊúÄÂàù„Åã„ÇâÈñãÂßã„Åó„Åæ„Åô„ÄÇ")

    start_time_dt = datetime.datetime.now()
    start_time_dt = datetime.datetime.now()
    output_json_path = os.path.join(output_dir, OUTPUT_JSON_FILE)
    driver = None
    scraped_data_all_years = []
    global_start_time = time.time()
    print(f"„Çπ„ÇØ„É¨„Ç§„Éî„É≥„Ç∞ÈñãÂßã: {start_time_dt.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ÂØæË±°Âπ¥Â∫¶: {TARGET_YEARS}")
    print(f"ÂØæË±°ÂàÜÈáé: {TARGET_FIELDS}")
    print(f"Âá∫ÂäõÂÖàJSON: {output_json_path}")
    print(f"‰∏¶ÂàóÂá¶ÁêÜ: ÁÑ°Âäπ (ÈÄêÊ¨°Âá¶ÁêÜ)") # ‰∏¶ÂàóÂá¶ÁêÜ„ÅØÁÑ°Âäπ

    driver = initialize_driver(CHROME_DRIVER_PATH, HEADLESS_MODE)
    if not driver:
        sys.exit("Ëá¥ÂëΩÁöÑ„Ç®„É©„Éº: WebDriver„ÇíÂàùÊúüÂåñ„Åß„Åç„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ")
    try:
        if not login(driver, USER_EMAIL, USER_PASSWORD, screenshots_dir):
            sys.exit("Ëá¥ÂëΩÁöÑ„Ç®„É©„Éº: ÂàùÊúü„É≠„Ç∞„Ç§„É≥„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ")
        print("\nË™çË®ºÊÉÖÂ†±„ÇíÊäΩÂá∫‰∏≠...")
        auth_cookies = extract_auth_cookies(driver)
        if auth_cookies:
            print(f"Ë™çË®ºCookieÂèñÂæóÊàêÂäü: {len(auth_cookies)}ÂÄã„ÅÆCookie„ÇíÂÖ±Êúâ„Åó„Åæ„Åô")
        else:
            print("[Ë≠¶Âëä] Ë™çË®ºCookieÂèñÂæóÂ§±Êïó„ÄÇÂêÑ„Çπ„É¨„ÉÉ„Éâ„ÅåÂÄãÂà•„Å´„É≠„Ç∞„Ç§„É≥„Åó„Åæ„Åô„ÄÇ")
    except Exception as initial_login_e:
        print(f"Ëá¥ÂëΩÁöÑ„Ç®„É©„Éº: ÂàùÊúü„É≠„Ç∞„Ç§„É≥‰∏≠„Å´‰∫àÊúü„Åõ„Å¨‰æãÂ§ñ„ÅåÁô∫Áîü: {initial_login_e}")
        traceback.print_exc()
        if driver:
            try:
                save_screenshot(driver, "initial_login_fatal_error", screenshots_dir)
                driver.quit()
            except Exception as qe: print(f"ÂàùÊúü„É≠„Ç∞„Ç§„É≥„Ç®„É©„ÉºÂæå„ÅÆ„Éñ„É©„Ç¶„Ç∂ÁµÇ‰∫ÜÊôÇ„Ç®„É©„Éº: {qe}")
        sys.exit(1)

# --- „É°„Ç§„É≥„É´„Éº„Éó ---
    try:
        year_index = starting_year_index
        while year_index < len(TARGET_YEARS):
            year = TARGET_YEARS[year_index]
            print(f"\n<<<<< {year}Âπ¥Â∫¶ „ÅÆÂá¶ÁêÜÈñãÂßã >>>>>")
            year_processed_successfully = True

            # „Åô„Åπ„Å¶„ÅÆÂπ¥Â∫¶„ÅßÊ®ôÊ∫ñÁöÑ„Å™„Çø„Ç§„É†„Ç¢„Ç¶„ÉàË®≠ÂÆö„Çí‰ΩøÁî®
            current_page_timeout = PAGE_LOAD_TIMEOUT
            current_element_timeout = ELEMENT_WAIT_TIMEOUT
            
            # „Åì„ÅÆÂπ¥Â∫¶„ÅÆÂá¶ÁêÜÈñãÂßã„Éï„Ç£„Éº„É´„Éâ„Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ„ÇíË®≠ÂÆö
            field_index = starting_field_index if year_index == starting_year_index else 0
            
            while field_index < len(TARGET_FIELDS):
                field_name = TARGET_FIELDS[field_index]
                print(f"\n===== ÂàÜÈáé: {field_name} ({year}Âπ¥Â∫¶) „ÅÆÂá¶ÁêÜÈñãÂßã =====")
                field_processed_successfully = True
                field_total_attempts = 0
                field_error_count = 0
                consecutive_errors = 0
                ttck_error_count = 0  # TTCKÁßëÁõÆÂ∞ÇÁî®„ÅÆ„Ç®„É©„Éº„Ç´„Ç¶„É≥„Çø„Éº
                
                # „Åì„ÅÆÂàÜÈáé„ÅÆÂá¶ÁêÜÊ∏à„ÅøURLÔºà„ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„Åã„Çâ„É≠„Éº„Éâ„ÄÅ„Åæ„Åü„ÅØÊñ∞Ë¶è‰ΩúÊàêÔºâ
                if year_index == starting_year_index and field_index == starting_field_index:
                    opened_links_this_year_field = processed_urls
                    # „Åì„ÅÆÂàÜÈáé„ÅÆÈñãÂßã„Éö„Éº„Ç∏Áï™Âè∑Ôºà„ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„Åã„Çâ„É≠„Éº„Éâ„ÄÅ„Åæ„Åü„ÅØÊúÄÂàù„Åã„ÇâÔºâ
                    last_processed_page_num = starting_page_num
                else:
                    opened_links_this_year_field = set()
                    last_processed_page_num = 0
                    
                # „ÉÅ„Çß„ÉÉ„ÇØ„Éù„Ç§„É≥„Éà„Çí‰ΩøÁî®„Åó„Åü„ÅÆ„Åß„É™„Çª„ÉÉ„ÉàÔºàÊ¨°„ÅÆÂàÜÈáé„Å®Âπ¥Â∫¶„Åß„ÅØÊúÄÂàù„Åã„ÇâÈñãÂßã„Åô„Çã„Åü„ÇÅÔºâ
                if year_index == starting_year_index and field_index == starting_field_index:
                    starting_page_num = 0

                try:
                    if check_session_timeout(driver, screenshots_dir):
                        print("„Çª„ÉÉ„Ç∑„Éß„É≥„Çø„Ç§„É†„Ç¢„Ç¶„ÉàÊ§úÂá∫„ÄÇÂÜç„É≠„Ç∞„Ç§„É≥Ë©¶Ë°å...")
                        if not login(driver, USER_EMAIL, USER_PASSWORD, screenshots_dir):
                            print("[„Ç®„É©„Éº] ÂÜç„É≠„Ç∞„Ç§„É≥Â§±Êïó„ÄÇ„Åì„ÅÆÂàÜÈáé„Çí„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åô„ÄÇ")
                            field_index += 1; continue

                    try:
                        current_url_check = driver.current_url
                        if "gslbs.keio.jp/syllabus/search" not in current_url_check:
                            print("Ê§úÁ¥¢„Éö„Éº„Ç∏‰ª•Â§ñ„Å´„ÅÑ„Çã„Åü„ÇÅ„ÄÅÊ§úÁ¥¢„Éö„Éº„Ç∏„Å´ÁßªÂãï„Åó„Åæ„Åô„ÄÇ")
                            driver.get('https://gslbs.keio.jp/syllabus/search')
                            WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.url_contains("gslbs.keio.jp/syllabus/search"))
                            time.sleep(MEDIUM_WAIT)
                    except WebDriverException as e_url_check:
                        screenshot_path = save_screenshot(driver, f"url_check_error_{year}_{field_name}", screenshots_dir)
                        print(f"[Ë≠¶Âëä] ÁèæÂú®„ÅÆURLÁ¢∫Ë™ç‰∏≠„Å´„Ç®„É©„Éº: {e_url_check}„ÄÇ")
                        
                        if not pause_on_error("WebDriver exception during URL check", e_url_check, screenshot_path):
                            print("„É¶„Éº„Ç∂„Éº„Å´„Çà„Çã‰∏≠Êñ≠„ÄÇ„Çπ„ÇØ„É™„Éó„Éà„ÇíÁµÇ‰∫Ü„Åó„Åæ„Åô„ÄÇ")
                            sys.exit(1)
                        
                        raise InvalidSessionIdException("URL check failed, likely closed window.") from e_url_check

                    # --- Ê§úÁ¥¢Êù°‰ª∂Ë®≠ÂÆö (JSÈ´òÈÄüÂåñ + Selenium„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ) ---
                    js_search_success = False
                    try: # JavaScript„Åß„ÅÆË®≠ÂÆöË©¶Ë°å
                        fast_search_js = """
                            async function setSearchCriteria(year, fieldName) {
                                try {
                                    var yearSelect = document.querySelector('select[name="KEYWORD_TTBLYR"]');
                                    if (yearSelect) { yearSelect.value = year; yearSelect.dispatchEvent(new Event('change', {bubbles:true})); }
                                    else { console.error('Year select not found'); return false; }

                                    var toggleButton = document.querySelector('button[data-target*="screensearch-cond-option-toggle-target"]');
                                    if (toggleButton) {
                                        var toggleTarget = document.querySelector(toggleButton.getAttribute('data-target'));
                                        if (toggleTarget && !toggleTarget.classList.contains('show')) {
                                            toggleButton.click(); await new Promise(r => setTimeout(r, 700));
                                        }
                                    }

                                    var fieldSelect = document.querySelector('select[name="KEYWORD_FLD1CD"]');
                                    if (fieldSelect) {
                                        let fieldFound = false;
                                        for (let i = 0; i < fieldSelect.options.length; i++) {
                                            if (fieldSelect.options[i].text.trim() === fieldName) {
                                                fieldSelect.selectedIndex = i; fieldSelect.dispatchEvent(new Event('change', {bubbles:true}));
                                                fieldFound = true; break;
                                            }
                                        }
                                        if (!fieldFound) console.warn('Field option not found: ' + fieldName);
                                    } else { console.error('Field select not found'); return false; }

                                    var checkbox = document.querySelector('input[name="KEYWORD_LVL"][value="3"]');
                                    if (checkbox && checkbox.checked) { checkbox.checked = false; checkbox.dispatchEvent(new Event('change', {bubbles:true})); }

                                    return true;
                                } catch (error) { console.error('Error in setSearchCriteria:', error); return false; }
                            }
                            return await setSearchCriteria(arguments[0], arguments[1]);
                        """
                        result = driver.execute_script(fast_search_js, str(year), field_name)
                        if result:
                            print(f"   JavaScript„ÅßÊ§úÁ¥¢Êù°‰ª∂„Çí‰∏ÄÊã¨Ë®≠ÂÆö„Åó„Åæ„Åó„ÅüÔºàÂπ¥Â∫¶: {year}, ÂàÜÈáé: {field_name}Ôºâ")
                            time.sleep(MEDIUM_WAIT); js_search_success = True
                        else: print(f"   JavaScriptÊ§úÁ¥¢Ë®≠ÂÆö„ÅßÂïèÈ°åÁô∫Áîü„ÄÇÈÄöÂ∏∏ÊñπÊ≥ï„ÅßË©¶Ë°å„Åó„Åæ„Åô„ÄÇ")
                    except Exception as js_err: print(f"   JavaScriptÊ§úÁ¥¢Ë®≠ÂÆöÂ§±Êïó: {js_err}„ÄÇÈÄöÂ∏∏ÊñπÊ≥ï„ÅßË©¶Ë°å„Åó„Åæ„Åô„ÄÇ")

                    if not js_search_success: # Selenium„Åß„ÅÆË®≠ÂÆö („Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ)
                        # Âπ¥Â∫¶ÈÅ∏Êäû
                        year_select_xpath = "//select[@name='KEYWORD_TTBLYR']"
                        year_select_element = WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.presence_of_element_located((By.XPATH, year_select_xpath)))
                        if not select_option_by_text(driver, year_select_element, str(year)):
                            print(f"     [Ë≠¶Âëä] Âπ¥Â∫¶ '{year}' „ÅÆÈÅ∏Êäû„Å´Â§±Êïó„ÄÇ„Åì„ÅÆÂàÜÈáé„Çí„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åô„ÄÇ")
                            save_screenshot(driver, f"year_selection_failed_{year}_{field_name}", screenshots_dir); field_index += 1; continue
                        print(f"   Âπ¥Â∫¶ '{year}' „ÇíÈÅ∏Êäû„Åó„Åæ„Åó„Åü„ÄÇ"); time.sleep(SHORT_WAIT)
                        # Ë©≥Á¥∞„Ç™„Éó„Ç∑„Éß„É≥Â±ïÈñã
                        try:
                            adv_button_xpath = "//button[contains(@data-target, 'screensearch-cond-option-toggle-target')]"
                            advanced_options_button = WebDriverWait(driver, SHORT_WAIT).until(EC.element_to_be_clickable((By.XPATH, adv_button_xpath)))
                            target_selector = advanced_options_button.get_attribute('data-target')
                            target_element = driver.find_element(By.CSS_SELECTOR, target_selector)
                            if advanced_options_button and not target_element.is_displayed():
                                print("   Â±ïÈñã„Éú„Çø„É≥„Çí„ÇØ„É™„ÉÉ„ÇØ„Åó„Å¶Ë©≥Á¥∞„Ç™„Éó„Ç∑„Éß„É≥„ÇíË°®Á§∫„Åó„Åæ„Åô„ÄÇ")
                                driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", advanced_options_button); time.sleep(0.5)
                                driver.execute_script("arguments[0].click();", advanced_options_button); time.sleep(1.5)
                            # else: print("   Ë©≥Á¥∞„Ç™„Éó„Ç∑„Éß„É≥„ÅØÊó¢„Å´Â±ïÈñãÊ∏à„Åø„ÄÅ„Åæ„Åü„ÅØ„Éú„Çø„É≥„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„ÄÇ") # „É≠„Ç∞ÁúÅÁï•ÂèØ
                        except Exception as e: print(f"   Ë©≥Á¥∞„Ç™„Éó„Ç∑„Éß„É≥Â±ïÈñã„Éú„Çø„É≥„ÅÆÊìç‰Ωú‰∏≠„Å´„Ç®„É©„Éº: {e}")
                        # ÂàÜÈáéÈÅ∏Êäû
                        field_select_xpath = "//select[@name='KEYWORD_FLD1CD']"
                        max_retries = 3; field_selected = False
                        for retry in range(max_retries):
                            try:
                                field_select_element = WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.element_to_be_clickable((By.XPATH, field_select_xpath)))
                                driver.execute_script("arguments[0].scrollIntoView({block: 'center', behavior: 'smooth'});", field_select_element); time.sleep(1.0)
                                if select_option_by_text(driver, field_select_element, field_name):
                                    print(f"   ÂàÜÈáé '{field_name}' „ÇíÈÅ∏Êäû„Åó„Åæ„Åó„Åü„ÄÇ"); time.sleep(MEDIUM_WAIT); field_selected = True; break
                                else: print(f"   ÂàÜÈáé '{field_name}' „ÅÆÈÅ∏Êäû„Å´Â§±ÊïóÔºàË©¶Ë°å {retry+1}/{max_retries}Ôºâ")
                            except Exception as e:
                                print(f"   „É™„Éà„É©„Ç§ {retry+1}/{max_retries}: ÂàÜÈáé '{field_name}' ÈÅ∏Êäû‰∏≠„Å´„Ç®„É©„Éº: {e}")
                                if retry < max_retries - 1:
                                     print("      „Éö„Éº„Ç∏„Çí„É™„Éï„É¨„ÉÉ„Ç∑„É•„Åó„Å¶ÂÜçË©¶Ë°å„Åó„Åæ„Åô...")
                                     driver.refresh()
                                     WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.presence_of_element_located((By.TAG_NAME, "body"))); time.sleep(MEDIUM_WAIT)
                                     year_select_element_retry = WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.presence_of_element_located((By.XPATH, year_select_xpath)))
                                     select_option_by_text(driver, year_select_element_retry, str(year)); time.sleep(SHORT_WAIT)
                                else: print("      „É™„Éï„É¨„ÉÉ„Ç∑„É•Âæå„ÅÆÂÜçË©¶Ë°å„ÇÇÂ§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ")
                                time.sleep(MEDIUM_WAIT)
                        if not field_selected:
                             print(f"     [Ë≠¶Âëä] ÂàÜÈáé '{field_name}' „ÅÆÈÅ∏Êäû„Åå {max_retries} ÂõûÂ§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åô„ÄÇ")
                             save_screenshot(driver, f"field_selection_failed_{field_name}_{year}", screenshots_dir); field_index += 1; continue
                        # Â≠¶Âπ¥„ÉÅ„Çß„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„ÇπËß£Èô§
                        try:
                            cb_xpath = "//input[@name='KEYWORD_LVL' and @value='3']"
                            cb = WebDriverWait(driver, SHORT_WAIT).until(EC.presence_of_element_located((By.XPATH, cb_xpath)))
                            if cb.is_selected():
                                print("   Â≠¶Âπ¥„Äå3Âπ¥„Äç„ÅÆ„ÉÅ„Çß„ÉÉ„ÇØ„ÇíÂ§ñ„Åó„Åæ„Åô„ÄÇ")
                                driver.execute_script("arguments[0].click();", cb); time.sleep(0.5)
                        except TimeoutException: pass
                        except Exception as e_cb: print(f"           Â≠¶Âπ¥„ÉÅ„Çß„ÉÉ„ÇØ„Éú„ÉÉ„ÇØ„ÇπÂá¶ÁêÜ„Ç®„É©„Éº: {e_cb}")

                    # --- Ê§úÁ¥¢ÂÆüË°å ---
                    search_xpath = "//button[@data-action_id='SYLLABUS_SEARCH_KEYWORD_EXECUTE'] | //button[contains(text(), 'Ê§úÁ¥¢')]"
                    search_button = WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(EC.element_to_be_clickable((By.XPATH, search_xpath)))
                    print("   Ê§úÁ¥¢„Éú„Çø„É≥„Çí„ÇØ„É™„ÉÉ„ÇØ„Åó„Åæ„Åô...")
                    if not click_element(driver, search_button):
                        print("     [„Ç®„É©„Éº] Ê§úÁ¥¢„Éú„Çø„É≥„ÇØ„É™„ÉÉ„ÇØÂ§±Êïó„ÄÇ„Åì„ÅÆÂàÜÈáé„Çí„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åô„ÄÇ")
                        save_screenshot(driver, f"search_button_click_failed_{year}_{field_name}", screenshots_dir); field_index += 1; continue

                    # --- ÁµêÊûúË°®Á§∫ÂæÖÊ©ü ---
                    # Êã°Âºµ„Åï„Çå„ÅüÁµêÊûú„Ç§„É≥„Ç∏„Ç±„Éº„Çø„ÉºXPath
                    result_indicator_xpath = (
                        "//a[contains(@class, 'syllabus-detail')] | "
                        "//a[contains(@class, 'btn-info')] | "
                        "//div[contains(text(), 'Ë©≤ÂΩì„Åô„Çã„Éá„Éº„Çø„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì')] | "
                        "//ul[contains(@class, 'pagination')] | "
                        "//table[contains(@class, 'search-result')] | "
                        "//div[contains(text(), '‰ª∂') and contains(text(), '‰∏≠')] | "
                        "//div[@class='search-result-list']"
                    )
                    print("   Ê§úÁ¥¢ÁµêÊûúË°®Á§∫ÂæÖÊ©ü‰∏≠...")
                    # Ê§úÁ¥¢ÁµêÊûú„ÅÆÂæÖÊ©üÂá¶ÁêÜ„ÇíÊîπÂñÑÔºàÊúÄÂ§ß3Âõû„É™„Éà„É©„Ç§Ôºâ
                    max_search_retries = 3
                    for search_retry in range(max_search_retries):
                        try:
                            print(f"   Ê§úÁ¥¢ÁµêÊûúË°®Á§∫ÂæÖÊ©ü‰∏≠... (Ë©¶Ë°å {search_retry + 1}/{max_search_retries})")
                            # ‰∏ÄÊó¶Áü≠„ÅÑ„Çø„Ç§„É†„Ç¢„Ç¶„Éà„ÅßË©¶„Åó„Å¶„Åø„Çã
                            try:
                                WebDriverWait(driver, min(30, current_element_timeout/2)).until(
                                    EC.presence_of_element_located((By.XPATH, result_indicator_xpath))
                                )
                                print("   Ê§úÁ¥¢ÁµêÊûúË°®Á§∫ÂÆå‰∫Ü„ÄÇ")
                                break
                            except TimeoutException:
                                # „Éö„Éº„Ç∏„ÅåÂÆåÂÖ®„Å´Ë™≠„ÅøËæº„Åæ„Çå„Å¶„ÅÑ„Å™„ÅÑÂèØËÉΩÊÄß„Åå„ÅÇ„Çã„Åü„ÇÅ„ÄÅ„É™„É≠„Éº„Éâ
                                if search_retry < max_search_retries - 1:
                                    print(f"   Ê§úÁ¥¢ÁµêÊûúË°®Á§∫„Çø„Ç§„É†„Ç¢„Ç¶„Éà„ÄÅ„Éö„Éº„Ç∏„Çí„É™„É≠„Éº„Éâ„Åó„Å¶ÂÜçË©¶Ë°å„Åó„Åæ„Åô... ({search_retry + 1}/{max_search_retries})")
                                    driver.refresh()
                                    time.sleep(MEDIUM_WAIT * 2)
                                    
                                    # Ê§úÁ¥¢Êù°‰ª∂„ÇíÂÜçË®≠ÂÆö„Åó„Å¶Ê§úÁ¥¢„Éú„Çø„É≥„ÇíÂÜçÂ∫¶„ÇØ„É™„ÉÉ„ÇØ
                                    if not js_search_success:
                                        # Âπ¥Â∫¶ÈÅ∏Êäû
                                        year_select_xpath = "//select[@name='KEYWORD_TTBLYR']"
                                        year_select_element = WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(
                                            EC.presence_of_element_located((By.XPATH, year_select_xpath))
                                        )
                                        select_option_by_text(driver, year_select_element, str(year))
                                        time.sleep(MEDIUM_WAIT)
                                        
                                        # ÂàÜÈáéÈÅ∏Êäû
                                        field_select_xpath = "//select[@name='KEYWORD_FLD1CD']"
                                        field_select_element = WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(
                                            EC.presence_of_element_located((By.XPATH, field_select_xpath))
                                        )
                                        select_option_by_text(driver, field_select_element, field_name)
                                        time.sleep(MEDIUM_WAIT)
                                    
                                    # Ê§úÁ¥¢„Éú„Çø„É≥„ÇíÂÜç„ÇØ„É™„ÉÉ„ÇØ
                                    search_xpath = "//button[@data-action_id='SYLLABUS_SEARCH_KEYWORD_EXECUTE'] | //button[contains(text(), 'Ê§úÁ¥¢')]"
                                    search_button = WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(
                                        EC.element_to_be_clickable((By.XPATH, search_xpath))
                                    )
                                    click_element(driver, search_button)
                                    
                                    # Èï∑„ÇÅ„ÅÆ„Çø„Ç§„É†„Ç¢„Ç¶„Éà„ÅßÊúÄÁµÇË©¶Ë°å
                                    if search_retry == max_search_retries - 2:
                                        WebDriverWait(driver, current_element_timeout).until(
                                            EC.presence_of_element_located((By.XPATH, result_indicator_xpath))
                                        )
                                        print("   Ê§úÁ¥¢ÁµêÊûúË°®Á§∫ÂÆå‰∫Ü„ÄÇ")
                                        break
                                else:
                                    # ÊúÄÁµÇË©¶Ë°å„Åß„ÇÇ„Çø„Ç§„É†„Ç¢„Ç¶„Éà„Åó„ÅüÂ†¥Âêà
                                    raise TimeoutException(f"Ê§úÁ¥¢ÁµêÊûú„ÅÆË°®Á§∫„Å´ {max_search_retries} ÂõûÂ§±Êïó„Åó„Åæ„Åó„Åü")
                        except TimeoutException as e_timeout:
                            if search_retry == max_search_retries - 1:
                                print(f"     [„Ç®„É©„Éº] Ê§úÁ¥¢ÁµêÊûú„ÅåË°®Á§∫„Åï„Çå„Åæ„Åõ„Çì„ÄÇ„Åì„ÅÆÂàÜÈáé„Çí„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åô„ÄÇ")
                                save_screenshot(driver, f"search_timeout_{year}_{field_name}", screenshots_dir)
                                field_index += 1
                                field_processed_successfully = False
                                year_processed_successfully = False
                                break
                        except Exception as e_search:
                            print(f"     [„Ç®„É©„Éº] Ê§úÁ¥¢Âá¶ÁêÜ‰∏≠„Å´‰∫àÊúü„Åõ„Å¨„Ç®„É©„Éº: {e_search}")
                            save_screenshot(driver, f"search_error_{year}_{field_name}", screenshots_dir)
                            field_index += 1
                            field_processed_successfully = False
                            year_processed_successfully = False
                            traceback.print_exc()
                            break

                    # „Ç™„É™„Ç∏„Éä„É´„Ç≥„Éº„Éâ„ÅÆÁ∂ö„Åç (if field_processed_successfully „Åã„Çâ)
                    time.sleep(MEDIUM_WAIT); print("   Ê§úÁ¥¢ÁµêÊûúË°®Á§∫ÂÆå‰∫Ü„ÄÇ")

                    # --- Ë©≤ÂΩì„Å™„Åó„ÉÅ„Çß„ÉÉ„ÇØ ---
                    try:
                        no_result_element = driver.find_element(By.XPATH, "//div[contains(text(), 'Ë©≤ÂΩì„Åô„Çã„Éá„Éº„Çø„ÅØ„ÅÇ„Çä„Åæ„Åõ„Çì')]")
                        if no_result_element.is_displayed():
                            print(f"   [ÊÉÖÂ†±] {year}Âπ¥Â∫¶„ÄÅÂàÜÈáé '{field_name}' „Å´Ë©≤ÂΩì„Éá„Éº„Çø„Å™„Åó„ÄÇ")
                            field_index += 1; continue
                    except NoSuchElementException: pass

                    # --- „ÇΩ„Éº„ÉàÈ†ÜÂ§âÊõ¥ (ÁßëÁõÆÂêçÈ†Ü) ---
                    try:
                        sort_xpath = "//select[@name='SEARCH_RESULT_NARABIJUN']"
                        sort_element = WebDriverWait(driver, MEDIUM_WAIT).until(EC.presence_of_element_located((By.XPATH, sort_xpath)))
                        current_sort_value = Select(sort_element).first_selected_option.get_attribute('value')
                        if current_sort_value != '2':
                            print("   „ÇΩ„Éº„ÉàÈ†Ü„Çí„ÄåÁßëÁõÆÂêçÈ†Ü„Äç„Å´Â§âÊõ¥Ë©¶Ë°å...")
                            if not select_option_by_text(driver, sort_element, "ÁßëÁõÆÂêçÈ†Ü"):
                                try: Select(sort_element).select_by_value("2"); print("           „ÇΩ„Éº„ÉàÈ†Ü„Çí Value='2' „ÅßÈÅ∏Êäû„Åó„Åæ„Åó„Åü„ÄÇ")
                                except Exception as e_sort_val:
                                    print(f"           [Ë≠¶Âëä] Value='2'„Åß„ÅÆ„ÇΩ„Éº„ÉàÂ§±Êïó: {e_sort_val}„ÄÇJS„ÅßË©¶Ë°å...")
                                    try: driver.execute_script("arguments[0].value = '2'; arguments[0].dispatchEvent(new Event('change', { bubbles: true }));", sort_element); print("           JS„Åß„ÇΩ„Éº„ÉàÈ†Ü Value='2' „ÇíË®≠ÂÆö„Åó„Åæ„Åó„Åü„ÄÇ")
                                    except Exception as e_js: print(f"           [Ë≠¶Âëä] JS„Åß„ÅÆ„ÇΩ„Éº„Éà„ÇÇÂ§±Êïó: {e_js}")
                            else: print("           „ÇΩ„Éº„ÉàÈ†Ü„Çí„ÄåÁßëÁõÆÂêçÈ†Ü„Äç„ÅßÈÅ∏Êäû„Åó„Åæ„Åó„Åü„ÄÇ")
                            time.sleep(MEDIUM_WAIT)
                            WebDriverWait(driver, current_element_timeout).until(EC.presence_of_element_located((By.XPATH, result_indicator_xpath)))
                            time.sleep(MEDIUM_WAIT)
                        # else: print("   „ÇΩ„Éº„ÉàÈ†Ü„ÅØÊó¢„Å´„ÄåÁßëÁõÆÂêçÈ†Ü„Äç„Åß„Åô„ÄÇ") # „É≠„Ç∞ÁúÅÁï•ÂèØ
                    except TimeoutException: pass
                    except Exception as e_sort: print(f"   [Ë≠¶Âëä] „ÇΩ„Éº„ÉàË®≠ÂÆö„Ç®„É©„Éº: {e_sort}")

                    # --- „Éö„Éº„Ç∏„Éç„Éº„Ç∑„Éß„É≥„É´„Éº„Éó (ÈÄêÊ¨°Âá¶ÁêÜ) ---
                    last_processed_page_num = 0
                    processed_page_numbers = set()  # Add this to track which pages we've already processed

                    while True:
                        print(f"\n     --- „Éö„Éº„Ç∏„Éç„Éº„Ç∑„Éß„É≥„Éñ„É≠„ÉÉ„ÇØÂá¶ÁêÜÈñãÂßã (ÊúÄÁµÇÂá¶ÁêÜ„Éö„Éº„Ç∏: {last_processed_page_num}) ---")
                        pagination_processed_in_block = False
                        current_page_links_processed_in_block = set()

                        # --- 1. „Ç¢„ÇØ„ÉÜ„Ç£„Éñ„Éö„Éº„Ç∏Âá¶ÁêÜ ---
                        current_active_page_num = -1
                        try:
                            pagination_container = WebDriverWait(driver, MEDIUM_WAIT).until(EC.presence_of_element_located((By.XPATH, "//ul[contains(@class, 'pagination')]")))
                            try:
                                active_page_element = pagination_container.find_element(By.XPATH, ".//li[contains(@class, 'active')]/span | .//li[contains(@class, 'active')]/a")
                                current_active_page_num = int(normalize_text(active_page_element.text))
                                print(f"         ÁèæÂú®„ÅÆ„Ç¢„ÇØ„ÉÜ„Ç£„Éñ„Éö„Éº„Ç∏: {current_active_page_num}")
                            except (NoSuchElementException, ValueError) as e_active:
                                print(f"         „Ç¢„ÇØ„ÉÜ„Ç£„Éñ„Éö„Éº„Ç∏Áï™Âè∑„ÅÆÂèñÂæó„Å´Â§±Êïó: {e_active}")
                                if last_processed_page_num == 0: print("         ÊúÄÂàù„ÅÆ„Éö„Éº„Ç∏(1)„Å®„Åó„Å¶Âá¶ÁêÜ„ÇíË©¶„Åø„Åæ„Åô..."); current_active_page_num = 1
                                else: print("         [„Ç®„É©„Éº] „Ç¢„ÇØ„ÉÜ„Ç£„Éñ„Éö„Éº„Ç∏„ÇíÁâπÂÆö„Åß„Åç„Åö„ÄÅÂá¶ÁêÜ„ÇíÁ∂öË°å„Åß„Åç„Åæ„Åõ„Çì„ÄÇ"); field_processed_successfully = False; year_processed_successfully = False; break

                            # Add check for already processed pages to avoid infinite loops
                            if current_active_page_num in processed_page_numbers:
                                print(f"         „Éö„Éº„Ç∏ {current_active_page_num} „ÅØÊó¢„Å´Âá¶ÁêÜÊ∏à„Åø„Åß„Åô„ÄÇÊ¨°„ÅÆ„Éö„Éº„Ç∏„ÇíË©¶Ë°å„Åó„Åæ„Åô„ÄÇ")
                            elif current_active_page_num > 0:  # Don't rely on last_processed_page_num check
                                print(f"         „Éö„Éº„Ç∏ {current_active_page_num} „ÇíÂá¶ÁêÜ„Åó„Åæ„Åô...")
                                syllabus_link_xpath = ""
                                # For 2025 and later
                                if year >= 2025:
                                    # 2025Âπ¥Â∫¶‰ª•Èôç„ÅÆÊñ∞„Ç∑„Çπ„ÉÜ„É†Áî®
                                    syllabus_link_xpath = "//a[contains(@class, 'syllabus-detail')]"
                                else:
                                    # 2024Âπ¥Â∫¶‰ª•Ââç„ÅÆÊóß„Ç∑„Çπ„ÉÜ„É†Áî®
                                    syllabus_link_xpath = (
                                        "//a[contains(@class, 'btn-info')] | "
                                        "//a[contains(@class, 'fa-book')] | "
                                        "//td//a[contains(@href, 'syllabus')] | "
                                        "//td//a[contains(@href, 'courses/2024')] | "
                                        "//a[contains(@title, '„Ç∑„É©„Éê„Çπ')] | "
                                        "//span[2]/a[contains(@href, 'syllabus') or contains(@href, 'courses')]"
                                    )

                                urls_on_page = []
                                buttons_on_page = []
                                processed_count_on_page = 0

                                try:
                                    # „Åæ„Åö‰∏ÄËà¨ÁöÑ„Å™„É™„É≥„ÇØ„Åå„ÅÇ„Çã„Åã„ÇíÁ¢∫Ë™ç
                                    WebDriverWait(driver, MEDIUM_WAIT).until(EC.presence_of_element_located((By.TAG_NAME, "a")))
                                    print("         „Éö„Éº„Ç∏„ÅÆÂÆåÂÖ®„Å™„É≠„Éº„Éâ„ÇíÂæÖÊ©ü‰∏≠...")
                                    time.sleep(2)  # „Ç∑„É©„Éê„Çπ„É™„É≥„ÇØÊäΩÂá∫Ââç„Å´2Áßí„ÅÆËøΩÂä†ÂæÖÊ©ü
                                    # „Åô„Åπ„Å¶„ÅÆ„É™„É≥„ÇØ„ÇíÂèñÂæó„Åó„Å¶Ë™øÊüª
                                    all_links = driver.find_elements(By.TAG_NAME, "a")
                                    print(f"         „Éö„Éº„Ç∏‰∏ä„ÅÆ„É™„É≥„ÇØÊï∞: {len(all_links)}")
                                    
                                    # „Çµ„É≥„Éó„É´„É™„É≥„ÇØ„ÇíË°®Á§∫
                                    for i, link in enumerate(all_links[:5]):
                                        link_text = link.text.strip() if link.text else "„ÉÜ„Ç≠„Çπ„Éà„Å™„Åó"
                                        link_class = link.get_attribute("class") or "„ÇØ„É©„Çπ„Å™„Åó"
                                        link_href = link.get_attribute("href") or "„É™„É≥„ÇØ„Å™„Åó"
                                        link_onclick = link.get_attribute("onclick") or "„Å™„Åó"
                                        print(f"         „É™„É≥„ÇØ{i+1}: „ÉÜ„Ç≠„Çπ„Éà={link_text}, „ÇØ„É©„Çπ={link_class}, URL={link_href}, onClick={link_onclick}")
                                    
                                    # „Ç∑„É©„Éê„ÇπË©≥Á¥∞„É™„É≥„ÇØ„ÅÆÊ§úÁ¥¢
                                    # IMPORTANT: Replace these lines with more comprehensive syllabus link XPath from csv10.py
                                    if year >= 2025:
                                        # 2025Âπ¥Â∫¶‰ª•Èôç„ÅÆÊñ∞„Ç∑„Çπ„ÉÜ„É†Áî®
                                        syllabus_link_xpath = "//a[contains(@class, 'syllabus-detail')]"
                                    else:
                                        # 2024Âπ¥Â∫¶‰ª•Ââç„ÅÆÊóß„Ç∑„Çπ„ÉÜ„É†Áî®
                                        syllabus_link_xpath = (
                                            "//a[contains(@class, 'btn-info')] | "
                                            "//a[contains(@class, 'fa-book')] | "
                                            "//td//a[contains(@href, 'syllabus')] | "
                                            "//td//a[contains(@href, 'courses/2024')] | "
                                            "//a[contains(@title, '„Ç∑„É©„Éê„Çπ')] | "
                                            "//span[2]/a[contains(@href, 'syllabus') or contains(@href, 'courses')]"
                                        )
                                        
                                    buttons_on_page = driver.find_elements(By.XPATH, syllabus_link_xpath)
                                    print(f"         „Ç∑„É©„Éê„Çπ„É™„É≥„ÇØÊï∞: {len(buttons_on_page)}")
                                    
                                    # onclickÂ±ûÊÄß„Åã„ÇâURL„ÇíÂèñÂæóÔºàJS„Çí‰ΩøÁî®„Åô„ÇãÂ†¥Âêà„ÅÆ„Åü„ÇÅÔºâ
                                    try:
                                        # Use ONLY JavaScript as the URL detection method
                                        js_script = """
                                        // Target all syllabus detail links
                                        const syllabusUrls = [];

                                        // First approach: Get all links with syllabus-detail class (for 2025+ system)
                                        const detailLinks = document.querySelectorAll('a.syllabus-detail');
                                        detailLinks.forEach(link => {
                                            if (link.href) {
                                                syllabusUrls.push(link.href);
                                            }
                                        });

                                        // Second approach: Get all blue buttons with class btn-info (for older system)
                                        const blueButtons = document.querySelectorAll('a.btn-info, button.btn-info');
                                        blueButtons.forEach(button => {
                                            if (button.href) {
                                                syllabusUrls.push(button.href);
                                            }
                                        });

                                        // Third approach: Look for syllabus links in table cells
                                        document.querySelectorAll('td a').forEach(link => {
                                            if (link.href && (link.href.includes('syllabus') || 
                                                            link.href.includes('entno=') || 
                                                            link.href.includes('courses'))) {
                                                syllabusUrls.push(link.href);
                                            }
                                        });

                                        // Fourth approach: Check for onclick handlers on buttons
                                        document.querySelectorAll('a[onclick], button[onclick]').forEach(el => {
                                            if (el.onclick) {
                                                const onclickStr = el.onclick.toString();
                                                if (onclickStr.includes('syllabus') || onclickStr.includes('detail')) {
                                                    const matches = onclickStr.match(/window\.open\(['"]([^'"]+)['"]/);
                                                    if (matches && matches[1]) {
                                                        syllabusUrls.push(matches[1]);
                                                    }
                                                }
                                            }
                                        });

                                        return [...new Set(syllabusUrls)];
                                        """
                                        urls_on_page = driver.execute_script(js_script)
                                        print(f"         JavaScript„ÅßÊ§úÂá∫„Åó„ÅüURLÊï∞: {len(urls_on_page)}")
                                        for i, url in enumerate(urls_on_page[:5]):
                                            print(f"         JS-URL{i+1}: {url}")
                                        
                                        # Basic filtering to remove non-syllabus URLs
                                        filtered_urls = []
                                        for url in urls_on_page:
                                            if url and not url.endswith('#') and not '/result#' in url:
                                                if year <= 2024:
                                                    if ("syllabus" in url or "courses" in url or "entno=" in url) and not "search" in url:
                                                        filtered_urls.append(url)
                                                else:
                                                    # For 2025 and later, just check for key identifiers
                                                    if "detail" in url or "syllabus" in url or "entno=" in url:
                                                        filtered_urls.append(url)
                                        
                                        urls_on_page = filtered_urls
                                        print(f"         „Éï„Ç£„É´„Çø„É™„É≥„Ç∞Âæå„ÅÆÊúâÂäπURLÊï∞: {len(urls_on_page)}")
                                        for i, url in enumerate(urls_on_page[:5]):
                                            print(f"         ÊúâÂäπURL {i+1}: {url}")
                                        
                                    except Exception as js_e:
                                        print(f"         [Ë≠¶Âëä] JavaScript URLÊäΩÂá∫„Ç®„É©„Éº: {js_e}")
                                        urls_on_page = []
                                    
                                    
                                    
                                    # ÈáçË§á„ÇíÂâäÈô§
                                    print(f"         ÊúÄÁµÇÂá¶ÁêÜÂØæË±°URLÊï∞: {len(urls_on_page)}")
                                    for i, url in enumerate(urls_on_page):
                                        print(f"         ÊúÄÁµÇURL {i+1}: {url}")
                                    # „Ç∑„É©„Éê„ÇπË©≥Á¥∞„Éö„Éº„Ç∏„ÅÆURL„ÅÆ„Åø„Çí„Éï„Ç£„É´„Çø„É™„É≥„Ç∞„Åó„Å¶ÊÆã„Åô
                                    filtered_urls = []
                                    for url in urls_on_page:
                                        if not url.endswith('#') and not '/result#' in url:
                                            if year <= 2024:
                                                if ("syllabus" in url or "courses" in url or "entno=" in url) and not "search" in url:
                                                    filtered_urls.append(url)
                                            else:
                                                filtered_urls.append(url)
                                        else:
                                            print(f"         „Çπ„Ç≠„ÉÉ„Éó: „Éä„Éì„Ç≤„Éº„Ç∑„Éß„É≥„Éè„ÉÉ„Ç∑„É•URL: {url}")

                                    urls_on_page = filtered_urls

                                    # „Éï„Ç£„É´„Çø„ÉºÂæå„ÅÆURL„Å´ÁΩÆ„ÅçÊèõ„Åà
                                    urls_on_page = filtered_urls
                                    print(f"         „Éï„Ç£„É´„Çø„É™„É≥„Ç∞Âæå„ÅÆÊúâÂäπURLÊï∞: {len(urls_on_page)}")
                                    for i, url in enumerate(urls_on_page[:5]):  # ÊúÄÂàù„ÅÆ5„Å§„ÅÆ„ÅøË°®Á§∫
                                        print(f"         ÊúâÂäπURL {i+1}: {url}")
                                    print(f"         ÊúÄÁµÇÁöÑ„Å´ÊäΩÂá∫„Åó„ÅüURLÊï∞: {len(urls_on_page)}")
                                    for i, url in enumerate(urls_on_page[:5]):
                                        print(f"         URL{i+1}: {url}")

                                    # Add debug logging for URL detection
                                    if not urls_on_page:
                                        print("         [Ë≠¶Âëä] „Éö„Éº„Ç∏‰∏ä„ÅÆ„Ç∑„É©„Éê„Çπ„É™„É≥„ÇØ„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇHTMLÊßãÈÄ†„ÇíÂá∫Âäõ„Åó„Åæ„Åô„ÄÇ")
                                        try:
                                            # „Éö„Éº„Ç∏„ÅÆ‰∏ªË¶ÅÊßãÈÄ†„ÇíÂá∫Âäõ
                                            js_debug = """
                                            const tables = document.querySelectorAll('table');
                                            let tableInfo = [];
                                            tables.forEach((table, idx) => {
                                                tableInfo.push({
                                                    index: idx,
                                                    rows: table.rows.length,
                                                    links: table.querySelectorAll('a').length,
                                                    buttons: table.querySelectorAll('button').length
                                                });
                                            });
                                            return {
                                                tables: tableInfo,
                                                allLinks: document.querySelectorAll('a').length,
                                                allButtons: document.querySelectorAll('button').length,
                                                bodyHTML: document.body.innerHTML.substring(0, 500) + '...'  // ÂÖàÈ†≠500ÊñáÂ≠ó„ÅÆ„Åø
                                            };
                                            """
                                            debug_info = driver.execute_script(js_debug)
                                            print(f"         „ÉÜ„Éº„Éñ„É´Êï∞: {len(debug_info['tables'])}")
                                            for i, table in enumerate(debug_info['tables']):
                                                print(f"         „ÉÜ„Éº„Éñ„É´ #{i+1}: {table['rows']}Ë°å, {table['links']}„É™„É≥„ÇØ, {table['buttons']}„Éú„Çø„É≥")
                                            print(f"         Á∑è„É™„É≥„ÇØÊï∞: {debug_info['allLinks']}, Á∑è„Éú„Çø„É≥Êï∞: {debug_info['allButtons']}")
                                            print(f"         HTMLÊßãÈÄ†„Éó„É¨„Éì„É•„Éº: {debug_info['bodyHTML']}")
                                            
                                            # „Çπ„ÇØ„É™„Éº„É≥„Ç∑„Éß„ÉÉ„Éà„Çí‰øùÂ≠ò
                                            save_screenshot(driver, f"no_links_found_{year}_{field_name}_page{current_active_page_num}", screenshots_dir)
                                        except Exception as debug_e:
                                            print(f"         [Ë≠¶Âëä] „Éá„Éê„ÉÉ„Ç∞ÊÉÖÂ†±ÂèñÂæó„Ç®„É©„Éº: {debug_e}")
                                    
                                    if len(urls_on_page) > 0:
                                        print(f"         {len(urls_on_page)} ‰ª∂„ÅÆURL„ÇíÂá¶ÁêÜ„Åó„Åæ„Åô...")
                                        processed_count_on_page = 0
                                        field_total_attempts = 0
                                        field_error_count = 0
                                        consecutive_errors = 0
                                        
                                        for index, syllabus_url in enumerate(urls_on_page):
                                            # Check if this URL has already been processed
                                            if syllabus_url in opened_links_this_year_field:
                                                print(f"           URL {index + 1}/{len(urls_on_page)}: {syllabus_url} „ÅØÊó¢„Å´Âá¶ÁêÜÊ∏à„Åø„ÅÆ„Åü„ÇÅ„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åô")
                                                continue

                                            print(f"\n           Ë©≥Á¥∞Âá¶ÁêÜ {index + 1}/{len(urls_on_page)}: {syllabus_url}")
                                            syllabus_details = None
                                            
                                            try:
                                                # Store the main window handle first for reliable tab management
                                                main_window = driver.current_window_handle
                                                
                                                if check_session_timeout(driver, screenshots_dir):
                                                    raise InvalidSessionIdException("Session timeout before detail fetch")
                                                
                                                # Open a new tab instead of navigating in the current tab
                                                print(f"           Êñ∞„Åó„ÅÑ„Çø„Éñ„ÇíÈñã„ÅÑ„Å¶Ë©≥Á¥∞„Éö„Éº„Ç∏„ÇíË°®Á§∫„Åó„Åæ„Åô...")
                                                driver.switch_to.new_window('tab')
                                                detail_tab = driver.current_window_handle
                                                
                                                # Navigate to the syllabus URL in the new tab
                                                driver.get(syllabus_url)
                                                
                                                # Process the page
                                                WebDriverWait(driver, min(30, ELEMENT_WAIT_TIMEOUT)).until(EC.presence_of_element_located((By.TAG_NAME, "body")))

                                                print(f"           Ë©≥Á¥∞„Éö„Éº„Ç∏Ë™≠„ÅøËæº„ÅøÂÆå‰∫Ü„ÄÇÂá¶ÁêÜÈñãÂßã...")
                                                time.sleep(MEDIUM_WAIT)
                                                
                                                # Get syllabus details - this function already handles both Japanese and English data
                                                syllabus_details = get_syllabus_details(driver, year, screenshots_dir)
                                                
                                                # Close the detail tab and switch back to main window
                                                print(f"           Ë©≥Á¥∞„Éö„Éº„Ç∏Âá¶ÁêÜÂÆå‰∫Ü„ÄÇ„Çø„Éñ„ÇíÈñâ„Åò„Å¶Ê§úÁ¥¢ÁµêÊûú„Å´Êàª„Çä„Åæ„Åô...")
                                                driver.close()
                                                driver.switch_to.window(main_window)
                                                time.sleep(SHORT_WAIT)

                                                # Only mark as processed if we actually got details
                                                if syllabus_details:
                                                    print(f"           Ë©≥Á¥∞ÊÉÖÂ†±ÂèñÂæóÊàêÂäü„ÄÇ„Éá„Éº„ÇøËøΩÂä†„Åó„Åæ„Åô„ÄÇ")
                                                    # Extract identifiers for logging
                                                    course_id = syllabus_details.get('course_id', 'unknown')
                                                    course_name = syllabus_details.get('translations', {}).get('ja', {}).get('name', 'Unknown')
                                                    professor = syllabus_details.get('professor_ja', 'Unknown')
                                                    field = syllabus_details.get('field_ja', 'Unknown')
                                                    
                                                    # Add to results and mark as processed
                                                    scraped_data_all_years.append(syllabus_details)
                                                    opened_links_this_year_field.add(syllabus_url)
                                                    processed_count_on_page += 1
                                                    consecutive_errors = 0
                                                    
                                                    print(f"           ‚úÖ ÊàêÂäü: ID:{course_id} | {course_name} | Prof:{professor} | Field:{field}")
                                                else:
                                                    print(f"           Ë©≥Á¥∞ÊÉÖÂ†±„ÅÆÂèñÂæó„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇ")
                                                    field_error_count += 1
                                                    consecutive_errors += 1
                                            except InvalidSessionIdException as e_session:
                                                print(f"           [„Ç®„É©„Éº] „Çª„ÉÉ„Ç∑„Éß„É≥„Ç®„É©„Éº: {e_session}")
                                                
                                                if recover_driver_session():
                                                    print(f"           „Çª„ÉÉ„Ç∑„Éß„É≥„ÇíÂõûÂæ©„Åó„Åæ„Åó„Åü„ÄÇÊ¨°„ÅÆURL„Å´ÈÄ≤„Åø„Åæ„Åô...")
                                                    driver = globals()['driver']  # Get the new driver
                                                    # Update main window in case of session recovery
                                                    main_window = driver.current_window_handle
                                                else:
                                                    print(f"           „Çª„ÉÉ„Ç∑„Éß„É≥ÂõûÂæ©„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇÂá¶ÁêÜ„Çí‰∏≠Êñ≠„Åó„Åæ„Åô„ÄÇ")
                                                    field_error_count += 1
                                                    consecutive_errors += 1
                                            except Exception as e:
                                                print(f"           [„Ç®„É©„Éº] Ë©≥Á¥∞„Éö„Éº„Ç∏Âá¶ÁêÜ‰∏≠„Å´„Ç®„É©„Éº: {e}")
                                                
                                                # Try to close the tab and return to main window
                                                try:
                                                    driver.close()
                                                    driver.switch_to.window(main_window)
                                                except Exception as tab_error:
                                                    print(f"           [Ë≠¶Âëä] „Çø„Éñ„ÇíÈñâ„Åò„ÇãÈöõ„Å´„Ç®„É©„Éº: {tab_error}")
                                                    
                                                    # Attempt to recover if tab management failed
                                                    try:
                                                        # Check if we have multiple windows open and need to close extras
                                                        if len(driver.window_handles) > 1:
                                                            print(f"           Ë§áÊï∞„ÅÆ„Ç¶„Ç£„É≥„Éâ„Ç¶„ÅåÈñã„ÅÑ„Å¶„ÅÑ„Åæ„Åô„ÄÇÂÖÉ„ÅÆ„Ç¶„Ç£„É≥„Éâ„Ç¶„Å´Êàª„Çä„Åæ„Åô...")
                                                            for handle in driver.window_handles:
                                                                if handle != main_window:
                                                                    driver.switch_to.window(handle)
                                                                    driver.close()
                                                            driver.switch_to.window(main_window)
                                                        else:
                                                            # If we're down to one window, it might not be the search results page
                                                            print(f"           Ê§úÁ¥¢„Éö„Éº„Ç∏„Å´Êàª„Çä„Åæ„Åô...")
                                                            driver.get('https://gslbs.keio.jp/syllabus/search')
                                                            WebDriverWait(driver, ELEMENT_WAIT_TIMEOUT).until(
                                                                EC.presence_of_element_located((By.XPATH, "//button[@data-action_id='SYLLABUS_SEARCH_KEYWORD_EXECUTE']"))
                                                            )
                                                            js_script = """
                                                                function getPageData() {
                                                                    const data = {};
                                                                    // Process Japanese page data
                                                                    try {
                                                                        data.course_name = document.querySelector('.class-name')?.textContent.trim() || "ÂêçÁß∞‰∏çÊòé";
                                                                        data.semester = document.querySelector('tr th:contains("Âπ¥Â∫¶„ÉªÂ≠¶Êúü") + td')?.textContent.trim() || "Â≠¶Êúü‰∏çÊòé";
                                                                        data.professor = document.querySelector('tr th:contains("ÊãÖÂΩìËÄÖÂêç") + td')?.textContent.trim() || "";
                                                                        data.credits = document.querySelector('tr th:contains("Âçò‰Ωç") + td')?.textContent.trim() || "Âçò‰Ωç‰∏çÊòé";
                                                                        data.field = document.querySelector('tr th:contains("ÂàÜÈáé") + td')?.textContent.trim() || "ÂàÜÈáé‰∏çÊòé";
                                                                        data.location = document.querySelector('tr th:contains("ÊïôÂÆ§") + td, tr th:contains("ÈñãË¨õÂ†¥ÊâÄ") + td')?.textContent.trim() || "ÊïôÂÆ§‰∏çÊòé";
                                                                        data.day_period = document.querySelector('tr th:contains("ÊõúÊó•ÊôÇÈôê") + td')?.textContent.trim() || "ÊõúÊó•ÊôÇÈôê‰∏çÊòé";
                                                                        data.selection_method = document.querySelector('tr th:contains("ÈÅ∏ÊäúÊñπÊ≥ï") + td')?.textContent.trim() || "";
                                                                        data.class_format = document.querySelector('tr th:contains("ÊéàÊ•≠ÂÆüÊñΩÂΩ¢ÊÖã") + td')?.textContent.trim() || "";
                                                                    } catch(e) {
                                                                        console.error("Error extracting Japanese data:", e);
                                                                    }
                                                                    return data;
                                                                }
                                                                return getPageData();
                                                            """
                                                            ja_data = driver.execute_script(js_script)
                                                            driver.execute_script(js_script, str(year), field_name)
                                                            time.sleep(MEDIUM_WAIT)
                                                    except Exception as recovery_error:
                                                        print(f"           [Ë≠¶Âëä] „É™„Ç´„Éê„É™„Éº‰∏≠„Å´„Ç®„É©„Éº: {recovery_error}")
                                                        field_error_count += 1
                                                        consecutive_errors += 1
                                                        continue
                                                        
                                                field_error_count += 1
                                                consecutive_errors += 1
                                            
                                            # Check consecutive errors threshold
                                            if ENABLE_AUTO_HALT and consecutive_errors >= CONSECUTIVE_ERROR_THRESHOLD:
                                                print(f"           [!!!] {consecutive_errors}Âõû„ÅÆÈÄ£Á∂ö„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü„ÄÇWebDriver„ÇíÂÜçÂàùÊúüÂåñ„Åó„Åæ„Åô...")
                                                if recover_driver_session():
                                                    consecutive_errors = 0
                                                    print("           ‚úÖ WebDriverÂÜçÂàùÊúüÂåñ„Å´ÊàêÂäü„Åó„Åæ„Åó„Åü„ÄÇÁ∂öË°å„Åó„Åæ„Åô„ÄÇ")
                                                    # Reload search page and redo search after full recovery
                                                    driver = globals()['driver']
                                                    main_window = driver.current_window_handle
                                                else:
                                                    print("           ‚ùå WebDriverÂÜçÂàùÊúüÂåñ„Å´Â§±Êïó„Åó„Åæ„Åó„Åü„ÄÇÂá¶ÁêÜ„Çí‰∏≠Êñ≠„Åó„Åæ„Åô„ÄÇ")
                                                    break
                                            
                                            # Brief pause between URLs to avoid hammering the server
                                            time.sleep(SHORT_WAIT)

                                    if processed_count_on_page > 0:
                                        save_checkpoint(year, field_name, current_active_page_num, opened_links_this_year_field)
                                        print(f"         „Éö„Éº„Ç∏ {current_active_page_num} „ÅÆÂá¶ÁêÜ„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„Åü: {processed_count_on_page}‰ª∂Âá¶ÁêÜÊ∏à")
                                    else:
                                        print(f"         Âá¶ÁêÜÂØæË±°„ÅÆURL„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü")

                                except TimeoutException:
                                    print(f"         [Ë≠¶Âëä] „Ç∑„É©„Éê„Çπ„É™„É≥„ÇØ„ÅÆË™≠„ÅøËæº„Åø„Çø„Ç§„É†„Ç¢„Ç¶„Éà")
                                    buttons_on_page = []
                                except Exception as e:
                                    print(f"         [Ë≠¶Âëä] „Ç∑„É©„Éê„Çπ„É™„É≥„ÇØ„ÅÆÂèñÂæó„Ç®„É©„Éº: {e}")
                                    traceback.print_exc()
                                    buttons_on_page = []

                                # Mark this page as processed and update the last processed page number
                                processed_page_numbers.add(current_active_page_num)
                                last_processed_page_num = current_active_page_num
                                current_page_links_processed_in_block.add(current_active_page_num)
                                pagination_processed_in_block = True
                                print(f"         „Éö„Éº„Ç∏ {current_active_page_num} „ÅÆÂá¶ÁêÜ„ÅåÂÆå‰∫Ü„Åó„Åæ„Åó„Åü„ÄÇ")

                            # --- 2. „ÇØ„É™„ÉÉ„ÇØÂèØËÉΩ„Å™„Éö„Éº„Ç∏Áï™Âè∑Âá¶ÁêÜ ---
                            page_number_elements_info = []
                            page_number_links_xpath = ".//li[not(contains(@class, 'active')) and not(contains(@class, 'disabled'))]/a[number(text()) = number(text())]"
                            try:
                                pagination_container_refresh = WebDriverWait(driver, SHORT_WAIT).until(EC.presence_of_element_located((By.XPATH, "//ul[contains(@class, 'pagination')]")))
                                page_number_elements = pagination_container_refresh.find_elements(By.XPATH, page_number_links_xpath)
                            except (TimeoutException, NoSuchElementException): page_number_elements = []

                            for link_element in page_number_elements:
                                try:
                                    page_num = int(normalize_text(link_element.text))
                                    # Only add unprocessed pages to the navigation targets
                                    if page_num not in processed_page_numbers and page_num not in current_page_links_processed_in_block:
                                        page_number_elements_info.append((page_num, link_element))
                                except (ValueError, StaleElementReferenceException): continue

                        except (NoSuchElementException, TimeoutException) as e_paginate_find:
                            if len(processed_page_numbers) <= 1 and current_active_page_num <= 1:
                                print("         „Éö„Éº„Ç∏„Éç„Éº„Ç∑„Éß„É≥Ë¶ÅÁ¥†„ÅåË¶ã„Å§„Åã„Çâ„Å™„ÅÑ„Åã„ÄÅÊúÄÂàù„ÅÆ„Éö„Éº„Ç∏„ÅÆ„Åø„Åß„Åô„ÄÇ")
                                if current_active_page_num > 0: pagination_processed_in_block = True
                            else: print(f"         [Ë≠¶Âëä] „Éö„Éº„Ç∏„Éç„Éº„Ç∑„Éß„É≥Ë¶ÅÁ¥†„ÅÆÂèñÂæó„Å´Â§±Êïó: {e_paginate_find}„ÄÇ")
                            if len(processed_page_numbers) > 0 and all(p in processed_page_numbers for p in range(1, max(processed_page_numbers) + 1)):
                                print("         „Åô„Åπ„Å¶„ÅÆ„Éö„Éº„Ç∏„ÇíÂá¶ÁêÜ„Åó„Åæ„Åó„Åü„ÄÇ„Éö„Éº„Ç∏„Éç„Éº„Ç∑„Éß„É≥„ÇíÁµÇ‰∫Ü„Åó„Åæ„Åô„ÄÇ")
                                break
                            break
                        except Exception as e_paginate_outer:
                            print(f"         [„Ç®„É©„Éº] „Éö„Éº„Ç∏„Éç„Éº„Ç∑„Éß„É≥Âá¶ÁêÜ‰∏≠„Å´‰∫àÊúü„Åõ„Å¨„Ç®„É©„Éº: {e_paginate_outer}"); traceback.print_exc()
                            field_processed_successfully = False; year_processed_successfully = False; break

                        # Sort page elements by number to ensure we process them in order
                        page_number_elements_info.sort(key=lambda x: x[0])
                        clicked_page_link = False
                        
                        if page_number_elements_info:
                            print(f"         Êú™Âá¶ÁêÜ„Éö„Éº„Ç∏: {', '.join(str(p[0]) for p in page_number_elements_info)}")
                            for page_num, link_element_stub in page_number_elements_info:
                                print(f"         „Éö„Éº„Ç∏ {page_num} „Å∏„ÅÆÈÅ∑Áßª„ÇíË©¶„Åø„Åæ„Åô...")
                                try:
                                    link_to_click = WebDriverWait(driver, SHORT_WAIT).until(EC.element_to_be_clickable((By.XPATH, f"//ul[contains(@class, 'pagination')]//li/a[normalize-space(text())='{page_num}']")))
                                    if click_element(driver, link_to_click):
                                        print(f"         „Éö„Éº„Ç∏ {page_num} „Å∏ÈÅ∑Áßª„ÄÇÁµêÊûúÂæÖÊ©ü‰∏≠...")
                                        WebDriverWait(driver, current_element_timeout).until(EC.presence_of_element_located((By.XPATH, result_indicator_xpath)))
                                        time.sleep(MEDIUM_WAIT)
                                        clicked_page_link = True
                                        break
                                    else: print(f"         [Ë≠¶Âëä] „Éö„Éº„Ç∏ {page_num} „ÅÆ„ÇØ„É™„ÉÉ„ÇØ„Å´Â§±Êïó„ÄÇÊ¨°„ÅÆ„Éö„Éº„Ç∏Áï™Âè∑„ÇíË©¶„Åó„Åæ„Åô„ÄÇ"); continue
                                except (TimeoutException, StaleElementReferenceException, NoSuchElementException) as e_click:
                                    print(f"         [Ë≠¶Âëä] „Éö„Éº„Ç∏ {page_num} „ÅÆÊ§úÁ¥¢/„ÇØ„É™„ÉÉ„ÇØ‰∏≠„Å´„Ç®„É©„Éº: {e_click}„ÄÇÊ¨°„ÅÆ„Éö„Éº„Ç∏Áï™Âè∑„ÇíË©¶„Åó„Åæ„Åô„ÄÇ"); continue
                                except Exception as e_proc_outer:
                                    print(f"         [„Ç®„É©„Éº] „Éö„Éº„Ç∏ {page_num} „ÅÆÂá¶ÁêÜ‰∏≠„Å´‰∫àÊúü„Åõ„Å¨„Ç®„É©„Éº: {e_proc_outer}"); traceback.print_exc()
                                    field_processed_successfully = False; year_processed_successfully = False; break

                        if not field_processed_successfully: break
                        if clicked_page_link: continue

                        # --- 3. „ÄåÊ¨°„Å∏„Äç„Éú„Çø„É≥Âá¶ÁêÜ - only if no other pages to process ---
                        if not clicked_page_link and not page_number_elements_info:
                            try:
                                pagination_container_next = WebDriverWait(driver, SHORT_WAIT).until(EC.presence_of_element_located((By.XPATH, "//ul[contains(@class, 'pagination')]")))
                                next_xpath = ".//li[not(contains(@class, 'disabled'))]/a[contains(text(), 'Ê¨°') or contains(., 'Next')]"
                                next_button = pagination_container_next.find_element(By.XPATH, next_xpath)
                                print(f"\n         „ÄåÊ¨°„Å∏„Äç„Éú„Çø„É≥„ÇíÊ§úÂá∫„Åó„Åæ„Åó„Åü„ÄÇ„ÇØ„É™„ÉÉ„ÇØ„ÇíË©¶„Åø„Åæ„Åô...")
                                if click_element(driver, next_button):
                                    print("         „ÄåÊ¨°„Å∏„Äç„Çí„ÇØ„É™„ÉÉ„ÇØ„Åó„Åæ„Åó„Åü„ÄÇÁµêÊûúÂæÖÊ©ü‰∏≠...")
                                    WebDriverWait(driver, current_element_timeout).until(EC.presence_of_element_located((By.XPATH, result_indicator_xpath)))
                                    time.sleep(MEDIUM_WAIT)
                                    pagination_processed_in_block = True
                                    continue
                                else: print("         [Ë≠¶Âëä] „ÄåÊ¨°„Å∏„Äç„Éú„Çø„É≥„ÅÆ„ÇØ„É™„ÉÉ„ÇØ„Å´Â§±Êïó„ÄÇ„Éö„Éº„Ç∏„Éç„Éº„Ç∑„Éß„É≥„ÇíÁµÇ‰∫Ü„Åó„Åæ„Åô„ÄÇ"); break
                            except (NoSuchElementException, TimeoutException):
                                print(f"\n         „ÄåÊ¨°„Å∏„Äç„Éú„Çø„É≥„ÅåË¶ã„Å§„Åã„Çâ„Å™„ÅÑ„ÅãÁÑ°Âäπ„Åß„Åô„ÄÇ„Åô„Åπ„Å¶„ÅÆ„Éö„Éº„Ç∏„ÇíÂá¶ÁêÜÂÆå‰∫Ü„Åó„Åæ„Åó„Åü„ÄÇ"); break
                            except Exception as e_next:
                                print(f"         [„Ç®„É©„Éº] „ÄåÊ¨°„Å∏„Äç„Éú„Çø„É≥„ÅÆÊ§úÁ¥¢/„ÇØ„É™„ÉÉ„ÇØ‰∏≠„Å´„Ç®„É©„Éº: {e_next}„ÄÇ„Éö„Éº„Ç∏„Éç„Éº„Ç∑„Éß„É≥„ÇíÁµÇ‰∫Ü„Åó„Åæ„Åô„ÄÇ"); traceback.print_exc(); break
                                
                        # --- „Éö„Éº„Ç∏„Éç„Éº„Ç∑„Éß„É≥„É´„Éº„ÉóÂà§ÂÆö ---
                        if not pagination_processed_in_block and len(page_number_elements_info) == 0:
                            print("         „Åì„ÅÆ„Éñ„É≠„ÉÉ„ÇØ„Åß„Éö„Éº„Ç∏Âá¶ÁêÜ„ÅåË°å„Çè„Çå„Åö„ÄÅÊú™Âá¶ÁêÜ„Éö„Éº„Ç∏„ÇÇ„ÅÇ„Çä„Åæ„Åõ„Çì„ÄÇ„Éö„Éº„Ç∏„Éç„Éº„Ç∑„Éß„É≥„ÇíÁµÇ‰∫Ü„Åó„Åæ„Åô„ÄÇ")
                            break

                except (InvalidSessionIdException, NoSuchWindowException) as e_session_field:
                    print(f"\n[!!!] ÂàÜÈáé '{field_name}' ({year}Âπ¥Â∫¶) Âá¶ÁêÜ‰∏≠„Çª„ÉÉ„Ç∑„Éß„É≥/„Ç¶„Ç£„É≥„Éâ„Ç¶„Ç®„É©„Éº: {e_session_field}„ÄÇWebDriverÂÜçËµ∑ÂãïË©¶Ë°å„ÄÇ")
                    if driver:
                        try: driver.quit()
                        except Exception as quit_err: print(f" WebDriverÁµÇ‰∫Ü„Ç®„É©„Éº: {quit_err}")
                    driver = None
                    driver = initialize_driver(CHROME_DRIVER_PATH, HEADLESS_MODE)
                    # Rest of existing code...
                    if not driver: print("[!!!] WebDriverÂÜçÂàùÊúüÂåñÂ§±Êïó„ÄÇ„Çπ„ÇØ„É™„Éó„Éà„ÇíÁµÇ‰∫Ü„Åó„Åæ„Åô„ÄÇ"); raise Exception("WebDriverÂÜçÂàùÊúüÂåñÂ§±Êïó„ÄÇ")
                    try:
                        if not login(driver, USER_EMAIL, USER_PASSWORD, screenshots_dir): print("[!!!] ÂÜç„É≠„Ç∞„Ç§„É≥Â§±Êïó„ÄÇ„Çπ„ÇØ„É™„Éó„Éà„ÇíÁµÇ‰∫Ü„Åó„Åæ„Åô„ÄÇ"); raise Exception("ÂÜç„É≠„Ç∞„Ç§„É≥Â§±Êïó„ÄÇ")
                    except Exception as relogin_e: print(f"[!!!] ÂÜç„É≠„Ç∞„Ç§„É≥‰∏≠„Å´„Ç®„É©„Éº: {relogin_e}"); raise
                    print(f" WebDriverÂÜçËµ∑Âãï„ÉªÂÜç„É≠„Ç∞„Ç§„É≥ÂÆå‰∫Ü„ÄÇÂàÜÈáé '{field_name}' ({year}Âπ¥Â∫¶) ÂÜçË©¶Ë°å„ÄÇ")
                    field_index -= 1; field_processed_successfully = False; year_processed_successfully = False
                except Exception as e_field_main:
                    print(f"     [„Ç®„É©„Éº] ÂàÜÈáé '{field_name}' ({year}Âπ¥Â∫¶) Âá¶ÁêÜ‰∏≠„Ç®„É©„Éº: {e_field_main}"); traceback.print_exc()
                    save_screenshot(driver, f"field_main_error_{year}_{field_name}", screenshots_dir); print(" „Åì„ÅÆÂàÜÈáé„Çí„Çπ„Ç≠„ÉÉ„Éó„Åó„Åæ„Åô„ÄÇ")
                    field_processed_successfully = False; year_processed_successfully = False
                finally:
                    if field_processed_successfully: print(f"===== ÂàÜÈáé: {field_name} ({year}Âπ¥Â∫¶) Ê≠£Â∏∏ÁµÇ‰∫Ü =====")
                    else: print(f"===== ÂàÜÈáé: {field_name} ({year}Âπ¥Â∫¶) Âá¶ÁêÜ‰∏≠Êñ≠„Åæ„Åü„ÅØÂ§±Êïó =====")
                    # ÂàÜÈáéÂÆå‰∫Ü„Åî„Å®„ÄÅ„Åæ„Åü„ÅØ„Ç®„É©„ÉºÁô∫ÁîüÊôÇ„Å´JSONÊõ∏„ÅçËæº„Åø
                    if scraped_data_all_years:
                        print(f"\n--- JSON„Éï„Ç°„Ç§„É´Êõ¥Êñ∞ ({'„Ç®„É©„ÉºÁô∫ÁîüÊôÇÁÇπ' if not field_processed_successfully else 'ÂàÜÈáéÂÆå‰∫ÜÊôÇÁÇπ'}) ---")
                        final_data = aggregate_syllabus_data(scraped_data_all_years)
                        write_json_data(final_data, output_json_path)
                    # else: print("ÂèéÈõÜ„Éá„Éº„Çø„Åå„Å™„ÅÑ„Åü„ÇÅJSON„ÅØÊõ¥Êñ∞„Åï„Çå„Åæ„Åõ„Çì„ÄÇ") # „É≠„Ç∞ÁúÅÁï•ÂèØ

                field_index += 1
            # --- ÂàÜÈáé„É´„Éº„ÉóÁµÇ‰∫Ü ---

            if not year_processed_successfully: print(f"<<<<< {year}Âπ¥Â∫¶ „ÅÆÂá¶ÁêÜ‰∏≠„Å´„Ç®„É©„Éº„Åå„ÅÇ„Çä„Åæ„Åó„Åü„Åå„ÄÅÊ¨°„ÅÆÂπ¥Â∫¶„Å∏ÈÄ≤„Åø„Åæ„Åô >>>>>")
            else: print(f"<<<<< {year}Âπ¥Â∫¶ „ÅÆÂá¶ÁêÜÊ≠£Â∏∏ÁµÇ‰∫Ü >>>>>")
            year_index += 1
        # --- Âπ¥Â∫¶„É´„Éº„ÉóÁµÇ‰∫Ü ---

    # --- „Ç∞„É≠„Éº„Éê„É´ try/except/finally ---
    except KeyboardInterrupt: print("\n„Ç≠„Éº„Éú„Éº„ÉâÂâ≤„ÇäËæº„Åø„Å´„Çà„ÇäÂá¶ÁêÜ‰∏≠Êñ≠„ÄÇ")
    except SystemExit as e: print(f"\n„Çπ„ÇØ„É™„Éó„ÉàÂÅúÊ≠¢ (ÁµÇ‰∫Ü„Ç≥„Éº„Éâ: {e.code})„ÄÇ")
    except Exception as e_global:
        print(f"\n‚òÖ‚òÖ‚òÖ ÈáçÂ§ß„Ç®„É©„ÉºÁô∫Áîü„ÄÅÂá¶ÁêÜ‰∏≠Êñ≠: {e_global} ‚òÖ‚òÖ‚òÖ"); traceback.print_exc()
        if driver:
            print("ÈáçÂ§ß„Ç®„É©„ÉºÁô∫Áîü„ÅÆ„Åü„ÇÅ„ÄÅ„Çπ„ÇØ„É™„Éº„É≥„Ç∑„Éß„ÉÉ„Éà„ÇíË©¶„Åø„Åæ„Åô...")
            try: save_screenshot(driver, "fatal_error_global", screenshots_dir)
            except Exception as ss_err: print(f"[Ë≠¶Âëä] „Ç®„É©„ÉºÁô∫ÁîüÂæå„ÅÆ„Çπ„ÇØ„É™„Éº„É≥„Ç∑„Éß„ÉÉ„Éà‰øùÂ≠ò„Å´Â§±Êïó„Åó„Åæ„Åó„Åü: {ss_err}")
    finally:
        if driver:
            try: driver.quit(); print("\n„Éñ„É©„Ç¶„Ç∂ÁµÇ‰∫Ü„ÄÇ")
            except Exception as qe: print(f"\n„Éñ„É©„Ç¶„Ç∂ÁµÇ‰∫ÜÊôÇ„Ç®„É©„Éº: {qe}")

        print("\n=== ÊúÄÁµÇÂá¶ÁêÜ: JSON„Éï„Ç°„Ç§„É´Êõ∏„ÅçËæº„Åø ===")
        if scraped_data_all_years:
            print(f"ÂêàË®à {len(scraped_data_all_years)} ‰ª∂„ÅÆÁîü„Éá„Éº„ÇøÂèñÂæó„ÄÇ")
            print("\nÊúÄÁµÇ„Éá„Éº„ÇøÈõÜÁ¥Ñ‰∏≠...")
            final_json_data = aggregate_syllabus_data(scraped_data_all_years)
            if final_json_data: write_json_data(final_json_data, output_json_path)
            else: print("ÈõÜÁ¥ÑÂæå„Éá„Éº„Çø„Å™„Åó„ÄÇJSONÊú™‰ΩúÊàê„ÄÇ")
        else: print("\nÊúâÂäπ„Éá„Éº„ÇøÂèéÈõÜ„Åï„Çå„Åö„ÄÇJSONÊú™‰ΩúÊàê„ÄÇ")

        end_time = time.time()
        elapsed_time = end_time - global_start_time
        print(f"\nÂá¶ÁêÜÊôÇÈñì: {elapsed_time:.2f} Áßí")
        print(f"„Çπ„ÇØ„É¨„Ç§„Éî„É≥„Ç∞ÁµÇ‰∫Ü: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
